seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0696392 | Vali Loss: 0.3243272 | Test Loss: 0.3176459 | Mae Loss: 0.4751134 | SMAPE: 42.7185249 | MASE: 4.2811551
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0642174 | Vali Loss: 0.3324864 | Test Loss: 0.3147739 | Mae Loss: 0.4778832 | SMAPE: 40.8986588 | MASE: 4.4245501
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0563800 | Vali Loss: 0.1916602 | Test Loss: 0.2178259 | Mae Loss: 0.3560271 | SMAPE: 36.3930779 | MASE: 3.8556917
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0494304 | Vali Loss: 0.0810387 | Test Loss: 0.1195956 | Mae Loss: 0.2276289 | SMAPE: 27.2471581 | MASE: 2.8669908
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0335846 | Vali Loss: 0.0810250 | Test Loss: 0.0995754 | Mae Loss: 0.2293196 | SMAPE: 19.2934341 | MASE: 2.2575071
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0361595 | Vali Loss: 0.0763195 | Test Loss: 0.0961387 | Mae Loss: 0.2217964 | SMAPE: 17.7145443 | MASE: 1.9371008
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0365040 | Vali Loss: 0.0740994 | Test Loss: 0.0933447 | Mae Loss: 0.2146527 | SMAPE: 18.9615822 | MASE: 2.1389222
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0316138 | Vali Loss: 0.0696054 | Test Loss: 0.0927663 | Mae Loss: 0.2046740 | SMAPE: 16.6520691 | MASE: 2.2109637
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0339190 | Vali Loss: 0.0709621 | Test Loss: 0.0915154 | Mae Loss: 0.2082149 | SMAPE: 25.6219120 | MASE: 2.1707284
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0321109 | Vali Loss: 0.0682063 | Test Loss: 0.0912050 | Mae Loss: 0.2025537 | SMAPE: 11.5469360 | MASE: 1.1824424
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1381677 | Vali Loss: 0.5320563 | Test Loss: 0.3544485 | Mae Loss: 0.6583661 | SMAPE: 52.1480484 | MASE: 6.7911258
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1087070 | Vali Loss: 0.5925117 | Test Loss: 0.3977136 | Mae Loss: 0.7157545 | SMAPE: 56.4834938 | MASE: 6.4455237
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.1087693 | Vali Loss: 0.6123986 | Test Loss: 0.4193042 | Mae Loss: 0.7239313 | SMAPE: 54.3769722 | MASE: 7.6487007
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.1018344 | Vali Loss: 0.4108047 | Test Loss: 0.3820004 | Mae Loss: 0.6010389 | SMAPE: 54.8516998 | MASE: 6.4011173
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0958175 | Vali Loss: 0.6104428 | Test Loss: 0.3728434 | Mae Loss: 0.7278700 | SMAPE: 53.2516174 | MASE: 6.8167877
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0976289 | Vali Loss: 0.4323001 | Test Loss: 0.3647761 | Mae Loss: 0.6120523 | SMAPE: 49.4025307 | MASE: 5.9369707
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0916516 | Vali Loss: 0.5382486 | Test Loss: 0.3527061 | Mae Loss: 0.6799380 | SMAPE: 41.4257011 | MASE: 4.9237952
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0835962 | Vali Loss: 0.5122477 | Test Loss: 0.3459981 | Mae Loss: 0.6603855 | SMAPE: 53.0244904 | MASE: 7.1499248
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0908997 | Vali Loss: 0.4688631 | Test Loss: 0.3399743 | Mae Loss: 0.6324078 | SMAPE: 52.2274628 | MASE: 6.0844316
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0857748 | Vali Loss: 0.4035644 | Test Loss: 0.3376308 | Mae Loss: 0.5894799 | SMAPE: 49.9496689 | MASE: 6.0451155
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.2072169 | Vali Loss: 0.8165677 | Test Loss: 0.3825607 | Mae Loss: 0.8556445 | SMAPE: 59.3487625 | MASE: 7.5385718
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1247004 | Vali Loss: 0.6010769 | Test Loss: 0.3012232 | Mae Loss: 0.7445837 | SMAPE: 56.2750702 | MASE: 7.4951329
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1245563 | Vali Loss: 0.7590699 | Test Loss: 0.3590068 | Mae Loss: 0.8404161 | SMAPE: 59.9270935 | MASE: 7.6660080
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1228164 | Vali Loss: 0.7337443 | Test Loss: 0.3315608 | Mae Loss: 0.8301902 | SMAPE: 58.4822006 | MASE: 7.3691440
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1162902 | Vali Loss: 0.7471560 | Test Loss: 0.3489077 | Mae Loss: 0.8399672 | SMAPE: 60.1673012 | MASE: 7.4423447
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1150491 | Vali Loss: 0.8196760 | Test Loss: 0.3539148 | Mae Loss: 0.8832354 | SMAPE: 63.4221573 | MASE: 8.2686710
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.1164818 | Vali Loss: 0.8094869 | Test Loss: 0.3403136 | Mae Loss: 0.8756849 | SMAPE: 61.8090096 | MASE: 8.6975155
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1160525 | Vali Loss: 0.8012154 | Test Loss: 0.3359687 | Mae Loss: 0.8749729 | SMAPE: 60.8798866 | MASE: 8.1867342
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1165142 | Vali Loss: 0.7689492 | Test Loss: 0.3341749 | Mae Loss: 0.8524123 | SMAPE: 58.9401894 | MASE: 7.9638858
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.1066703 | Vali Loss: 0.7803434 | Test Loss: 0.3343947 | Mae Loss: 0.8535125 | SMAPE: 59.7534409 | MASE: 8.2759647
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2072792 | Vali Loss: 0.7261478 | Test Loss: 0.2832362 | Mae Loss: 0.8021973 | SMAPE: 58.0076561 | MASE: 7.5843649
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1416521 | Vali Loss: 0.8236663 | Test Loss: 0.3016620 | Mae Loss: 0.8787717 | SMAPE: 61.8741684 | MASE: 8.0035248
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1411418 | Vali Loss: 0.8973536 | Test Loss: 0.3215424 | Mae Loss: 0.9087654 | SMAPE: 62.7082214 | MASE: 8.4480867
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1359974 | Vali Loss: 0.8080122 | Test Loss: 0.2991055 | Mae Loss: 0.8724675 | SMAPE: 60.5062408 | MASE: 8.2933035
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1356290 | Vali Loss: 0.8140561 | Test Loss: 0.2988286 | Mae Loss: 0.8743774 | SMAPE: 62.1077309 | MASE: 8.7120342
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1222418 | Vali Loss: 0.8040565 | Test Loss: 0.3001829 | Mae Loss: 0.8633136 | SMAPE: 61.4443970 | MASE: 8.2246666
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1335180 | Vali Loss: 0.8009696 | Test Loss: 0.3034993 | Mae Loss: 0.8675310 | SMAPE: 59.5744057 | MASE: 8.2789412
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1358704 | Vali Loss: 0.8651540 | Test Loss: 0.3047207 | Mae Loss: 0.8982183 | SMAPE: 61.3663445 | MASE: 8.2578506
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1389549 | Vali Loss: 0.8380218 | Test Loss: 0.3054161 | Mae Loss: 0.8865736 | SMAPE: 60.4012604 | MASE: 7.7166405
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1287738 | Vali Loss: 0.8827194 | Test Loss: 0.3055764 | Mae Loss: 0.9124036 | SMAPE: 62.6234055 | MASE: 8.7909803
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.2666446 | Vali Loss: 0.5989935 | Test Loss: 0.3694114 | Mae Loss: 0.7066820 | SMAPE: 54.1511459 | MASE: 6.9352012
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1548544 | Vali Loss: 0.7397215 | Test Loss: 0.3905493 | Mae Loss: 0.8249150 | SMAPE: 61.2436066 | MASE: 8.1224022
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1542279 | Vali Loss: 0.8696021 | Test Loss: 0.4466439 | Mae Loss: 0.8813044 | SMAPE: 58.1046028 | MASE: 7.9946642
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1591119 | Vali Loss: 0.8255841 | Test Loss: 0.4314039 | Mae Loss: 0.8842064 | SMAPE: 57.6180115 | MASE: 8.1245661
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1480244 | Vali Loss: 0.7734413 | Test Loss: 0.4123758 | Mae Loss: 0.8496322 | SMAPE: 59.8264618 | MASE: 8.2438440
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1382000 | Vali Loss: 0.7613317 | Test Loss: 0.4041894 | Mae Loss: 0.8395011 | SMAPE: 57.6633644 | MASE: 7.5808296
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1363301 | Vali Loss: 0.7837449 | Test Loss: 0.4072395 | Mae Loss: 0.8589257 | SMAPE: 59.7236557 | MASE: 8.1431894
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1468849 | Vali Loss: 0.7698005 | Test Loss: 0.4073155 | Mae Loss: 0.8464584 | SMAPE: 60.8445091 | MASE: 8.0139294
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1395042 | Vali Loss: 0.7991305 | Test Loss: 0.4082942 | Mae Loss: 0.8613118 | SMAPE: 60.8568306 | MASE: 8.1325769
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1399180 | Vali Loss: 0.7744879 | Test Loss: 0.4083708 | Mae Loss: 0.8513604 | SMAPE: 61.3452072 | MASE: 8.2132969
