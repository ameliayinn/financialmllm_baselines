seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0474534 | Vali Loss: 0.0394342 | Test Loss: 0.0727392 | Mae Loss: 0.1506099 | SMAPE: 15.5757952 | MASE: 2.1278887
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0356944 | Vali Loss: 0.0426310 | Test Loss: 0.0771758 | Mae Loss: 0.1617027 | SMAPE: 11.2404261 | MASE: 2.2660763
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0327917 | Vali Loss: 0.0156687 | Test Loss: 0.0247434 | Mae Loss: 0.0941577 | SMAPE: 11.2709370 | MASE: 1.6041894
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0305144 | Vali Loss: 0.0187793 | Test Loss: 0.0211309 | Mae Loss: 0.1048788 | SMAPE: 8.3470707 | MASE: 1.5415128
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0287501 | Vali Loss: 0.0192073 | Test Loss: 0.0217351 | Mae Loss: 0.1015661 | SMAPE: 9.7740726 | MASE: 1.6544667
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0269613 | Vali Loss: 0.0194353 | Test Loss: 0.0222276 | Mae Loss: 0.1048009 | SMAPE: 8.2237606 | MASE: 1.4642415
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0256710 | Vali Loss: 0.0197501 | Test Loss: 0.0217260 | Mae Loss: 0.1077366 | SMAPE: 10.2687206 | MASE: 1.5925763
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0234935 | Vali Loss: 0.0196186 | Test Loss: 0.0221655 | Mae Loss: 0.1065717 | SMAPE: 8.6242218 | MASE: 1.4861743
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0229443 | Vali Loss: 0.0193421 | Test Loss: 0.0224962 | Mae Loss: 0.1068776 | SMAPE: 7.1369591 | MASE: 1.4446687
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0224670 | Vali Loss: 0.0192923 | Test Loss: 0.0225109 | Mae Loss: 0.1055157 | SMAPE: 8.9931726 | MASE: 1.4468360
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1040652 | Vali Loss: 0.0529831 | Test Loss: 0.2052374 | Mae Loss: 0.1708957 | SMAPE: 15.0298443 | MASE: 2.1502216
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0758304 | Vali Loss: 0.0680285 | Test Loss: 0.2658596 | Mae Loss: 0.2193654 | SMAPE: 17.3434982 | MASE: 3.0379198
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0762818 | Vali Loss: 0.0635887 | Test Loss: 0.2507335 | Mae Loss: 0.2129713 | SMAPE: 17.6801586 | MASE: 2.9266634
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0790229 | Vali Loss: 0.0329343 | Test Loss: 0.2208803 | Mae Loss: 0.1532065 | SMAPE: 16.2611847 | MASE: 2.4264920
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0558525 | Vali Loss: 0.0475037 | Test Loss: 0.1935326 | Mae Loss: 0.1669607 | SMAPE: 15.1356249 | MASE: 2.4424520
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0651066 | Vali Loss: 0.0356484 | Test Loss: 0.1722435 | Mae Loss: 0.1569249 | SMAPE: 12.2907963 | MASE: 2.0886514
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0596174 | Vali Loss: 0.0366462 | Test Loss: 0.1623237 | Mae Loss: 0.1429891 | SMAPE: 12.6152725 | MASE: 2.1791599
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0586682 | Vali Loss: 0.0493182 | Test Loss: 0.1570072 | Mae Loss: 0.1668278 | SMAPE: 13.3214054 | MASE: 2.3826091
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0607897 | Vali Loss: 0.0447317 | Test Loss: 0.1543944 | Mae Loss: 0.1586772 | SMAPE: 12.2289209 | MASE: 2.2518740
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0550254 | Vali Loss: 0.0345853 | Test Loss: 0.1532500 | Mae Loss: 0.1456190 | SMAPE: 13.3622351 | MASE: 1.9645568
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1982948 | Vali Loss: 0.0514452 | Test Loss: 0.3323949 | Mae Loss: 0.1861253 | SMAPE: 12.4988756 | MASE: 2.2520711
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1225255 | Vali Loss: 0.0576858 | Test Loss: 0.3808352 | Mae Loss: 0.2024495 | SMAPE: 16.3053646 | MASE: 2.7105200
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1170785 | Vali Loss: 0.0512529 | Test Loss: 0.4123409 | Mae Loss: 0.1785544 | SMAPE: 15.7547264 | MASE: 2.7755625
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1126771 | Vali Loss: 0.0574900 | Test Loss: 0.3813058 | Mae Loss: 0.2009615 | SMAPE: 15.1575775 | MASE: 2.8518808
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1161040 | Vali Loss: 0.0603706 | Test Loss: 0.3621144 | Mae Loss: 0.2065235 | SMAPE: 12.6539364 | MASE: 2.4061863
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1107130 | Vali Loss: 0.0648957 | Test Loss: 0.3509236 | Mae Loss: 0.2162102 | SMAPE: 12.7866163 | MASE: 2.1584756
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.1128860 | Vali Loss: 0.0598315 | Test Loss: 0.3522135 | Mae Loss: 0.2020168 | SMAPE: 15.8218460 | MASE: 2.8127015
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1178402 | Vali Loss: 0.0649898 | Test Loss: 0.3536843 | Mae Loss: 0.2137446 | SMAPE: 13.9917698 | MASE: 2.4612944
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1132195 | Vali Loss: 0.0595961 | Test Loss: 0.3537461 | Mae Loss: 0.2012324 | SMAPE: 15.5865278 | MASE: 2.8808112
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.1119901 | Vali Loss: 0.0543397 | Test Loss: 0.3533860 | Mae Loss: 0.1831557 | SMAPE: 15.4479694 | MASE: 2.6091385
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2339221 | Vali Loss: 0.0525703 | Test Loss: 0.5083152 | Mae Loss: 0.1910054 | SMAPE: 14.1021729 | MASE: 2.4257295
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1713819 | Vali Loss: 0.0627344 | Test Loss: 0.5797492 | Mae Loss: 0.2109833 | SMAPE: 15.9242420 | MASE: 2.6885889
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1718820 | Vali Loss: 0.0339697 | Test Loss: 0.4015651 | Mae Loss: 0.1406676 | SMAPE: 11.8358793 | MASE: 2.0226839
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1719449 | Vali Loss: 0.0469129 | Test Loss: 0.4542908 | Mae Loss: 0.1757004 | SMAPE: 12.8492804 | MASE: 2.2595723
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1541915 | Vali Loss: 0.0494954 | Test Loss: 0.4351993 | Mae Loss: 0.1778062 | SMAPE: 14.5234976 | MASE: 2.4939353
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1432946 | Vali Loss: 0.0391560 | Test Loss: 0.4176594 | Mae Loss: 0.1513174 | SMAPE: 13.7943687 | MASE: 2.3154042
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1526575 | Vali Loss: 0.0444315 | Test Loss: 0.4074777 | Mae Loss: 0.1684232 | SMAPE: 12.9282742 | MASE: 2.2541525
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1349073 | Vali Loss: 0.0463187 | Test Loss: 0.4000223 | Mae Loss: 0.1664239 | SMAPE: 13.4579363 | MASE: 2.2854295
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1502782 | Vali Loss: 0.0442823 | Test Loss: 0.3961295 | Mae Loss: 0.1668126 | SMAPE: 12.0398426 | MASE: 2.1347401
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1413375 | Vali Loss: 0.0490094 | Test Loss: 0.3935374 | Mae Loss: 0.1746233 | SMAPE: 12.7455397 | MASE: 2.1191170
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3821865 | Vali Loss: 0.0389680 | Test Loss: 0.5210508 | Mae Loss: 0.1543292 | SMAPE: 13.7194605 | MASE: 2.3642352
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.2476853 | Vali Loss: 0.0448982 | Test Loss: 0.5224623 | Mae Loss: 0.1690632 | SMAPE: 13.5587063 | MASE: 2.1935275
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.2605126 | Vali Loss: 0.0539193 | Test Loss: 0.5875203 | Mae Loss: 0.1852327 | SMAPE: 14.6807985 | MASE: 2.6665442
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.2814580 | Vali Loss: 0.0506256 | Test Loss: 0.5000820 | Mae Loss: 0.1828788 | SMAPE: 12.7705555 | MASE: 2.3773916
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2685914 | Vali Loss: 0.0464302 | Test Loss: 0.5470921 | Mae Loss: 0.1688809 | SMAPE: 14.0555620 | MASE: 2.4561164
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.2474544 | Vali Loss: 0.0624264 | Test Loss: 0.5865068 | Mae Loss: 0.2030956 | SMAPE: 16.5712051 | MASE: 3.0008829
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2438707 | Vali Loss: 0.0613241 | Test Loss: 0.5931694 | Mae Loss: 0.2035864 | SMAPE: 16.0620193 | MASE: 2.8329575
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.2398462 | Vali Loss: 0.0582728 | Test Loss: 0.5928953 | Mae Loss: 0.1982966 | SMAPE: 16.5616550 | MASE: 2.9058473
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.2358154 | Vali Loss: 0.0592068 | Test Loss: 0.5918738 | Mae Loss: 0.1960438 | SMAPE: 16.4163418 | MASE: 2.8816330
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.2160670 | Vali Loss: 0.0594832 | Test Loss: 0.5913175 | Mae Loss: 0.2017447 | SMAPE: 17.0227623 | MASE: 2.9285989
