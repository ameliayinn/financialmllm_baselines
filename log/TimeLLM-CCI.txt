seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0742684 | Vali Loss: 0.2687047 | Test Loss: 0.1542510 | Mae Loss: 0.4242697 | SMAPE: 41.3703995 | MASE: 4.6180220
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0676860 | Vali Loss: 0.2748459 | Test Loss: 0.1556913 | Mae Loss: 0.4214956 | SMAPE: 36.0514412 | MASE: 3.5460320
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0653096 | Vali Loss: 0.2086193 | Test Loss: 0.1449768 | Mae Loss: 0.3703576 | SMAPE: 33.4936867 | MASE: 3.4861219
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0567503 | Vali Loss: 0.1669137 | Test Loss: 0.1196360 | Mae Loss: 0.3128445 | SMAPE: 40.0222321 | MASE: 4.1333132
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0441359 | Vali Loss: 0.1041117 | Test Loss: 0.1003085 | Mae Loss: 0.2516952 | SMAPE: 24.8485851 | MASE: 2.6547267
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0396304 | Vali Loss: 0.0729955 | Test Loss: 0.0954664 | Mae Loss: 0.2130909 | SMAPE: 13.7236233 | MASE: 1.4048598
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0364112 | Vali Loss: 0.0619211 | Test Loss: 0.0942479 | Mae Loss: 0.1872980 | SMAPE: 25.6653690 | MASE: 2.0474157
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0370579 | Vali Loss: 0.0600950 | Test Loss: 0.0927148 | Mae Loss: 0.1841523 | SMAPE: 18.1036224 | MASE: 1.6603711
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0406660 | Vali Loss: 0.0585402 | Test Loss: 0.0920756 | Mae Loss: 0.1848966 | SMAPE: 24.1129456 | MASE: 2.2241631
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0343534 | Vali Loss: 0.0579851 | Test Loss: 0.0918226 | Mae Loss: 0.1818913 | SMAPE: 11.1312094 | MASE: 1.2908993
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1763173 | Vali Loss: 0.7150800 | Test Loss: 0.2831623 | Mae Loss: 0.7534546 | SMAPE: 60.6780815 | MASE: 6.9546223
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1305286 | Vali Loss: 0.6659860 | Test Loss: 0.3184214 | Mae Loss: 0.7184863 | SMAPE: 67.7345657 | MASE: 7.6360044
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.1363180 | Vali Loss: 0.7358314 | Test Loss: 0.2911797 | Mae Loss: 0.7570435 | SMAPE: 69.5238113 | MASE: 8.3146868
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.1246142 | Vali Loss: 0.4414967 | Test Loss: 0.2514201 | Mae Loss: 0.5865159 | SMAPE: 54.7562675 | MASE: 6.3060570
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.1033724 | Vali Loss: 0.5880779 | Test Loss: 0.2102563 | Mae Loss: 0.6957349 | SMAPE: 52.8954391 | MASE: 5.5954032
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0935435 | Vali Loss: 0.3725946 | Test Loss: 0.2092831 | Mae Loss: 0.5047712 | SMAPE: 51.1354752 | MASE: 5.2265086
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0857555 | Vali Loss: 0.4144337 | Test Loss: 0.1902984 | Mae Loss: 0.5577852 | SMAPE: 39.0880203 | MASE: 4.2186499
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0783858 | Vali Loss: 0.3644776 | Test Loss: 0.1839160 | Mae Loss: 0.5031333 | SMAPE: 65.5368423 | MASE: 6.7774734
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0853374 | Vali Loss: 0.4099353 | Test Loss: 0.1820563 | Mae Loss: 0.5464273 | SMAPE: 48.1173935 | MASE: 4.5066409
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0808190 | Vali Loss: 0.3484207 | Test Loss: 0.1830321 | Mae Loss: 0.4885374 | SMAPE: 37.9274902 | MASE: 3.9864910
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.3143198 | Vali Loss: 0.6415540 | Test Loss: 0.5251710 | Mae Loss: 0.7421978 | SMAPE: 55.9328918 | MASE: 6.0971646
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.2077888 | Vali Loss: 0.8451408 | Test Loss: 0.4245706 | Mae Loss: 0.8768637 | SMAPE: 76.5614471 | MASE: 9.9991980
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.2011129 | Vali Loss: 0.7979982 | Test Loss: 0.4147231 | Mae Loss: 0.8485410 | SMAPE: 66.4981766 | MASE: 8.1560268
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1889144 | Vali Loss: 0.8571769 | Test Loss: 0.4120858 | Mae Loss: 0.8911174 | SMAPE: 73.2481384 | MASE: 8.5925341
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1832621 | Vali Loss: 0.9473161 | Test Loss: 0.4106096 | Mae Loss: 0.9418586 | SMAPE: 62.6163788 | MASE: 7.2657714
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1899910 | Vali Loss: 0.9349409 | Test Loss: 0.4132589 | Mae Loss: 0.9347455 | SMAPE: 67.8343277 | MASE: 7.7913737
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.1935582 | Vali Loss: 0.8604428 | Test Loss: 0.4117347 | Mae Loss: 0.8908273 | SMAPE: 74.4536514 | MASE: 9.1673670
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1944917 | Vali Loss: 0.9122122 | Test Loss: 0.4107549 | Mae Loss: 0.9301683 | SMAPE: 74.0874557 | MASE: 8.6888142
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1894179 | Vali Loss: 0.8815036 | Test Loss: 0.4098426 | Mae Loss: 0.9070470 | SMAPE: 74.4757004 | MASE: 9.1878681
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.1875557 | Vali Loss: 0.8322588 | Test Loss: 0.4093480 | Mae Loss: 0.8707107 | SMAPE: 75.8678894 | MASE: 8.7719603
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2899882 | Vali Loss: 0.6681613 | Test Loss: 0.5200617 | Mae Loss: 0.7703530 | SMAPE: 64.7381744 | MASE: 6.9812593
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.2460759 | Vali Loss: 0.7837218 | Test Loss: 0.4333432 | Mae Loss: 0.8502188 | SMAPE: 65.4941788 | MASE: 7.3847389
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2292919 | Vali Loss: 0.6435068 | Test Loss: 0.4621187 | Mae Loss: 0.7583897 | SMAPE: 70.0673752 | MASE: 7.9427681
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.2372761 | Vali Loss: 0.7876846 | Test Loss: 0.4126469 | Mae Loss: 0.8550910 | SMAPE: 70.2138748 | MASE: 8.0293159
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.2320336 | Vali Loss: 0.7370843 | Test Loss: 0.4186300 | Mae Loss: 0.8258805 | SMAPE: 73.0478668 | MASE: 8.8983440
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.2274340 | Vali Loss: 0.7404348 | Test Loss: 0.4063225 | Mae Loss: 0.8216879 | SMAPE: 69.4339142 | MASE: 7.9702082
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.2279010 | Vali Loss: 0.7764739 | Test Loss: 0.4090793 | Mae Loss: 0.8495204 | SMAPE: 71.0894623 | MASE: 8.4350576
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.2353834 | Vali Loss: 0.7504694 | Test Loss: 0.4084584 | Mae Loss: 0.8250982 | SMAPE: 70.7176056 | MASE: 8.2207632
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.2359977 | Vali Loss: 0.7454664 | Test Loss: 0.4093405 | Mae Loss: 0.8242005 | SMAPE: 66.9577942 | MASE: 7.4763455
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.2317207 | Vali Loss: 0.7707295 | Test Loss: 0.4098319 | Mae Loss: 0.8469132 | SMAPE: 72.9975204 | MASE: 8.4955368
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.4106227 | Vali Loss: 0.5609365 | Test Loss: 0.4999687 | Mae Loss: 0.6922095 | SMAPE: 59.9423637 | MASE: 6.4498925
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.2843789 | Vali Loss: 0.6465538 | Test Loss: 0.3869505 | Mae Loss: 0.7628423 | SMAPE: 64.0823135 | MASE: 7.0627670
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.2670520 | Vali Loss: 0.7468694 | Test Loss: 0.3243558 | Mae Loss: 0.8294288 | SMAPE: 66.0914993 | MASE: 7.6759057
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.2756434 | Vali Loss: 0.8094651 | Test Loss: 0.3353913 | Mae Loss: 0.8724326 | SMAPE: 68.3232117 | MASE: 7.9016852
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2593705 | Vali Loss: 0.7392126 | Test Loss: 0.3313780 | Mae Loss: 0.8254385 | SMAPE: 70.9804230 | MASE: 8.2544994
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.2736373 | Vali Loss: 0.7543808 | Test Loss: 0.3279959 | Mae Loss: 0.8272496 | SMAPE: 68.4367676 | MASE: 7.8835235
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2658657 | Vali Loss: 0.7791494 | Test Loss: 0.3280651 | Mae Loss: 0.8510866 | SMAPE: 71.2550430 | MASE: 8.0571556
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.2606450 | Vali Loss: 0.7225422 | Test Loss: 0.3273044 | Mae Loss: 0.8179265 | SMAPE: 69.1357727 | MASE: 8.1502018
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.2657680 | Vali Loss: 0.7435651 | Test Loss: 0.3271474 | Mae Loss: 0.8202545 | SMAPE: 71.7286911 | MASE: 8.3011761
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.2436819 | Vali Loss: 0.7552490 | Test Loss: 0.3273676 | Mae Loss: 0.8383973 | SMAPE: 74.2176743 | MASE: 8.6834078
