seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0489812 | Vali Loss: 0.0212474 | Test Loss: 0.0655068 | Mae Loss: 0.1277302 | SMAPE: 5.7381592 | MASE: 2.9296272
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0419287 | Vali Loss: 0.0096193 | Test Loss: 0.0426282 | Mae Loss: 0.0845609 | SMAPE: 3.7882214 | MASE: 1.4564228
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0296550 | Vali Loss: 0.0103189 | Test Loss: 0.0335396 | Mae Loss: 0.0817615 | SMAPE: 2.8958402 | MASE: 1.2947460
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0293445 | Vali Loss: 0.0072757 | Test Loss: 0.0279899 | Mae Loss: 0.0701882 | SMAPE: 4.8726516 | MASE: 2.0291812
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0219661 | Vali Loss: 0.0105725 | Test Loss: 0.0297553 | Mae Loss: 0.0830997 | SMAPE: 3.5023034 | MASE: 1.4441712
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0237850 | Vali Loss: 0.0093834 | Test Loss: 0.0287364 | Mae Loss: 0.0768416 | SMAPE: 3.4030542 | MASE: 1.3493545
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0207728 | Vali Loss: 0.0086242 | Test Loss: 0.0275055 | Mae Loss: 0.0742379 | SMAPE: 4.6093621 | MASE: 1.7924467
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0229823 | Vali Loss: 0.0085630 | Test Loss: 0.0272469 | Mae Loss: 0.0741713 | SMAPE: 5.5382857 | MASE: 1.9816747
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0212237 | Vali Loss: 0.0080320 | Test Loss: 0.0267122 | Mae Loss: 0.0721500 | SMAPE: 4.5159550 | MASE: 2.3302064
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0183835 | Vali Loss: 0.0082341 | Test Loss: 0.0266672 | Mae Loss: 0.0728379 | SMAPE: 2.8960130 | MASE: 1.0976982
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1100076 | Vali Loss: 0.0570328 | Test Loss: 0.0722803 | Mae Loss: 0.2214050 | SMAPE: 10.3248940 | MASE: 3.8247249
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0761474 | Vali Loss: 0.0344249 | Test Loss: 0.0613693 | Mae Loss: 0.1698837 | SMAPE: 8.7873840 | MASE: 3.5670803
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0649421 | Vali Loss: 0.0527712 | Test Loss: 0.0639956 | Mae Loss: 0.2113416 | SMAPE: 10.0766134 | MASE: 3.7300673
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0711174 | Vali Loss: 0.0375378 | Test Loss: 0.0573998 | Mae Loss: 0.1753077 | SMAPE: 7.5899391 | MASE: 3.1061826
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0630891 | Vali Loss: 0.0360198 | Test Loss: 0.0555739 | Mae Loss: 0.1744169 | SMAPE: 7.5311236 | MASE: 3.0203218
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0604916 | Vali Loss: 0.0324088 | Test Loss: 0.0520254 | Mae Loss: 0.1616912 | SMAPE: 8.8687582 | MASE: 3.5195601
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0593919 | Vali Loss: 0.0245907 | Test Loss: 0.0501729 | Mae Loss: 0.1366585 | SMAPE: 7.4142084 | MASE: 2.9180696
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0565279 | Vali Loss: 0.0280573 | Test Loss: 0.0495602 | Mae Loss: 0.1524234 | SMAPE: 8.8011103 | MASE: 3.4061263
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0593217 | Vali Loss: 0.0265614 | Test Loss: 0.0491919 | Mae Loss: 0.1470500 | SMAPE: 6.2804713 | MASE: 2.4011388
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0543922 | Vali Loss: 0.0287098 | Test Loss: 0.0490869 | Mae Loss: 0.1520528 | SMAPE: 6.7061186 | MASE: 2.6849775
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1326044 | Vali Loss: 0.0560159 | Test Loss: 0.0782008 | Mae Loss: 0.2103976 | SMAPE: 9.2502270 | MASE: 3.9031892
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1039572 | Vali Loss: 0.0655400 | Test Loss: 0.0769853 | Mae Loss: 0.2375798 | SMAPE: 13.2298632 | MASE: 5.2476749
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.0956244 | Vali Loss: 0.0959953 | Test Loss: 0.0801075 | Mae Loss: 0.2878220 | SMAPE: 14.6396894 | MASE: 5.9319773
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.0802790 | Vali Loss: 0.0708564 | Test Loss: 0.0728260 | Mae Loss: 0.2471899 | SMAPE: 11.1152363 | MASE: 4.3284154
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0841142 | Vali Loss: 0.0826536 | Test Loss: 0.0733432 | Mae Loss: 0.2682911 | SMAPE: 11.9370356 | MASE: 4.7231188
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0859733 | Vali Loss: 0.0839771 | Test Loss: 0.0744261 | Mae Loss: 0.2716915 | SMAPE: 12.2455339 | MASE: 5.1361628
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0882314 | Vali Loss: 0.0775614 | Test Loss: 0.0742903 | Mae Loss: 0.2590122 | SMAPE: 11.6291370 | MASE: 4.5034137
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.0896666 | Vali Loss: 0.0849642 | Test Loss: 0.0742163 | Mae Loss: 0.2751020 | SMAPE: 12.4654312 | MASE: 4.7921948
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0852352 | Vali Loss: 0.0859669 | Test Loss: 0.0739737 | Mae Loss: 0.2758420 | SMAPE: 12.6957150 | MASE: 4.9605622
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0775981 | Vali Loss: 0.0688537 | Test Loss: 0.0740502 | Mae Loss: 0.2450595 | SMAPE: 13.0915298 | MASE: 5.0370669
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.1543247 | Vali Loss: 0.1548638 | Test Loss: 0.1022526 | Mae Loss: 0.3709165 | SMAPE: 16.6212254 | MASE: 6.3794465
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1050067 | Vali Loss: 0.1425861 | Test Loss: 0.1067313 | Mae Loss: 0.3506114 | SMAPE: 18.3763676 | MASE: 7.1458716
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1087117 | Vali Loss: 0.1005582 | Test Loss: 0.0919522 | Mae Loss: 0.2979604 | SMAPE: 16.1075821 | MASE: 6.3100362
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.0987713 | Vali Loss: 0.1385764 | Test Loss: 0.0927118 | Mae Loss: 0.3513103 | SMAPE: 16.8358154 | MASE: 6.5226579
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1026434 | Vali Loss: 0.1297715 | Test Loss: 0.0930529 | Mae Loss: 0.3358918 | SMAPE: 15.7670469 | MASE: 6.0000410
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.0925011 | Vali Loss: 0.1127832 | Test Loss: 0.0918804 | Mae Loss: 0.3130438 | SMAPE: 17.0777893 | MASE: 6.5242743
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.0922664 | Vali Loss: 0.1344123 | Test Loss: 0.0917207 | Mae Loss: 0.3460119 | SMAPE: 16.8571434 | MASE: 6.4371457
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.0946265 | Vali Loss: 0.1164004 | Test Loss: 0.0919829 | Mae Loss: 0.3200146 | SMAPE: 16.2954292 | MASE: 6.1814547
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1013005 | Vali Loss: 0.1193946 | Test Loss: 0.0924063 | Mae Loss: 0.3241348 | SMAPE: 16.2029190 | MASE: 6.2658930
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.0964196 | Vali Loss: 0.1295929 | Test Loss: 0.0924628 | Mae Loss: 0.3413429 | SMAPE: 16.3600273 | MASE: 6.3216124
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.2227509 | Vali Loss: 0.1629559 | Test Loss: 0.0934886 | Mae Loss: 0.3704202 | SMAPE: 17.4976444 | MASE: 6.5945711
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1265967 | Vali Loss: 0.1673602 | Test Loss: 0.1069555 | Mae Loss: 0.3838853 | SMAPE: 18.2329178 | MASE: 6.9719825
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1317837 | Vali Loss: 0.1347438 | Test Loss: 0.0820940 | Mae Loss: 0.3354297 | SMAPE: 16.3240204 | MASE: 6.3175001
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1203974 | Vali Loss: 0.1407601 | Test Loss: 0.0940580 | Mae Loss: 0.3523872 | SMAPE: 18.9745922 | MASE: 6.9999480
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1243083 | Vali Loss: 0.1406287 | Test Loss: 0.0848725 | Mae Loss: 0.3465188 | SMAPE: 16.0393276 | MASE: 6.1505198
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1186214 | Vali Loss: 0.1143892 | Test Loss: 0.0827137 | Mae Loss: 0.3058197 | SMAPE: 16.8932533 | MASE: 6.5746174
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1135387 | Vali Loss: 0.1223100 | Test Loss: 0.0828569 | Mae Loss: 0.3206047 | SMAPE: 15.8409815 | MASE: 6.0670977
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1280413 | Vali Loss: 0.1474195 | Test Loss: 0.0839320 | Mae Loss: 0.3572196 | SMAPE: 15.7974033 | MASE: 6.2275853
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1214392 | Vali Loss: 0.1202881 | Test Loss: 0.0845403 | Mae Loss: 0.3174233 | SMAPE: 16.3630848 | MASE: 6.3957787
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1199458 | Vali Loss: 0.1374409 | Test Loss: 0.0850269 | Mae Loss: 0.3449771 | SMAPE: 15.4226913 | MASE: 5.9857736
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0509805 | Vali Loss: 0.0332269 | Test Loss: 0.0542473 | Mae Loss: 0.1684640 | SMAPE: 8.1338196 | MASE: 3.5185943
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0429280 | Vali Loss: 0.0097896 | Test Loss: 0.0448974 | Mae Loss: 0.0812368 | SMAPE: 5.8946109 | MASE: 2.0992424
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0494345 | Vali Loss: 0.0203389 | Test Loss: 0.0521675 | Mae Loss: 0.1274350 | SMAPE: 6.6825891 | MASE: 2.7031693
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0422576 | Vali Loss: 0.0181486 | Test Loss: 0.0452252 | Mae Loss: 0.1195346 | SMAPE: 5.4273462 | MASE: 2.3787029
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0445413 | Vali Loss: 0.0165085 | Test Loss: 0.0443497 | Mae Loss: 0.1100222 | SMAPE: 5.2405977 | MASE: 2.1067429
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0403634 | Vali Loss: 0.0169708 | Test Loss: 0.0442184 | Mae Loss: 0.1115053 | SMAPE: 4.8720655 | MASE: 2.0681248
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0446144 | Vali Loss: 0.0146077 | Test Loss: 0.0442661 | Mae Loss: 0.1030981 | SMAPE: 4.6072135 | MASE: 1.5901455
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0399998 | Vali Loss: 0.0160991 | Test Loss: 0.0444692 | Mae Loss: 0.1091488 | SMAPE: 4.9783301 | MASE: 1.8689739
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0407159 | Vali Loss: 0.0198984 | Test Loss: 0.0442559 | Mae Loss: 0.1220599 | SMAPE: 4.1491566 | MASE: 1.4507788
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0433013 | Vali Loss: 0.0163944 | Test Loss: 0.0443152 | Mae Loss: 0.1075330 | SMAPE: 4.5500884 | MASE: 1.9820333
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0452804 | Vali Loss: 0.0166533 | Test Loss: 0.0442874 | Mae Loss: 0.1118739 | SMAPE: 6.2124205 | MASE: 2.1736410
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0391791 | Vali Loss: 0.0125875 | Test Loss: 0.0443659 | Mae Loss: 0.0945927 | SMAPE: 5.6006021 | MASE: 1.9035124
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1349151 | Vali Loss: 0.0517200 | Test Loss: 0.0713553 | Mae Loss: 0.2091692 | SMAPE: 10.9780455 | MASE: 4.2889123
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0777771 | Vali Loss: 0.0511611 | Test Loss: 0.0702299 | Mae Loss: 0.1980684 | SMAPE: 10.1844215 | MASE: 3.8587780
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0739117 | Vali Loss: 0.0502759 | Test Loss: 0.0641856 | Mae Loss: 0.2109942 | SMAPE: 11.0120153 | MASE: 4.5658669
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0672981 | Vali Loss: 0.0419827 | Test Loss: 0.0631308 | Mae Loss: 0.1916789 | SMAPE: 9.1493120 | MASE: 3.5965574
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0696197 | Vali Loss: 0.0360406 | Test Loss: 0.0626966 | Mae Loss: 0.1768040 | SMAPE: 7.8326507 | MASE: 3.3384378
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0708214 | Vali Loss: 0.0389739 | Test Loss: 0.0625394 | Mae Loss: 0.1816893 | SMAPE: 9.0330763 | MASE: 3.6091757
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0720190 | Vali Loss: 0.0391615 | Test Loss: 0.0625145 | Mae Loss: 0.1824699 | SMAPE: 9.5428705 | MASE: 4.1234746
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0654277 | Vali Loss: 0.0393374 | Test Loss: 0.0626131 | Mae Loss: 0.1841792 | SMAPE: 8.4170256 | MASE: 3.8024151
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0706629 | Vali Loss: 0.0401596 | Test Loss: 0.0622865 | Mae Loss: 0.1866759 | SMAPE: 8.4173193 | MASE: 3.6610415
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0700778 | Vali Loss: 0.0408268 | Test Loss: 0.0622993 | Mae Loss: 0.1858002 | SMAPE: 7.3180890 | MASE: 3.0977597
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0695931 | Vali Loss: 0.0408929 | Test Loss: 0.0622788 | Mae Loss: 0.1855427 | SMAPE: 8.2545900 | MASE: 3.7649295
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.0710406 | Vali Loss: 0.0427537 | Test Loss: 0.0625773 | Mae Loss: 0.1939772 | SMAPE: 8.1802082 | MASE: 3.3644052
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.0688038 | Vali Loss: 0.0431804 | Test Loss: 0.0624068 | Mae Loss: 0.1938284 | SMAPE: 9.7845545 | MASE: 3.9787598
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 14 | Train Loss: 0.0741460 | Vali Loss: 0.0392317 | Test Loss: 0.0624791 | Mae Loss: 0.1830739 | SMAPE: 8.8231773 | MASE: 3.3569982
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 15 | Train Loss: 0.0675209 | Vali Loss: 0.0370587 | Test Loss: 0.0624638 | Mae Loss: 0.1771869 | SMAPE: 9.1312819 | MASE: 3.6067679
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1275338 | Vali Loss: 0.0686870 | Test Loss: 0.0767470 | Mae Loss: 0.2410515 | SMAPE: 9.8482265 | MASE: 4.0385394
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.0945332 | Vali Loss: 0.0860595 | Test Loss: 0.0743955 | Mae Loss: 0.2673845 | SMAPE: 13.6224613 | MASE: 5.5224938
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.0859167 | Vali Loss: 0.0863770 | Test Loss: 0.0741371 | Mae Loss: 0.2748389 | SMAPE: 13.5011787 | MASE: 5.4967866
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.0842618 | Vali Loss: 0.0778822 | Test Loss: 0.0735893 | Mae Loss: 0.2595060 | SMAPE: 11.0370464 | MASE: 4.7132077
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0832000 | Vali Loss: 0.0828917 | Test Loss: 0.0728938 | Mae Loss: 0.2687185 | SMAPE: 11.6856937 | MASE: 4.4469705
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0886023 | Vali Loss: 0.0784902 | Test Loss: 0.0730680 | Mae Loss: 0.2608400 | SMAPE: 12.0905113 | MASE: 4.6991401
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0830365 | Vali Loss: 0.0820122 | Test Loss: 0.0730234 | Mae Loss: 0.2665043 | SMAPE: 14.8057852 | MASE: 5.5558486
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.0772943 | Vali Loss: 0.0833845 | Test Loss: 0.0729282 | Mae Loss: 0.2695317 | SMAPE: 12.4195833 | MASE: 4.8769193
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0810164 | Vali Loss: 0.0799848 | Test Loss: 0.0729086 | Mae Loss: 0.2628971 | SMAPE: 11.3271780 | MASE: 4.9839973
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0836904 | Vali Loss: 0.0799297 | Test Loss: 0.0727726 | Mae Loss: 0.2633909 | SMAPE: 11.0990582 | MASE: 4.5405540
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.0839567 | Vali Loss: 0.0819277 | Test Loss: 0.0728589 | Mae Loss: 0.2658602 | SMAPE: 12.1382017 | MASE: 4.7566824
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2230146 | Vali Loss: 0.2628812 | Test Loss: 0.1564867 | Mae Loss: 0.4833275 | SMAPE: 22.5483093 | MASE: 8.0256128
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1180691 | Vali Loss: 0.0791251 | Test Loss: 0.0989522 | Mae Loss: 0.2424175 | SMAPE: 12.9404564 | MASE: 4.9140606
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1085223 | Vali Loss: 0.1484743 | Test Loss: 0.0959808 | Mae Loss: 0.3573978 | SMAPE: 15.9974842 | MASE: 6.3185639
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1021026 | Vali Loss: 0.1437416 | Test Loss: 0.0966512 | Mae Loss: 0.3503859 | SMAPE: 15.6465721 | MASE: 5.8422127
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.0916607 | Vali Loss: 0.1607283 | Test Loss: 0.0960491 | Mae Loss: 0.3776897 | SMAPE: 15.5261593 | MASE: 6.2365918
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.0978152 | Vali Loss: 0.1217757 | Test Loss: 0.0953196 | Mae Loss: 0.3294100 | SMAPE: 17.1833382 | MASE: 6.8971338
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1024909 | Vali Loss: 0.1089835 | Test Loss: 0.0953826 | Mae Loss: 0.3086393 | SMAPE: 17.5154209 | MASE: 7.1113267
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1004614 | Vali Loss: 0.1303135 | Test Loss: 0.0950012 | Mae Loss: 0.3381922 | SMAPE: 16.8272781 | MASE: 6.3937554
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1044483 | Vali Loss: 0.1084823 | Test Loss: 0.0947982 | Mae Loss: 0.3124575 | SMAPE: 16.0300064 | MASE: 6.1756105
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.0917101 | Vali Loss: 0.1465874 | Test Loss: 0.0948999 | Mae Loss: 0.3662932 | SMAPE: 16.2299023 | MASE: 6.4515176
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.0886887 | Vali Loss: 0.1451700 | Test Loss: 0.0952338 | Mae Loss: 0.3565677 | SMAPE: 14.4502506 | MASE: 5.6157694
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.0981413 | Vali Loss: 0.1246559 | Test Loss: 0.0949581 | Mae Loss: 0.3337332 | SMAPE: 16.3481770 | MASE: 6.3306222
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.2578005 | Vali Loss: 0.2432822 | Test Loss: 0.1546791 | Mae Loss: 0.4563854 | SMAPE: 20.9905910 | MASE: 8.0972309
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1490904 | Vali Loss: 0.0871009 | Test Loss: 0.0903533 | Mae Loss: 0.2619606 | SMAPE: 17.1961441 | MASE: 6.4926701
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1263611 | Vali Loss: 0.1365172 | Test Loss: 0.0886873 | Mae Loss: 0.3340584 | SMAPE: 17.8656750 | MASE: 6.6685667
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1215959 | Vali Loss: 0.1504352 | Test Loss: 0.0852392 | Mae Loss: 0.3573340 | SMAPE: 16.7949753 | MASE: 6.4962983
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1253582 | Vali Loss: 0.1141843 | Test Loss: 0.0869329 | Mae Loss: 0.3119338 | SMAPE: 16.5084305 | MASE: 6.0540652
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1242236 | Vali Loss: 0.1293286 | Test Loss: 0.0865997 | Mae Loss: 0.3262951 | SMAPE: 15.4551725 | MASE: 5.7293510
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1167375 | Vali Loss: 0.1562928 | Test Loss: 0.0863366 | Mae Loss: 0.3682728 | SMAPE: 15.5535936 | MASE: 6.1785693
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1268951 | Vali Loss: 0.1372874 | Test Loss: 0.0865921 | Mae Loss: 0.3428468 | SMAPE: 16.6541061 | MASE: 6.3296318
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1221870 | Vali Loss: 0.1179627 | Test Loss: 0.0861912 | Mae Loss: 0.3103641 | SMAPE: 16.0354404 | MASE: 6.2244849
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1172377 | Vali Loss: 0.1128788 | Test Loss: 0.0861208 | Mae Loss: 0.3111219 | SMAPE: 16.4019585 | MASE: 6.0561509
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.1140769 | Vali Loss: 0.1407062 | Test Loss: 0.0860645 | Mae Loss: 0.3463397 | SMAPE: 17.3943233 | MASE: 6.7111316
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.1179781 | Vali Loss: 0.1335221 | Test Loss: 0.0859755 | Mae Loss: 0.3317543 | SMAPE: 15.8671618 | MASE: 5.9739051
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0489812 | Vali Loss: 0.0212474 | Test Loss: 0.0655068 | Mae Loss: 0.1277302 | SMAPE: 0.9436101 | MASE: 2.9296424
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0419287 | Vali Loss: 0.0096193 | Test Loss: 0.0426282 | Mae Loss: 0.0845609 | SMAPE: 0.5911038 | MASE: 1.4564270
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0296550 | Vali Loss: 0.0103189 | Test Loss: 0.0335396 | Mae Loss: 0.0817615 | SMAPE: 0.4642401 | MASE: 1.2947465
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0293445 | Vali Loss: 0.0072757 | Test Loss: 0.0279899 | Mae Loss: 0.0701882 | SMAPE: 0.7872958 | MASE: 2.0291836
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0219661 | Vali Loss: 0.0105725 | Test Loss: 0.0297553 | Mae Loss: 0.0830997 | SMAPE: 0.5678896 | MASE: 1.4441780
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0237850 | Vali Loss: 0.0093834 | Test Loss: 0.0287364 | Mae Loss: 0.0768416 | SMAPE: 0.5542297 | MASE: 1.3493568
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0207728 | Vali Loss: 0.0086242 | Test Loss: 0.0275055 | Mae Loss: 0.0742379 | SMAPE: 0.7491920 | MASE: 1.7924529
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0229823 | Vali Loss: 0.0085630 | Test Loss: 0.0272469 | Mae Loss: 0.0741713 | SMAPE: 0.8875837 | MASE: 1.9816751
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0212237 | Vali Loss: 0.0080320 | Test Loss: 0.0267122 | Mae Loss: 0.0721500 | SMAPE: 0.7190767 | MASE: 2.3302138
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0183835 | Vali Loss: 0.0082341 | Test Loss: 0.0266672 | Mae Loss: 0.0728379 | SMAPE: 0.4843008 | MASE: 1.0976993
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0221073 | Vali Loss: 0.0082225 | Test Loss: 0.0266903 | Mae Loss: 0.0729592 | SMAPE: 0.6564646 | MASE: 1.5882289
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0210202 | Vali Loss: 0.0083357 | Test Loss: 0.0266436 | Mae Loss: 0.0731426 | SMAPE: 0.5610136 | MASE: 1.4672625
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0215908 | Vali Loss: 0.0085036 | Test Loss: 0.0266351 | Mae Loss: 0.0738358 | SMAPE: 0.7147421 | MASE: 1.7138422
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0224390 | Vali Loss: 0.0079790 | Test Loss: 0.0265975 | Mae Loss: 0.0717179 | SMAPE: 0.5889693 | MASE: 1.3651003
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1100076 | Vali Loss: 0.0570328 | Test Loss: 0.0722803 | Mae Loss: 0.2214050 | SMAPE: 1.6278200 | MASE: 3.8247247
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0761474 | Vali Loss: 0.0344249 | Test Loss: 0.0613693 | Mae Loss: 0.1698837 | SMAPE: 1.3397778 | MASE: 3.5670867
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0649421 | Vali Loss: 0.0527712 | Test Loss: 0.0639956 | Mae Loss: 0.2113416 | SMAPE: 1.5876619 | MASE: 3.7300708
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0711174 | Vali Loss: 0.0375378 | Test Loss: 0.0573998 | Mae Loss: 0.1753077 | SMAPE: 1.2265450 | MASE: 3.1061833
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0630891 | Vali Loss: 0.0360198 | Test Loss: 0.0555739 | Mae Loss: 0.1744169 | SMAPE: 1.2061638 | MASE: 3.0203266
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0604916 | Vali Loss: 0.0324088 | Test Loss: 0.0520254 | Mae Loss: 0.1616912 | SMAPE: 1.4040943 | MASE: 3.5195651
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0593919 | Vali Loss: 0.0245907 | Test Loss: 0.0501729 | Mae Loss: 0.1366585 | SMAPE: 1.2209325 | MASE: 2.9180667
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0565279 | Vali Loss: 0.0280573 | Test Loss: 0.0495602 | Mae Loss: 0.1524234 | SMAPE: 1.3423592 | MASE: 3.4061329
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0593217 | Vali Loss: 0.0265614 | Test Loss: 0.0491919 | Mae Loss: 0.1470500 | SMAPE: 0.9731422 | MASE: 2.4011474
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0543922 | Vali Loss: 0.0287098 | Test Loss: 0.0490869 | Mae Loss: 0.1520528 | SMAPE: 1.0853920 | MASE: 2.6849811
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0572538 | Vali Loss: 0.0231744 | Test Loss: 0.0489368 | Mae Loss: 0.1362929 | SMAPE: 0.9670337 | MASE: 2.6209812
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.0535980 | Vali Loss: 0.0238553 | Test Loss: 0.0487443 | Mae Loss: 0.1354111 | SMAPE: 0.9701144 | MASE: 2.4277046
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.0526271 | Vali Loss: 0.0275368 | Test Loss: 0.0486794 | Mae Loss: 0.1488670 | SMAPE: 1.0938797 | MASE: 2.9522159
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 14 | Train Loss: 0.0527840 | Vali Loss: 0.0278181 | Test Loss: 0.0486530 | Mae Loss: 0.1511463 | SMAPE: 1.1693306 | MASE: 2.9466431
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 15 | Train Loss: 0.0543281 | Vali Loss: 0.0263798 | Test Loss: 0.0487921 | Mae Loss: 0.1432169 | SMAPE: 1.2822100 | MASE: 3.0265481
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 16 | Train Loss: 0.0514665 | Vali Loss: 0.0270912 | Test Loss: 0.0487242 | Mae Loss: 0.1472580 | SMAPE: 1.2016698 | MASE: 2.7474265
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 17 | Train Loss: 0.0575160 | Vali Loss: 0.0242311 | Test Loss: 0.0486145 | Mae Loss: 0.1389205 | SMAPE: 1.2205850 | MASE: 2.8128455
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 18 | Train Loss: 0.0580748 | Vali Loss: 0.0242649 | Test Loss: 0.0487875 | Mae Loss: 0.1404836 | SMAPE: 0.8684636 | MASE: 2.2566526
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 19 | Train Loss: 0.0540932 | Vali Loss: 0.0289129 | Test Loss: 0.0487317 | Mae Loss: 0.1555962 | SMAPE: 1.2483151 | MASE: 3.1542914
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 20 | Train Loss: 0.0543179 | Vali Loss: 0.0202591 | Test Loss: 0.0487876 | Mae Loss: 0.1287891 | SMAPE: 1.3379496 | MASE: 3.2704029
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1326044 | Vali Loss: 0.0560159 | Test Loss: 0.0782008 | Mae Loss: 0.2103976 | SMAPE: 1.4807448 | MASE: 3.9031918
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1039572 | Vali Loss: 0.0655400 | Test Loss: 0.0769853 | Mae Loss: 0.2375798 | SMAPE: 2.0607035 | MASE: 5.2476716
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.0956244 | Vali Loss: 0.0959953 | Test Loss: 0.0801075 | Mae Loss: 0.2878220 | SMAPE: 2.2510886 | MASE: 5.9319816
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.0802790 | Vali Loss: 0.0708564 | Test Loss: 0.0728260 | Mae Loss: 0.2471899 | SMAPE: 1.6839594 | MASE: 4.3284178
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0841142 | Vali Loss: 0.0826536 | Test Loss: 0.0733432 | Mae Loss: 0.2682911 | SMAPE: 1.8708766 | MASE: 4.7231245
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0859733 | Vali Loss: 0.0839771 | Test Loss: 0.0744261 | Mae Loss: 0.2716915 | SMAPE: 1.9010286 | MASE: 5.1361628
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0882314 | Vali Loss: 0.0775614 | Test Loss: 0.0742903 | Mae Loss: 0.2590122 | SMAPE: 1.8484827 | MASE: 4.5034156
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.0896666 | Vali Loss: 0.0849642 | Test Loss: 0.0742163 | Mae Loss: 0.2751020 | SMAPE: 1.8910739 | MASE: 4.7921968
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0852352 | Vali Loss: 0.0859669 | Test Loss: 0.0739737 | Mae Loss: 0.2758420 | SMAPE: 2.0300598 | MASE: 4.9605646
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0775981 | Vali Loss: 0.0688537 | Test Loss: 0.0740502 | Mae Loss: 0.2450595 | SMAPE: 2.0184908 | MASE: 5.0370688
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.0789067 | Vali Loss: 0.0892533 | Test Loss: 0.0739054 | Mae Loss: 0.2825197 | SMAPE: 2.2393332 | MASE: 5.5917482
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.1543247 | Vali Loss: 0.1548638 | Test Loss: 0.1022526 | Mae Loss: 0.3709165 | SMAPE: 2.5327177 | MASE: 6.3794470
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1050067 | Vali Loss: 0.1425861 | Test Loss: 0.1067313 | Mae Loss: 0.3506114 | SMAPE: 2.7856588 | MASE: 7.1458716
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1087117 | Vali Loss: 0.1005582 | Test Loss: 0.0919522 | Mae Loss: 0.2979604 | SMAPE: 2.4554639 | MASE: 6.3100343
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.0987713 | Vali Loss: 0.1385764 | Test Loss: 0.0927118 | Mae Loss: 0.3513103 | SMAPE: 2.5097830 | MASE: 6.5226583
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1026434 | Vali Loss: 0.1297715 | Test Loss: 0.0930529 | Mae Loss: 0.3358918 | SMAPE: 2.4280188 | MASE: 6.0000377
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.0925011 | Vali Loss: 0.1127832 | Test Loss: 0.0918804 | Mae Loss: 0.3130438 | SMAPE: 2.5498896 | MASE: 6.5242724
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.0922664 | Vali Loss: 0.1344123 | Test Loss: 0.0917207 | Mae Loss: 0.3460119 | SMAPE: 2.6150808 | MASE: 6.4371467
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.0946265 | Vali Loss: 0.1164004 | Test Loss: 0.0919829 | Mae Loss: 0.3200146 | SMAPE: 2.4636359 | MASE: 6.1814528
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1013005 | Vali Loss: 0.1193946 | Test Loss: 0.0924063 | Mae Loss: 0.3241348 | SMAPE: 2.4561033 | MASE: 6.2658963
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.0964196 | Vali Loss: 0.1295929 | Test Loss: 0.0924628 | Mae Loss: 0.3413429 | SMAPE: 2.4774024 | MASE: 6.3216119
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.0993369 | Vali Loss: 0.1344013 | Test Loss: 0.0923637 | Mae Loss: 0.3467707 | SMAPE: 2.2986712 | MASE: 5.6976514
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.0884985 | Vali Loss: 0.1178259 | Test Loss: 0.0924497 | Mae Loss: 0.3226434 | SMAPE: 2.5234370 | MASE: 6.4933043
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 13 | Train Loss: 0.0877095 | Vali Loss: 0.1314529 | Test Loss: 0.0923571 | Mae Loss: 0.3463104 | SMAPE: 2.2771513 | MASE: 5.8519192
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.2227509 | Vali Loss: 0.1629559 | Test Loss: 0.0934886 | Mae Loss: 0.3704202 | SMAPE: 2.6391792 | MASE: 6.5945721
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1265967 | Vali Loss: 0.1673602 | Test Loss: 0.1069555 | Mae Loss: 0.3838853 | SMAPE: 2.7196484 | MASE: 6.9719882
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1317837 | Vali Loss: 0.1347438 | Test Loss: 0.0820940 | Mae Loss: 0.3354297 | SMAPE: 2.4754193 | MASE: 6.3175006
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1203974 | Vali Loss: 0.1407601 | Test Loss: 0.0940580 | Mae Loss: 0.3523872 | SMAPE: 2.8809850 | MASE: 6.9999452
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1243083 | Vali Loss: 0.1406287 | Test Loss: 0.0848725 | Mae Loss: 0.3465188 | SMAPE: 2.4636767 | MASE: 6.1505218
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1186214 | Vali Loss: 0.1143892 | Test Loss: 0.0827137 | Mae Loss: 0.3058197 | SMAPE: 2.5292239 | MASE: 6.5746174
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1135387 | Vali Loss: 0.1223100 | Test Loss: 0.0828569 | Mae Loss: 0.3206047 | SMAPE: 2.4009519 | MASE: 6.0670962
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1280413 | Vali Loss: 0.1474195 | Test Loss: 0.0839320 | Mae Loss: 0.3572196 | SMAPE: 2.4311206 | MASE: 6.2275863
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1214392 | Vali Loss: 0.1202881 | Test Loss: 0.0845403 | Mae Loss: 0.3174233 | SMAPE: 2.4820006 | MASE: 6.3957810
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1199458 | Vali Loss: 0.1374409 | Test Loss: 0.0850269 | Mae Loss: 0.3449771 | SMAPE: 2.3417566 | MASE: 5.9857759
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.1218440 | Vali Loss: 0.1265837 | Test Loss: 0.0851598 | Mae Loss: 0.3305655 | SMAPE: 2.3880589 | MASE: 6.0551715
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.1139832 | Vali Loss: 0.1509993 | Test Loss: 0.0851011 | Mae Loss: 0.3646551 | SMAPE: 2.5247407 | MASE: 6.2071743
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 13 | Train Loss: 0.1074135 | Vali Loss: 0.1577207 | Test Loss: 0.0852580 | Mae Loss: 0.3746134 | SMAPE: 2.4514592 | MASE: 6.2227550
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 14 | Train Loss: 0.1186634 | Vali Loss: 0.1180538 | Test Loss: 0.0852168 | Mae Loss: 0.3153921 | SMAPE: 2.5188756 | MASE: 6.2200532
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 15 | Train Loss: 0.1160691 | Vali Loss: 0.1310667 | Test Loss: 0.0851541 | Mae Loss: 0.3380307 | SMAPE: 2.5839317 | MASE: 6.3981404
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 16 | Train Loss: 0.1197686 | Vali Loss: 0.1154205 | Test Loss: 0.0853077 | Mae Loss: 0.3165286 | SMAPE: 2.3242469 | MASE: 5.8495483
