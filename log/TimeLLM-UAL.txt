seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2583969 | Vali Loss: 0.3717564 | Test Loss: 0.2444829 | Mae Loss: 0.5000755 | SMAPE: 30.2731628 | MASE: 4.2586169
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.2430835 | Vali Loss: 0.3885060 | Test Loss: 0.2309709 | Mae Loss: 0.5228790 | SMAPE: 27.9249134 | MASE: 3.7812192
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.2128598 | Vali Loss: 0.3591216 | Test Loss: 0.1801203 | Mae Loss: 0.5059274 | SMAPE: 32.4045639 | MASE: 3.8410754
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.1628467 | Vali Loss: 0.1743992 | Test Loss: 0.1507112 | Mae Loss: 0.3577800 | SMAPE: 20.9234409 | MASE: 2.6164041
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.1251504 | Vali Loss: 0.1045409 | Test Loss: 0.1151014 | Mae Loss: 0.2574826 | SMAPE: 13.4268150 | MASE: 1.4789329
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1243316 | Vali Loss: 0.0913880 | Test Loss: 0.1103172 | Mae Loss: 0.2397486 | SMAPE: 18.0573502 | MASE: 1.5000379
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.1211516 | Vali Loss: 0.0858917 | Test Loss: 0.1075556 | Mae Loss: 0.2312864 | SMAPE: 16.8731060 | MASE: 2.4671061
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.1056478 | Vali Loss: 0.0922557 | Test Loss: 0.1070510 | Mae Loss: 0.2412948 | SMAPE: 19.5297813 | MASE: 1.8964283
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.1196074 | Vali Loss: 0.0769107 | Test Loss: 0.1066503 | Mae Loss: 0.2221014 | SMAPE: 15.6955137 | MASE: 1.7364970
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.1028518 | Vali Loss: 0.0933210 | Test Loss: 0.1066910 | Mae Loss: 0.2426125 | SMAPE: 14.5529375 | MASE: 1.3883125
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.5387103 | Vali Loss: 0.9958253 | Test Loss: 0.2957552 | Mae Loss: 0.7572023 | SMAPE: 43.2547646 | MASE: 5.7388005
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.5930344 | Vali Loss: 0.5761469 | Test Loss: 0.3815931 | Mae Loss: 0.6364387 | SMAPE: 25.3374996 | MASE: 3.4505894
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.4673312 | Vali Loss: 0.5288461 | Test Loss: 0.1798942 | Mae Loss: 0.6015799 | SMAPE: 31.2756481 | MASE: 3.6016855
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.3264354 | Vali Loss: 0.5980332 | Test Loss: 0.1748784 | Mae Loss: 0.6856765 | SMAPE: 38.1503983 | MASE: 4.1088867
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.2497900 | Vali Loss: 0.2829437 | Test Loss: 0.1522473 | Mae Loss: 0.4663850 | SMAPE: 29.5511684 | MASE: 3.2236233
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.2611938 | Vali Loss: 0.3229655 | Test Loss: 0.1388589 | Mae Loss: 0.4871714 | SMAPE: 28.6383591 | MASE: 3.4035480
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.1972659 | Vali Loss: 0.2742945 | Test Loss: 0.1356028 | Mae Loss: 0.4363048 | SMAPE: 34.1405945 | MASE: 3.1410503
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.2194702 | Vali Loss: 0.3573593 | Test Loss: 0.1332921 | Mae Loss: 0.5268542 | SMAPE: 22.0810852 | MASE: 2.7712531
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.2209264 | Vali Loss: 0.2850362 | Test Loss: 0.1334037 | Mae Loss: 0.4692911 | SMAPE: 24.8242016 | MASE: 2.8374755
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.2115153 | Vali Loss: 0.2636479 | Test Loss: 0.1336743 | Mae Loss: 0.4457014 | SMAPE: 30.4289398 | MASE: 3.2608483
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.9777519 | Vali Loss: 0.8880126 | Test Loss: 0.3426731 | Mae Loss: 0.8061208 | SMAPE: 47.9120407 | MASE: 5.2656875
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.8896798 | Vali Loss: 0.7755740 | Test Loss: 0.3807087 | Mae Loss: 0.7650088 | SMAPE: 39.0660172 | MASE: 4.5474472
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.8230148 | Vali Loss: 0.6678101 | Test Loss: 0.2602754 | Mae Loss: 0.6969355 | SMAPE: 40.8842278 | MASE: 4.6003456
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.5902134 | Vali Loss: 0.6104316 | Test Loss: 0.2720469 | Mae Loss: 0.6761914 | SMAPE: 30.5989056 | MASE: 3.5622742
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.4313997 | Vali Loss: 0.5204731 | Test Loss: 0.2847366 | Mae Loss: 0.6100999 | SMAPE: 39.2162857 | MASE: 3.9307408
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.4161026 | Vali Loss: 0.5296230 | Test Loss: 0.3134603 | Mae Loss: 0.6074963 | SMAPE: 35.6479225 | MASE: 4.0901713
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.3875420 | Vali Loss: 0.3608632 | Test Loss: 0.3377115 | Mae Loss: 0.5142993 | SMAPE: 32.5937462 | MASE: 3.6136780
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.3717934 | Vali Loss: 0.4502948 | Test Loss: 0.3336102 | Mae Loss: 0.5642489 | SMAPE: 29.7280846 | MASE: 3.5571589
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.3908174 | Vali Loss: 0.4857793 | Test Loss: 0.3262607 | Mae Loss: 0.5897339 | SMAPE: 38.2678795 | MASE: 4.0665236
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.3531683 | Vali Loss: 0.4209570 | Test Loss: 0.3200216 | Mae Loss: 0.5371268 | SMAPE: 28.6587677 | MASE: 3.7226853
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 1.3764136 | Vali Loss: 0.7763664 | Test Loss: 0.2492189 | Mae Loss: 0.7700316 | SMAPE: 41.3802338 | MASE: 4.7032514
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 1.2187063 | Vali Loss: 0.5266831 | Test Loss: 0.2233566 | Mae Loss: 0.6271324 | SMAPE: 44.9569206 | MASE: 5.0076866
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 1.1287886 | Vali Loss: 0.6644467 | Test Loss: 0.2408416 | Mae Loss: 0.7062735 | SMAPE: 35.3973274 | MASE: 4.1791186
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.9353200 | Vali Loss: 0.6938518 | Test Loss: 0.2767979 | Mae Loss: 0.7063813 | SMAPE: 33.9406242 | MASE: 4.2283373
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.7374830 | Vali Loss: 0.6109504 | Test Loss: 0.3258108 | Mae Loss: 0.6531298 | SMAPE: 38.6947021 | MASE: 4.4730439
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.5748545 | Vali Loss: 0.6108936 | Test Loss: 0.3556603 | Mae Loss: 0.6299638 | SMAPE: 29.3973503 | MASE: 3.7880251
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.5126356 | Vali Loss: 0.7270306 | Test Loss: 0.3569972 | Mae Loss: 0.7033870 | SMAPE: 43.4356346 | MASE: 4.6225872
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.5189307 | Vali Loss: 0.5867242 | Test Loss: 0.3597883 | Mae Loss: 0.6033983 | SMAPE: 34.7314911 | MASE: 4.3515387
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.5349134 | Vali Loss: 0.5802097 | Test Loss: 0.3594305 | Mae Loss: 0.6225910 | SMAPE: 34.3585777 | MASE: 4.1482167
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.4770728 | Vali Loss: 0.6231854 | Test Loss: 0.3592761 | Mae Loss: 0.6349367 | SMAPE: 34.5239182 | MASE: 4.4453540
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 1.7582708 | Vali Loss: 0.5518021 | Test Loss: 0.2602704 | Mae Loss: 0.6021231 | SMAPE: 42.5972900 | MASE: 4.6751466
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 1.6451617 | Vali Loss: 0.8151763 | Test Loss: 0.2708510 | Mae Loss: 0.7807657 | SMAPE: 48.3789902 | MASE: 5.7219920
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 1.5242598 | Vali Loss: 0.7489054 | Test Loss: 0.2396157 | Mae Loss: 0.7633744 | SMAPE: 46.0095749 | MASE: 4.7857399
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 1.4659696 | Vali Loss: 0.7018155 | Test Loss: 0.2398831 | Mae Loss: 0.7343615 | SMAPE: 41.8307800 | MASE: 4.1867905
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 1.5230174 | Vali Loss: 0.7972033 | Test Loss: 0.2384412 | Mae Loss: 0.7887836 | SMAPE: 44.4429207 | MASE: 4.8818746
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 1.4544852 | Vali Loss: 0.8832014 | Test Loss: 0.2373842 | Mae Loss: 0.8338086 | SMAPE: 46.0319595 | MASE: 5.0767350
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 1.5050624 | Vali Loss: 0.8395922 | Test Loss: 0.2372289 | Mae Loss: 0.8172231 | SMAPE: 44.4491119 | MASE: 4.9414001
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 1.5275976 | Vali Loss: 0.7721577 | Test Loss: 0.2372018 | Mae Loss: 0.7832258 | SMAPE: 46.9022827 | MASE: 5.2904148
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 1.4766500 | Vali Loss: 0.9802130 | Test Loss: 0.2371076 | Mae Loss: 0.8974991 | SMAPE: 45.2959862 | MASE: 5.1054835
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 1.4398018 | Vali Loss: 0.7968880 | Test Loss: 0.2370276 | Mae Loss: 0.7884534 | SMAPE: 43.5212746 | MASE: 5.0013084
