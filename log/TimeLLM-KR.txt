seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0928156 | Vali Loss: 0.0160041 | Test Loss: 0.1332124 | Mae Loss: 0.1027789 | SMAPE: 5.4572744 | MASE: 1.6965792
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0868408 | Vali Loss: 0.0172641 | Test Loss: 0.1345215 | Mae Loss: 0.1105264 | SMAPE: 6.9028406 | MASE: 1.7151183
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0946521 | Vali Loss: 0.0145630 | Test Loss: 0.1711051 | Mae Loss: 0.0966579 | SMAPE: 6.2519655 | MASE: 1.7348287
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0912579 | Vali Loss: 0.0146911 | Test Loss: 0.1427100 | Mae Loss: 0.0972714 | SMAPE: 6.7233434 | MASE: 1.6905924
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0713187 | Vali Loss: 0.0126009 | Test Loss: 0.1461404 | Mae Loss: 0.0890625 | SMAPE: 6.0142131 | MASE: 1.4736553
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0709247 | Vali Loss: 0.0119280 | Test Loss: 0.1372381 | Mae Loss: 0.0857485 | SMAPE: 4.6180615 | MASE: 1.3512745
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0674521 | Vali Loss: 0.0111606 | Test Loss: 0.1243684 | Mae Loss: 0.0821138 | SMAPE: 4.7256403 | MASE: 1.4129885
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0587406 | Vali Loss: 0.0113236 | Test Loss: 0.1164795 | Mae Loss: 0.0833877 | SMAPE: 4.9871635 | MASE: 1.7894871
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0577996 | Vali Loss: 0.0104042 | Test Loss: 0.1124757 | Mae Loss: 0.0789306 | SMAPE: 5.5383844 | MASE: 1.3982116
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0648032 | Vali Loss: 0.0109801 | Test Loss: 0.1104715 | Mae Loss: 0.0815786 | SMAPE: 4.3894691 | MASE: 1.4931061
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1837348 | Vali Loss: 0.0580328 | Test Loss: 0.2625803 | Mae Loss: 0.2022853 | SMAPE: 12.4703541 | MASE: 3.4279752
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1592290 | Vali Loss: 0.0273260 | Test Loss: 0.4205712 | Mae Loss: 0.1399500 | SMAPE: 7.9621286 | MASE: 2.8235831
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.1232953 | Vali Loss: 0.0258990 | Test Loss: 0.3600292 | Mae Loss: 0.1365558 | SMAPE: 7.3864450 | MASE: 2.4370990
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.1257034 | Vali Loss: 0.0171543 | Test Loss: 0.3010565 | Mae Loss: 0.1024599 | SMAPE: 7.5568886 | MASE: 2.0728889
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.1190782 | Vali Loss: 0.0158843 | Test Loss: 0.2795980 | Mae Loss: 0.0936774 | SMAPE: 6.5857635 | MASE: 1.8537211
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0966996 | Vali Loss: 0.0171308 | Test Loss: 0.2731502 | Mae Loss: 0.0967022 | SMAPE: 7.1985865 | MASE: 1.9375317
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0979199 | Vali Loss: 0.0215761 | Test Loss: 0.2693393 | Mae Loss: 0.1098217 | SMAPE: 5.0606308 | MASE: 1.5260299
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0952971 | Vali Loss: 0.0188718 | Test Loss: 0.2660863 | Mae Loss: 0.1064362 | SMAPE: 6.8134217 | MASE: 2.2202525
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.1076333 | Vali Loss: 0.0116898 | Test Loss: 0.2650153 | Mae Loss: 0.0801373 | SMAPE: 6.0916791 | MASE: 1.6806879
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0933155 | Vali Loss: 0.0149017 | Test Loss: 0.2643531 | Mae Loss: 0.0894796 | SMAPE: 5.7485437 | MASE: 1.5456736
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.2903645 | Vali Loss: 0.0299247 | Test Loss: 0.7111222 | Mae Loss: 0.1483463 | SMAPE: 8.0922756 | MASE: 2.4039211
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.2394807 | Vali Loss: 0.0453003 | Test Loss: 0.5207323 | Mae Loss: 0.1711449 | SMAPE: 12.2028456 | MASE: 3.9947326
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.2120596 | Vali Loss: 0.0495311 | Test Loss: 0.5629589 | Mae Loss: 0.1794485 | SMAPE: 10.6231213 | MASE: 3.0489106
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.2061512 | Vali Loss: 0.0362682 | Test Loss: 0.5866368 | Mae Loss: 0.1507843 | SMAPE: 10.2231836 | MASE: 3.1356328
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1991775 | Vali Loss: 0.0377703 | Test Loss: 0.5264379 | Mae Loss: 0.1530979 | SMAPE: 9.0272627 | MASE: 2.3808951
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1684582 | Vali Loss: 0.0328614 | Test Loss: 0.5529249 | Mae Loss: 0.1475812 | SMAPE: 10.1033449 | MASE: 2.9426844
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.1691423 | Vali Loss: 0.0460965 | Test Loss: 0.5475272 | Mae Loss: 0.1733456 | SMAPE: 8.0369120 | MASE: 2.4434643
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1620468 | Vali Loss: 0.0457815 | Test Loss: 0.5417794 | Mae Loss: 0.1697507 | SMAPE: 10.6226883 | MASE: 3.2386694
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1580803 | Vali Loss: 0.0338840 | Test Loss: 0.5408836 | Mae Loss: 0.1443020 | SMAPE: 6.5107889 | MASE: 2.0637414
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.1549711 | Vali Loss: 0.0465422 | Test Loss: 0.5396282 | Mae Loss: 0.1803729 | SMAPE: 10.0061445 | MASE: 3.2213511
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.5550247 | Vali Loss: 0.0701509 | Test Loss: 0.7244191 | Mae Loss: 0.2192970 | SMAPE: 13.7488785 | MASE: 4.2276421
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.2863312 | Vali Loss: 0.0788904 | Test Loss: 0.7495488 | Mae Loss: 0.2401733 | SMAPE: 13.2293816 | MASE: 3.7694335
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2914445 | Vali Loss: 0.0823943 | Test Loss: 0.7182900 | Mae Loss: 0.2385118 | SMAPE: 14.6037073 | MASE: 4.7161498
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.2627095 | Vali Loss: 0.0769824 | Test Loss: 0.6967581 | Mae Loss: 0.2317686 | SMAPE: 17.3071899 | MASE: 5.2087746
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.2760163 | Vali Loss: 0.0789652 | Test Loss: 0.7029821 | Mae Loss: 0.2341308 | SMAPE: 13.3182411 | MASE: 4.1368942
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.2820100 | Vali Loss: 0.0770785 | Test Loss: 0.7117394 | Mae Loss: 0.2316809 | SMAPE: 16.6809845 | MASE: 5.0537920
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.2679725 | Vali Loss: 0.0600474 | Test Loss: 0.7273642 | Mae Loss: 0.2002584 | SMAPE: 11.5093679 | MASE: 3.5579839
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.2725701 | Vali Loss: 0.0791032 | Test Loss: 0.7327111 | Mae Loss: 0.2351513 | SMAPE: 14.1576023 | MASE: 4.2396469
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.2654813 | Vali Loss: 0.0666569 | Test Loss: 0.7329571 | Mae Loss: 0.2125584 | SMAPE: 13.5815592 | MASE: 3.8994944
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.2659399 | Vali Loss: 0.0722427 | Test Loss: 0.7328815 | Mae Loss: 0.2219422 | SMAPE: 13.9780865 | MASE: 4.4073415
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.4560649 | Vali Loss: 0.0923536 | Test Loss: 0.8791912 | Mae Loss: 0.2647926 | SMAPE: 16.4479637 | MASE: 5.0916896
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.3125050 | Vali Loss: 0.0920316 | Test Loss: 0.9029989 | Mae Loss: 0.2657623 | SMAPE: 15.5609426 | MASE: 4.6319127
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.3066761 | Vali Loss: 0.0885425 | Test Loss: 0.8344339 | Mae Loss: 0.2574635 | SMAPE: 17.4579048 | MASE: 5.1578836
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.2960404 | Vali Loss: 0.1063181 | Test Loss: 0.8538527 | Mae Loss: 0.2981910 | SMAPE: 15.4003468 | MASE: 4.8037810
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2781200 | Vali Loss: 0.0833106 | Test Loss: 0.8816864 | Mae Loss: 0.2511612 | SMAPE: 14.6773252 | MASE: 4.7265115
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.2813107 | Vali Loss: 0.0994923 | Test Loss: 0.8703325 | Mae Loss: 0.2835652 | SMAPE: 16.6778164 | MASE: 5.1571636
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2735076 | Vali Loss: 0.0994242 | Test Loss: 0.8664938 | Mae Loss: 0.2813018 | SMAPE: 16.3451805 | MASE: 5.3599453
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.2978151 | Vali Loss: 0.0828332 | Test Loss: 0.8616633 | Mae Loss: 0.2467297 | SMAPE: 15.5049114 | MASE: 4.8173394
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.2680203 | Vali Loss: 0.1051746 | Test Loss: 0.8596110 | Mae Loss: 0.2864129 | SMAPE: 17.1261883 | MASE: 5.4000850
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.3094966 | Vali Loss: 0.0944072 | Test Loss: 0.8589725 | Mae Loss: 0.2734776 | SMAPE: 16.7523155 | MASE: 5.5582433
