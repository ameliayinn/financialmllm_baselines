seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0434172 | Vali Loss: 0.0650197 | Test Loss: 0.0954139 | Mae Loss: 0.2183486 | SMAPE: 26.7261124 | MASE: 3.2333927
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0422854 | Vali Loss: 0.1161792 | Test Loss: 0.1635275 | Mae Loss: 0.2820708 | SMAPE: 28.3939800 | MASE: 2.7361915
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0430329 | Vali Loss: 0.0800820 | Test Loss: 0.1189372 | Mae Loss: 0.2349852 | SMAPE: 21.4269199 | MASE: 1.9569471
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0416209 | Vali Loss: 0.0867273 | Test Loss: 0.1176921 | Mae Loss: 0.2468984 | SMAPE: 34.9841309 | MASE: 3.6018913
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0360713 | Vali Loss: 0.0515828 | Test Loss: 0.0684308 | Mae Loss: 0.1946046 | SMAPE: 24.8487949 | MASE: 3.2144678
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0294435 | Vali Loss: 0.0270721 | Test Loss: 0.0338009 | Mae Loss: 0.1387691 | SMAPE: 17.9386940 | MASE: 2.5012200
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0255621 | Vali Loss: 0.0218488 | Test Loss: 0.0247676 | Mae Loss: 0.1159759 | SMAPE: 16.3302097 | MASE: 1.5162388
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0250517 | Vali Loss: 0.0199083 | Test Loss: 0.0220700 | Mae Loss: 0.1038035 | SMAPE: 19.5068588 | MASE: 2.2625246
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0259444 | Vali Loss: 0.0217686 | Test Loss: 0.0218106 | Mae Loss: 0.1131313 | SMAPE: 14.1693678 | MASE: 1.3061841
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0268926 | Vali Loss: 0.0202403 | Test Loss: 0.0217922 | Mae Loss: 0.1063751 | SMAPE: 13.2191792 | MASE: 1.8489069
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0997687 | Vali Loss: 0.1918039 | Test Loss: 0.3181342 | Mae Loss: 0.4176206 | SMAPE: 48.3358192 | MASE: 5.6537566
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0783342 | Vali Loss: 0.2315353 | Test Loss: 0.3504402 | Mae Loss: 0.4546540 | SMAPE: 52.4272690 | MASE: 6.0691166
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0675754 | Vali Loss: 0.2592546 | Test Loss: 0.3756953 | Mae Loss: 0.4873499 | SMAPE: 60.4806709 | MASE: 7.9688826
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0732695 | Vali Loss: 0.2251024 | Test Loss: 0.3675596 | Mae Loss: 0.4554609 | SMAPE: 52.5853882 | MASE: 6.0474539
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0707544 | Vali Loss: 0.2584081 | Test Loss: 0.3606604 | Mae Loss: 0.4856668 | SMAPE: 53.2128677 | MASE: 6.2031322
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0684628 | Vali Loss: 0.2274803 | Test Loss: 0.3543805 | Mae Loss: 0.4575176 | SMAPE: 53.7002144 | MASE: 6.3042908
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0640591 | Vali Loss: 0.2103421 | Test Loss: 0.3467265 | Mae Loss: 0.4349182 | SMAPE: 56.6050606 | MASE: 9.6878786
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0656785 | Vali Loss: 0.2093199 | Test Loss: 0.3419617 | Mae Loss: 0.4366109 | SMAPE: 56.2142601 | MASE: 7.5634046
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0638709 | Vali Loss: 0.2317962 | Test Loss: 0.3386353 | Mae Loss: 0.4618144 | SMAPE: 45.4345093 | MASE: 4.5935631
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0578405 | Vali Loss: 0.2121754 | Test Loss: 0.3374623 | Mae Loss: 0.4380140 | SMAPE: 47.2010918 | MASE: 5.1611638
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1507280 | Vali Loss: 0.4802180 | Test Loss: 0.5698265 | Mae Loss: 0.6670318 | SMAPE: 65.6726685 | MASE: 8.6870518
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1112377 | Vali Loss: 0.4854129 | Test Loss: 0.5601390 | Mae Loss: 0.6728919 | SMAPE: 72.5824203 | MASE: 11.8046865
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1043246 | Vali Loss: 0.3986342 | Test Loss: 0.5333529 | Mae Loss: 0.5984398 | SMAPE: 64.7708435 | MASE: 8.5701532
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1024218 | Vali Loss: 0.4419928 | Test Loss: 0.5343058 | Mae Loss: 0.6404562 | SMAPE: 66.6847076 | MASE: 9.3254366
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0932917 | Vali Loss: 0.5456656 | Test Loss: 0.5763550 | Mae Loss: 0.7180609 | SMAPE: 65.6119919 | MASE: 8.7001333
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0978195 | Vali Loss: 0.5267821 | Test Loss: 0.5609542 | Mae Loss: 0.7083818 | SMAPE: 63.4049492 | MASE: 7.5517464
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0935900 | Vali Loss: 0.4370881 | Test Loss: 0.5528610 | Mae Loss: 0.6331062 | SMAPE: 72.9326782 | MASE: 11.9378414
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1023705 | Vali Loss: 0.4723958 | Test Loss: 0.5483389 | Mae Loss: 0.6660200 | SMAPE: 65.9525986 | MASE: 8.5489883
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0944893 | Vali Loss: 0.4879163 | Test Loss: 0.5448321 | Mae Loss: 0.6769540 | SMAPE: 77.1815338 | MASE: 13.6725731
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0954072 | Vali Loss: 0.4083428 | Test Loss: 0.5433316 | Mae Loss: 0.6102393 | SMAPE: 68.0498962 | MASE: 9.0131264
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3250170 | Vali Loss: 0.4640689 | Test Loss: 0.5900084 | Mae Loss: 0.6591986 | SMAPE: 67.8082733 | MASE: 9.0581818
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1571582 | Vali Loss: 0.5916085 | Test Loss: 0.7930118 | Mae Loss: 0.7439422 | SMAPE: 73.6749039 | MASE: 10.1687450
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1333990 | Vali Loss: 0.5670987 | Test Loss: 0.7605199 | Mae Loss: 0.7270392 | SMAPE: 75.8120270 | MASE: 11.4388943
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1204933 | Vali Loss: 0.6288511 | Test Loss: 0.7624662 | Mae Loss: 0.7730722 | SMAPE: 71.3395538 | MASE: 9.8028269
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1217231 | Vali Loss: 0.6299769 | Test Loss: 0.7963385 | Mae Loss: 0.7694874 | SMAPE: 79.2040329 | MASE: 12.5242653
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1270506 | Vali Loss: 0.6070822 | Test Loss: 0.7887760 | Mae Loss: 0.7549087 | SMAPE: 70.5396500 | MASE: 9.2288132
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1306984 | Vali Loss: 0.6559798 | Test Loss: 0.7871639 | Mae Loss: 0.7919895 | SMAPE: 81.1121216 | MASE: 14.1878376
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1298151 | Vali Loss: 0.5813893 | Test Loss: 0.7869346 | Mae Loss: 0.7361111 | SMAPE: 75.0274811 | MASE: 10.8717976
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1331940 | Vali Loss: 0.6227559 | Test Loss: 0.7873471 | Mae Loss: 0.7690415 | SMAPE: 72.1554489 | MASE: 9.6479311
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1264139 | Vali Loss: 0.6160448 | Test Loss: 0.7878240 | Mae Loss: 0.7601907 | SMAPE: 75.4798355 | MASE: 11.4342098
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3987842 | Vali Loss: 0.7517569 | Test Loss: 1.0553324 | Mae Loss: 0.8486521 | SMAPE: 78.7491226 | MASE: 11.9767504
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1973023 | Vali Loss: 0.7803541 | Test Loss: 1.1477493 | Mae Loss: 0.8633342 | SMAPE: 78.7546539 | MASE: 11.4856329
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1824897 | Vali Loss: 0.8458087 | Test Loss: 1.1990168 | Mae Loss: 0.9056399 | SMAPE: 80.5441360 | MASE: 12.8228741
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1691724 | Vali Loss: 0.8639574 | Test Loss: 1.2182001 | Mae Loss: 0.9104788 | SMAPE: 86.4504089 | MASE: 15.7805023
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1722633 | Vali Loss: 0.8404756 | Test Loss: 1.2080955 | Mae Loss: 0.8991653 | SMAPE: 85.1837082 | MASE: 14.3838816
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1639701 | Vali Loss: 0.8009045 | Test Loss: 1.1904773 | Mae Loss: 0.8765553 | SMAPE: 81.8998413 | MASE: 13.2110662
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1671413 | Vali Loss: 0.8134816 | Test Loss: 1.1829579 | Mae Loss: 0.8840418 | SMAPE: 82.7312622 | MASE: 13.3968000
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1773976 | Vali Loss: 0.8257602 | Test Loss: 1.1765238 | Mae Loss: 0.8946967 | SMAPE: 82.6085434 | MASE: 13.2233391
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1773902 | Vali Loss: 0.7716466 | Test Loss: 1.1739056 | Mae Loss: 0.8581574 | SMAPE: 81.9524765 | MASE: 13.1966181
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1815941 | Vali Loss: 0.8158728 | Test Loss: 1.1729308 | Mae Loss: 0.8869534 | SMAPE: 83.4039078 | MASE: 13.6009560
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0452187 | Vali Loss: 0.0957645 | Test Loss: 0.1386319 | Mae Loss: 0.2728600 | SMAPE: 28.2871666 | MASE: 3.0570881
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0400654 | Vali Loss: 0.1024985 | Test Loss: 0.1592826 | Mae Loss: 0.2703144 | SMAPE: 32.4220810 | MASE: 2.7706950
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0423942 | Vali Loss: 0.0720880 | Test Loss: 0.1463227 | Mae Loss: 0.2192919 | SMAPE: 33.7222519 | MASE: 4.3080072
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0473163 | Vali Loss: 0.0750583 | Test Loss: 0.1446583 | Mae Loss: 0.2201149 | SMAPE: 31.3287258 | MASE: 3.2802556
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0425839 | Vali Loss: 0.0840327 | Test Loss: 0.1494466 | Mae Loss: 0.2434888 | SMAPE: 27.3623772 | MASE: 2.3211985
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0407450 | Vali Loss: 0.0908625 | Test Loss: 0.1504824 | Mae Loss: 0.2607416 | SMAPE: 27.7889462 | MASE: 2.9426320
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0419035 | Vali Loss: 0.0886952 | Test Loss: 0.1507929 | Mae Loss: 0.2472752 | SMAPE: 35.9233665 | MASE: 4.3062882
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0417063 | Vali Loss: 0.0796320 | Test Loss: 0.1503403 | Mae Loss: 0.2308243 | SMAPE: 37.6733284 | MASE: 3.6587391
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0400127 | Vali Loss: 0.0778491 | Test Loss: 0.1508408 | Mae Loss: 0.2244027 | SMAPE: 28.1772308 | MASE: 2.8048491
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0413928 | Vali Loss: 0.0965842 | Test Loss: 0.1505356 | Mae Loss: 0.2648068 | SMAPE: 25.8483353 | MASE: 3.2178245
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0397004 | Vali Loss: 0.0987983 | Test Loss: 0.1505017 | Mae Loss: 0.2698153 | SMAPE: 30.5435486 | MASE: 2.8075943
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0392826 | Vali Loss: 0.0829412 | Test Loss: 0.1504649 | Mae Loss: 0.2346749 | SMAPE: 32.3528137 | MASE: 4.0072970
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0416338 | Vali Loss: 0.0886745 | Test Loss: 0.1508677 | Mae Loss: 0.2495681 | SMAPE: 32.9976425 | MASE: 2.9639609
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0946161 | Vali Loss: 0.2433067 | Test Loss: 0.3920428 | Mae Loss: 0.4741258 | SMAPE: 61.7121696 | MASE: 9.0175343
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0788210 | Vali Loss: 0.2577429 | Test Loss: 0.4218529 | Mae Loss: 0.4833616 | SMAPE: 56.7305756 | MASE: 6.0111098
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0752526 | Vali Loss: 0.2386375 | Test Loss: 0.3840914 | Mae Loss: 0.4673645 | SMAPE: 51.5994377 | MASE: 7.3772864
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0711366 | Vali Loss: 0.2505592 | Test Loss: 0.3997427 | Mae Loss: 0.4802219 | SMAPE: 57.3338203 | MASE: 6.6027026
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0714749 | Vali Loss: 0.2400865 | Test Loss: 0.4067338 | Mae Loss: 0.4698374 | SMAPE: 48.9152031 | MASE: 5.2127180
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0711959 | Vali Loss: 0.2647210 | Test Loss: 0.4077621 | Mae Loss: 0.4958783 | SMAPE: 60.3077354 | MASE: 7.4828553
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0699949 | Vali Loss: 0.2446718 | Test Loss: 0.4088904 | Mae Loss: 0.4742055 | SMAPE: 58.0688286 | MASE: 7.6231747
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0699134 | Vali Loss: 0.2527228 | Test Loss: 0.4083541 | Mae Loss: 0.4839770 | SMAPE: 54.3329239 | MASE: 6.2421618
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0715224 | Vali Loss: 0.2480386 | Test Loss: 0.4091104 | Mae Loss: 0.4793382 | SMAPE: 52.7386665 | MASE: 6.2600350
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0710333 | Vali Loss: 0.2507409 | Test Loss: 0.4091503 | Mae Loss: 0.4803026 | SMAPE: 55.1492996 | MASE: 6.7286963
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0711927 | Vali Loss: 0.2611069 | Test Loss: 0.4092516 | Mae Loss: 0.4906103 | SMAPE: 53.6908455 | MASE: 6.4233360
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.0714171 | Vali Loss: 0.2650031 | Test Loss: 0.4093218 | Mae Loss: 0.4962182 | SMAPE: 58.3791428 | MASE: 8.3654652
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.0692817 | Vali Loss: 0.2597775 | Test Loss: 0.4088141 | Mae Loss: 0.4922707 | SMAPE: 55.4594574 | MASE: 7.0715203
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1265701 | Vali Loss: 0.5622831 | Test Loss: 0.7325198 | Mae Loss: 0.7225944 | SMAPE: 67.0357513 | MASE: 8.2995558
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1027403 | Vali Loss: 0.4423905 | Test Loss: 0.6089965 | Mae Loss: 0.6390367 | SMAPE: 74.9223862 | MASE: 14.0848618
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1010331 | Vali Loss: 0.4735747 | Test Loss: 0.6293930 | Mae Loss: 0.6613450 | SMAPE: 72.0489273 | MASE: 11.0966501
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1015693 | Vali Loss: 0.4723694 | Test Loss: 0.6559224 | Mae Loss: 0.6619717 | SMAPE: 66.5421219 | MASE: 8.4429245
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0971562 | Vali Loss: 0.4984694 | Test Loss: 0.6599680 | Mae Loss: 0.6825371 | SMAPE: 71.0966797 | MASE: 10.1123781
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0947078 | Vali Loss: 0.4850976 | Test Loss: 0.6713994 | Mae Loss: 0.6716180 | SMAPE: 66.5791779 | MASE: 8.4695396
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0962742 | Vali Loss: 0.4940918 | Test Loss: 0.6736814 | Mae Loss: 0.6770992 | SMAPE: 70.6986923 | MASE: 9.5785103
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.0940538 | Vali Loss: 0.5158704 | Test Loss: 0.6723913 | Mae Loss: 0.6952702 | SMAPE: 80.2349777 | MASE: 14.9150953
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0983678 | Vali Loss: 0.5047458 | Test Loss: 0.6705068 | Mae Loss: 0.6844834 | SMAPE: 64.8460999 | MASE: 7.9555769
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0927732 | Vali Loss: 0.4857277 | Test Loss: 0.6705416 | Mae Loss: 0.6718021 | SMAPE: 60.8752747 | MASE: 6.9071608
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.0958754 | Vali Loss: 0.5108471 | Test Loss: 0.6690217 | Mae Loss: 0.6915616 | SMAPE: 77.6318130 | MASE: 13.6075840
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 12 | Train Loss: 0.0946097 | Vali Loss: 0.4913955 | Test Loss: 0.6687508 | Mae Loss: 0.6751788 | SMAPE: 68.4960327 | MASE: 9.7236958
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2033778 | Vali Loss: 0.6283483 | Test Loss: 0.8390842 | Mae Loss: 0.7735822 | SMAPE: 72.9797745 | MASE: 10.7511053
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1345842 | Vali Loss: 0.6097072 | Test Loss: 0.9647910 | Mae Loss: 0.7539858 | SMAPE: 72.5331955 | MASE: 9.5877876
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1443063 | Vali Loss: 0.7232856 | Test Loss: 0.9404825 | Mae Loss: 0.8332986 | SMAPE: 77.5429306 | MASE: 12.4674320
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1356612 | Vali Loss: 0.6591958 | Test Loss: 0.9367209 | Mae Loss: 0.7918425 | SMAPE: 74.1917572 | MASE: 9.8864746
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1109862 | Vali Loss: 0.7106591 | Test Loss: 0.9284801 | Mae Loss: 0.8273522 | SMAPE: 85.0993958 | MASE: 15.7754631
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1249349 | Vali Loss: 0.6292846 | Test Loss: 0.9233641 | Mae Loss: 0.7706184 | SMAPE: 74.5578384 | MASE: 10.6862011
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1269912 | Vali Loss: 0.5573969 | Test Loss: 0.9261341 | Mae Loss: 0.7162704 | SMAPE: 75.2088928 | MASE: 11.0571728
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1282278 | Vali Loss: 0.6023585 | Test Loss: 0.9268663 | Mae Loss: 0.7523216 | SMAPE: 78.3039932 | MASE: 12.1963997
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1249111 | Vali Loss: 0.5998554 | Test Loss: 0.9253736 | Mae Loss: 0.7515473 | SMAPE: 75.1295395 | MASE: 10.7552853
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0434172 | Vali Loss: 0.0650197 | Test Loss: 0.0954139 | Mae Loss: 0.2183486 | SMAPE: 3.0915833 | MASE: 3.2333903
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0422854 | Vali Loss: 0.1161792 | Test Loss: 0.1635275 | Mae Loss: 0.2820708 | SMAPE: 3.8663406 | MASE: 2.7361901
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0430329 | Vali Loss: 0.0800820 | Test Loss: 0.1189372 | Mae Loss: 0.2349852 | SMAPE: 2.6372659 | MASE: 1.9569467
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0416209 | Vali Loss: 0.0867273 | Test Loss: 0.1176921 | Mae Loss: 0.2468984 | SMAPE: 4.6122956 | MASE: 3.6018889
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0360713 | Vali Loss: 0.0515828 | Test Loss: 0.0684308 | Mae Loss: 0.1946046 | SMAPE: 2.9776700 | MASE: 3.2144666
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0294435 | Vali Loss: 0.0270721 | Test Loss: 0.0338009 | Mae Loss: 0.1387691 | SMAPE: 1.9044124 | MASE: 2.5012159
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0255621 | Vali Loss: 0.0218488 | Test Loss: 0.0247676 | Mae Loss: 0.1159759 | SMAPE: 1.9324952 | MASE: 1.5162379
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0250517 | Vali Loss: 0.0199083 | Test Loss: 0.0220700 | Mae Loss: 0.1038035 | SMAPE: 2.1417394 | MASE: 2.2625229
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0259444 | Vali Loss: 0.0217686 | Test Loss: 0.0218106 | Mae Loss: 0.1131313 | SMAPE: 1.6641561 | MASE: 1.3061833
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0268926 | Vali Loss: 0.0202403 | Test Loss: 0.0217922 | Mae Loss: 0.1063751 | SMAPE: 1.2326298 | MASE: 1.8489051
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0265131 | Vali Loss: 0.0218342 | Test Loss: 0.0217444 | Mae Loss: 0.1128634 | SMAPE: 1.8529673 | MASE: 1.7172402
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0269682 | Vali Loss: 0.0201869 | Test Loss: 0.0216601 | Mae Loss: 0.1061238 | SMAPE: 1.3376352 | MASE: 1.4643275
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0235898 | Vali Loss: 0.0213825 | Test Loss: 0.0215440 | Mae Loss: 0.1104319 | SMAPE: 2.5980012 | MASE: 1.9915074
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0254176 | Vali Loss: 0.0217748 | Test Loss: 0.0215789 | Mae Loss: 0.1136884 | SMAPE: 1.7930772 | MASE: 1.9171332
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.0243466 | Vali Loss: 0.0218383 | Test Loss: 0.0216585 | Mae Loss: 0.1143418 | SMAPE: 2.1408134 | MASE: 1.6420848
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.0281153 | Vali Loss: 0.0191013 | Test Loss: 0.0215990 | Mae Loss: 0.1055230 | SMAPE: 2.6221390 | MASE: 1.6416081
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 17 | Train Loss: 0.0246737 | Vali Loss: 0.0213724 | Test Loss: 0.0215901 | Mae Loss: 0.1111625 | SMAPE: 1.3373854 | MASE: 1.7382416
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 18 | Train Loss: 0.0290213 | Vali Loss: 0.0214695 | Test Loss: 0.0216199 | Mae Loss: 0.1108875 | SMAPE: 1.8055094 | MASE: 1.5018885
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 19 | Train Loss: 0.0241802 | Vali Loss: 0.0215407 | Test Loss: 0.0216097 | Mae Loss: 0.1109030 | SMAPE: 2.4744821 | MASE: 1.6329899
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 20 | Train Loss: 0.0230448 | Vali Loss: 0.0211044 | Test Loss: 0.0216073 | Mae Loss: 0.1095815 | SMAPE: 2.0884993 | MASE: 1.6557497
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0997687 | Vali Loss: 0.1918039 | Test Loss: 0.3181342 | Mae Loss: 0.4176206 | SMAPE: 6.9719248 | MASE: 5.6537571
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0783342 | Vali Loss: 0.2315353 | Test Loss: 0.3504402 | Mae Loss: 0.4546540 | SMAPE: 7.9710779 | MASE: 6.0691090
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0675754 | Vali Loss: 0.2592546 | Test Loss: 0.3756953 | Mae Loss: 0.4873499 | SMAPE: 8.8345165 | MASE: 7.9688764
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0732695 | Vali Loss: 0.2251024 | Test Loss: 0.3675596 | Mae Loss: 0.4554609 | SMAPE: 7.3716202 | MASE: 6.0474539
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0707544 | Vali Loss: 0.2584081 | Test Loss: 0.3606604 | Mae Loss: 0.4856668 | SMAPE: 7.8691535 | MASE: 6.2031322
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0684628 | Vali Loss: 0.2274803 | Test Loss: 0.3543805 | Mae Loss: 0.4575176 | SMAPE: 7.5370660 | MASE: 6.3042893
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0640591 | Vali Loss: 0.2103421 | Test Loss: 0.3467265 | Mae Loss: 0.4349182 | SMAPE: 7.4984865 | MASE: 9.6878719
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0656785 | Vali Loss: 0.2093199 | Test Loss: 0.3419617 | Mae Loss: 0.4366109 | SMAPE: 8.2627974 | MASE: 7.5633960
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0638709 | Vali Loss: 0.2317962 | Test Loss: 0.3386353 | Mae Loss: 0.4618144 | SMAPE: 7.1269045 | MASE: 4.5935612
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0578405 | Vali Loss: 0.2121754 | Test Loss: 0.3374623 | Mae Loss: 0.4380140 | SMAPE: 7.0105023 | MASE: 5.1611657
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0647222 | Vali Loss: 0.2093118 | Test Loss: 0.3365780 | Mae Loss: 0.4337274 | SMAPE: 7.3017468 | MASE: 5.0700793
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1507280 | Vali Loss: 0.4802180 | Test Loss: 0.5698265 | Mae Loss: 0.6670318 | SMAPE: 10.7376966 | MASE: 8.6870508
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1112377 | Vali Loss: 0.4854129 | Test Loss: 0.5601390 | Mae Loss: 0.6728919 | SMAPE: 11.5814476 | MASE: 11.8046827
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1043246 | Vali Loss: 0.3986342 | Test Loss: 0.5333529 | Mae Loss: 0.5984398 | SMAPE: 10.4358625 | MASE: 8.5701513
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1024218 | Vali Loss: 0.4419928 | Test Loss: 0.5343058 | Mae Loss: 0.6404562 | SMAPE: 11.0291653 | MASE: 9.3254261
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0932917 | Vali Loss: 0.5456656 | Test Loss: 0.5763550 | Mae Loss: 0.7180609 | SMAPE: 10.5988894 | MASE: 8.7001305
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0978195 | Vali Loss: 0.5267821 | Test Loss: 0.5609542 | Mae Loss: 0.7083818 | SMAPE: 10.5141249 | MASE: 7.5517449
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0935900 | Vali Loss: 0.4370881 | Test Loss: 0.5528610 | Mae Loss: 0.6331062 | SMAPE: 11.7362804 | MASE: 11.9378319
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1023705 | Vali Loss: 0.4723958 | Test Loss: 0.5483389 | Mae Loss: 0.6660200 | SMAPE: 11.0106668 | MASE: 8.5489817
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0944893 | Vali Loss: 0.4879163 | Test Loss: 0.5448321 | Mae Loss: 0.6769540 | SMAPE: 12.1451960 | MASE: 13.6725664
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0954072 | Vali Loss: 0.4083428 | Test Loss: 0.5433316 | Mae Loss: 0.6102393 | SMAPE: 11.1201391 | MASE: 9.0131197
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.0923339 | Vali Loss: 0.4759988 | Test Loss: 0.5419729 | Mae Loss: 0.6694024 | SMAPE: 12.0898113 | MASE: 12.6144753
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 12 | Train Loss: 0.0897722 | Vali Loss: 0.5080068 | Test Loss: 0.5413189 | Mae Loss: 0.6899389 | SMAPE: 10.9319258 | MASE: 8.8515139
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 13 | Train Loss: 0.0937554 | Vali Loss: 0.4511849 | Test Loss: 0.5412862 | Mae Loss: 0.6505718 | SMAPE: 11.2424173 | MASE: 10.0102978
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3250170 | Vali Loss: 0.4640689 | Test Loss: 0.5900084 | Mae Loss: 0.6591986 | SMAPE: 11.0188284 | MASE: 9.0581789
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1571582 | Vali Loss: 0.5916085 | Test Loss: 0.7930118 | Mae Loss: 0.7439422 | SMAPE: 12.8821154 | MASE: 10.1687441
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1333990 | Vali Loss: 0.5670987 | Test Loss: 0.7605199 | Mae Loss: 0.7270392 | SMAPE: 12.8905983 | MASE: 11.4388866
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1204933 | Vali Loss: 0.6288511 | Test Loss: 0.7624662 | Mae Loss: 0.7730722 | SMAPE: 12.3231773 | MASE: 9.8028212
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1217231 | Vali Loss: 0.6299769 | Test Loss: 0.7963385 | Mae Loss: 0.7694874 | SMAPE: 13.7139845 | MASE: 12.5242567
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1270506 | Vali Loss: 0.6070822 | Test Loss: 0.7887760 | Mae Loss: 0.7549087 | SMAPE: 12.2749119 | MASE: 9.2288074
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1306984 | Vali Loss: 0.6559798 | Test Loss: 0.7871639 | Mae Loss: 0.7919895 | SMAPE: 13.8077679 | MASE: 14.1878328
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1298151 | Vali Loss: 0.5813893 | Test Loss: 0.7869346 | Mae Loss: 0.7361111 | SMAPE: 12.9717913 | MASE: 10.8717890
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1331940 | Vali Loss: 0.6227559 | Test Loss: 0.7873471 | Mae Loss: 0.7690415 | SMAPE: 12.5848160 | MASE: 9.6479254
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1264139 | Vali Loss: 0.6160448 | Test Loss: 0.7878240 | Mae Loss: 0.7601907 | SMAPE: 13.1228905 | MASE: 11.4342031
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.1362007 | Vali Loss: 0.6442814 | Test Loss: 0.7879960 | Mae Loss: 0.7822083 | SMAPE: 12.9912395 | MASE: 10.7177916
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3987842 | Vali Loss: 0.7517569 | Test Loss: 1.0553324 | Mae Loss: 0.8486521 | SMAPE: 14.0104084 | MASE: 11.9767418
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1973023 | Vali Loss: 0.7803541 | Test Loss: 1.1477493 | Mae Loss: 0.8633342 | SMAPE: 14.5731792 | MASE: 11.4856234
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1824897 | Vali Loss: 0.8458087 | Test Loss: 1.1990168 | Mae Loss: 0.9056399 | SMAPE: 14.7914753 | MASE: 12.8228683
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1691724 | Vali Loss: 0.8639574 | Test Loss: 1.2182001 | Mae Loss: 0.9104788 | SMAPE: 15.7395687 | MASE: 15.7804918
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1722633 | Vali Loss: 0.8404756 | Test Loss: 1.2080955 | Mae Loss: 0.8991653 | SMAPE: 15.7127991 | MASE: 14.3838701
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1639701 | Vali Loss: 0.8009045 | Test Loss: 1.1904773 | Mae Loss: 0.8765553 | SMAPE: 15.0348234 | MASE: 13.2110529
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1671413 | Vali Loss: 0.8134816 | Test Loss: 1.1829579 | Mae Loss: 0.8840418 | SMAPE: 15.2557583 | MASE: 13.3967896
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1773976 | Vali Loss: 0.8257602 | Test Loss: 1.1765238 | Mae Loss: 0.8946967 | SMAPE: 15.1784744 | MASE: 13.2233286
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1773902 | Vali Loss: 0.7716466 | Test Loss: 1.1739056 | Mae Loss: 0.8581574 | SMAPE: 15.0898752 | MASE: 13.1966076
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1815941 | Vali Loss: 0.8158728 | Test Loss: 1.1729308 | Mae Loss: 0.8869534 | SMAPE: 15.4178410 | MASE: 13.6009426
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.1678530 | Vali Loss: 0.8023711 | Test Loss: 1.1719024 | Mae Loss: 0.8777840 | SMAPE: 15.4917583 | MASE: 14.2065220
