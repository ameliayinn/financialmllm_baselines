seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.3841305 | Vali Loss: 0.3444517 | Test Loss: 0.3789036 | Mae Loss: 0.4929559 | SMAPE: 26.0520897 | MASE: 2.6977472
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.3527490 | Vali Loss: 0.1765302 | Test Loss: 0.3338122 | Mae Loss: 0.3396643 | SMAPE: 27.7397385 | MASE: 1.7291437
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.2948900 | Vali Loss: 0.2004691 | Test Loss: 0.2259364 | Mae Loss: 0.3817753 | SMAPE: 20.1325035 | MASE: 2.0628316
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.2636245 | Vali Loss: 0.1922058 | Test Loss: 0.2144183 | Mae Loss: 0.3724981 | SMAPE: 25.9823532 | MASE: 1.9948249
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.2659153 | Vali Loss: 0.2233324 | Test Loss: 0.2019348 | Mae Loss: 0.4093812 | SMAPE: 26.9838753 | MASE: 2.0669010
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.2499865 | Vali Loss: 0.2389663 | Test Loss: 0.2037585 | Mae Loss: 0.4263404 | SMAPE: 26.5218620 | MASE: 2.0529053
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.2412713 | Vali Loss: 0.2187141 | Test Loss: 0.2052528 | Mae Loss: 0.4004196 | SMAPE: 21.1215305 | MASE: 2.0842404
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.2426462 | Vali Loss: 0.2320949 | Test Loss: 0.2045011 | Mae Loss: 0.4169329 | SMAPE: 25.6191425 | MASE: 2.6968894
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.2288729 | Vali Loss: 0.2138112 | Test Loss: 0.2032557 | Mae Loss: 0.3948697 | SMAPE: 26.6893387 | MASE: 2.1253769
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.2397323 | Vali Loss: 0.2167966 | Test Loss: 0.2031191 | Mae Loss: 0.4044535 | SMAPE: 22.1407852 | MASE: 2.0104241
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.6032206 | Vali Loss: 1.1704903 | Test Loss: 0.4830701 | Mae Loss: 0.9428713 | SMAPE: 64.9113922 | MASE: 5.1221642
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.5508306 | Vali Loss: 1.0466709 | Test Loss: 0.5623253 | Mae Loss: 0.8850881 | SMAPE: 66.9922791 | MASE: 5.3687224
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.5084219 | Vali Loss: 0.9793994 | Test Loss: 0.4728178 | Mae Loss: 0.8435720 | SMAPE: 56.0360718 | MASE: 5.1889067
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.4413457 | Vali Loss: 0.5854208 | Test Loss: 0.3598672 | Mae Loss: 0.6382191 | SMAPE: 38.9691658 | MASE: 3.3624921
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.3876014 | Vali Loss: 0.7039379 | Test Loss: 0.2952016 | Mae Loss: 0.7599568 | SMAPE: 37.1177444 | MASE: 3.4410770
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.3554395 | Vali Loss: 0.4769163 | Test Loss: 0.2758059 | Mae Loss: 0.5743647 | SMAPE: 41.9317856 | MASE: 3.5167065
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.3582790 | Vali Loss: 0.4536894 | Test Loss: 0.2634038 | Mae Loss: 0.5728616 | SMAPE: 26.8888893 | MASE: 3.0233965
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.3416934 | Vali Loss: 0.4302462 | Test Loss: 0.2593139 | Mae Loss: 0.5409476 | SMAPE: 49.2714958 | MASE: 4.4213877
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.3240135 | Vali Loss: 0.4714690 | Test Loss: 0.2560646 | Mae Loss: 0.5943840 | SMAPE: 43.7627563 | MASE: 3.1405306
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.3254859 | Vali Loss: 0.4392438 | Test Loss: 0.2545355 | Mae Loss: 0.5677508 | SMAPE: 33.6957932 | MASE: 2.7594266
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.7783092 | Vali Loss: 1.7079818 | Test Loss: 0.7175632 | Mae Loss: 1.1411737 | SMAPE: 56.5352974 | MASE: 5.5483050
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.5886634 | Vali Loss: 1.8605453 | Test Loss: 0.6369663 | Mae Loss: 1.2153721 | SMAPE: 83.0275574 | MASE: 8.0361519
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.5646507 | Vali Loss: 1.3322892 | Test Loss: 0.5666078 | Mae Loss: 0.9911805 | SMAPE: 58.2389526 | MASE: 5.7722311
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.4859788 | Vali Loss: 1.2165208 | Test Loss: 0.4275317 | Mae Loss: 0.9431722 | SMAPE: 61.5983238 | MASE: 5.4429927
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.4542575 | Vali Loss: 1.4962763 | Test Loss: 0.3885635 | Mae Loss: 1.0757936 | SMAPE: 41.7670097 | MASE: 3.9136708
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.4263860 | Vali Loss: 1.3695166 | Test Loss: 0.3789866 | Mae Loss: 1.0208317 | SMAPE: 47.8686142 | MASE: 4.3722634
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.4231358 | Vali Loss: 1.0317754 | Test Loss: 0.3884471 | Mae Loss: 0.8481278 | SMAPE: 47.0520897 | MASE: 4.5741773
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.4369543 | Vali Loss: 1.1001955 | Test Loss: 0.3861501 | Mae Loss: 0.9228938 | SMAPE: 55.1121521 | MASE: 4.7522197
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.4185548 | Vali Loss: 1.0908247 | Test Loss: 0.3812908 | Mae Loss: 0.8874109 | SMAPE: 45.5222740 | MASE: 4.9454975
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.4195556 | Vali Loss: 0.9354284 | Test Loss: 0.3793093 | Mae Loss: 0.8015102 | SMAPE: 57.4451370 | MASE: 5.2785697
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.7011578 | Vali Loss: 2.3419256 | Test Loss: 0.6316550 | Mae Loss: 1.4058750 | SMAPE: 75.9543457 | MASE: 7.3605094
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.6133340 | Vali Loss: 1.9938498 | Test Loss: 0.6255244 | Mae Loss: 1.2669270 | SMAPE: 67.2325363 | MASE: 6.6825900
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.6153988 | Vali Loss: 1.6181554 | Test Loss: 0.6299672 | Mae Loss: 1.1196992 | SMAPE: 69.7517395 | MASE: 6.8856449
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.6024001 | Vali Loss: 1.7463770 | Test Loss: 0.6092410 | Mae Loss: 1.2164125 | SMAPE: 64.5250092 | MASE: 6.1212139
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.5572223 | Vali Loss: 1.4481004 | Test Loss: 0.6239128 | Mae Loss: 1.0792391 | SMAPE: 60.2931519 | MASE: 6.1642413
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.5348543 | Vali Loss: 1.4306695 | Test Loss: 0.5924157 | Mae Loss: 1.0580184 | SMAPE: 60.4238281 | MASE: 5.6485271
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.5497120 | Vali Loss: 1.6196517 | Test Loss: 0.5869525 | Mae Loss: 1.1683820 | SMAPE: 62.6509018 | MASE: 6.9929094
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.5322049 | Vali Loss: 1.2931050 | Test Loss: 0.5853592 | Mae Loss: 0.9986404 | SMAPE: 59.0410347 | MASE: 5.8790884
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.5256150 | Vali Loss: 1.3878030 | Test Loss: 0.5840942 | Mae Loss: 1.0575669 | SMAPE: 55.8512802 | MASE: 5.6031055
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.5347212 | Vali Loss: 1.3487759 | Test Loss: 0.5840925 | Mae Loss: 1.0479358 | SMAPE: 58.6513214 | MASE: 5.8684940
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.9078337 | Vali Loss: 3.0911787 | Test Loss: 1.3642497 | Mae Loss: 1.5712508 | SMAPE: 93.8424683 | MASE: 7.7855911
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.8516901 | Vali Loss: 1.9862199 | Test Loss: 0.5170553 | Mae Loss: 1.2944170 | SMAPE: 66.1961823 | MASE: 6.2556758
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.5766435 | Vali Loss: 1.6481768 | Test Loss: 0.6162010 | Mae Loss: 1.1920067 | SMAPE: 59.2064438 | MASE: 6.1415143
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.5935668 | Vali Loss: 1.8546623 | Test Loss: 0.5483919 | Mae Loss: 1.2642083 | SMAPE: 66.8857269 | MASE: 7.1234360
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.5777059 | Vali Loss: 1.8048302 | Test Loss: 0.5305689 | Mae Loss: 1.2367013 | SMAPE: 65.5410004 | MASE: 6.7407126
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.5836173 | Vali Loss: 1.7198249 | Test Loss: 0.5253664 | Mae Loss: 1.1839181 | SMAPE: 65.3306503 | MASE: 6.5404305
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.5857129 | Vali Loss: 1.7627040 | Test Loss: 0.5260953 | Mae Loss: 1.2157271 | SMAPE: 64.9757690 | MASE: 6.6418314
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.5585505 | Vali Loss: 1.8269578 | Test Loss: 0.5259076 | Mae Loss: 1.2577525 | SMAPE: 62.4990692 | MASE: 6.4315166
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.5910139 | Vali Loss: 1.5490204 | Test Loss: 0.5274287 | Mae Loss: 1.1150539 | SMAPE: 63.5156822 | MASE: 6.3913445
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.5807649 | Vali Loss: 1.8133098 | Test Loss: 0.5279035 | Mae Loss: 1.2397411 | SMAPE: 63.1915169 | MASE: 6.5025177
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.4131252 | Vali Loss: 0.3495269 | Test Loss: 0.3183947 | Mae Loss: 0.5169195 | SMAPE: 27.8145847 | MASE: 2.5451155
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.3590780 | Vali Loss: 0.8084308 | Test Loss: 0.2403991 | Mae Loss: 0.7756724 | SMAPE: 68.8665237 | MASE: 4.5347557
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.3746773 | Vali Loss: 0.4993705 | Test Loss: 0.2512147 | Mae Loss: 0.5727013 | SMAPE: 30.9963951 | MASE: 2.8056531
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.3540230 | Vali Loss: 0.5557459 | Test Loss: 0.2608012 | Mae Loss: 0.6164317 | SMAPE: 29.6735764 | MASE: 2.8264058
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.3516465 | Vali Loss: 0.4577385 | Test Loss: 0.2656163 | Mae Loss: 0.5478586 | SMAPE: 37.9260521 | MASE: 2.8091712
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.3497830 | Vali Loss: 0.4594341 | Test Loss: 0.2674462 | Mae Loss: 0.5569346 | SMAPE: 30.6148796 | MASE: 2.5668430
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.3524243 | Vali Loss: 0.5081727 | Test Loss: 0.2681931 | Mae Loss: 0.5801062 | SMAPE: 39.3735313 | MASE: 3.2595401
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.3529047 | Vali Loss: 0.3981210 | Test Loss: 0.2683663 | Mae Loss: 0.5068984 | SMAPE: 49.7318077 | MASE: 3.4379816
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.3529335 | Vali Loss: 0.3821455 | Test Loss: 0.2679898 | Mae Loss: 0.4931560 | SMAPE: 33.4007568 | MASE: 2.7448204
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.3492234 | Vali Loss: 0.5002328 | Test Loss: 0.2680308 | Mae Loss: 0.5974577 | SMAPE: 32.0736046 | MASE: 2.7951794
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.3531370 | Vali Loss: 0.5105757 | Test Loss: 0.2685832 | Mae Loss: 0.6013000 | SMAPE: 38.8526306 | MASE: 3.4335511
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.6389600 | Vali Loss: 0.9066937 | Test Loss: 0.5905536 | Mae Loss: 0.8093430 | SMAPE: 56.4160271 | MASE: 5.9124904
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.5330311 | Vali Loss: 1.1868441 | Test Loss: 0.5248928 | Mae Loss: 0.9537948 | SMAPE: 74.8928452 | MASE: 5.9591794
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.5246635 | Vali Loss: 1.1618137 | Test Loss: 0.5295603 | Mae Loss: 0.9540294 | SMAPE: 51.1623306 | MASE: 4.8130407
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.5015872 | Vali Loss: 1.1005268 | Test Loss: 0.5362138 | Mae Loss: 0.9257593 | SMAPE: 50.9352684 | MASE: 4.3323178
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.4933514 | Vali Loss: 0.9022170 | Test Loss: 0.5351551 | Mae Loss: 0.8173666 | SMAPE: 50.5614471 | MASE: 3.7443972
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.5174213 | Vali Loss: 1.0928750 | Test Loss: 0.5357435 | Mae Loss: 0.9253739 | SMAPE: 58.9574623 | MASE: 4.9404140
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.5049131 | Vali Loss: 0.9462999 | Test Loss: 0.5336702 | Mae Loss: 0.8340183 | SMAPE: 56.7670593 | MASE: 5.7665195
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.5170994 | Vali Loss: 0.9946598 | Test Loss: 0.5332220 | Mae Loss: 0.8575667 | SMAPE: 53.8949013 | MASE: 4.5283289
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.5137662 | Vali Loss: 0.9550989 | Test Loss: 0.5338217 | Mae Loss: 0.8369131 | SMAPE: 58.9680023 | MASE: 5.1290841
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.5210962 | Vali Loss: 1.0388917 | Test Loss: 0.5343057 | Mae Loss: 0.8913862 | SMAPE: 46.3005638 | MASE: 3.8522024
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.4994436 | Vali Loss: 1.1121020 | Test Loss: 0.5324924 | Mae Loss: 0.9174083 | SMAPE: 62.8730965 | MASE: 5.3050904
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.5130233 | Vali Loss: 1.1539190 | Test Loss: 0.5325380 | Mae Loss: 0.9505732 | SMAPE: 49.3091393 | MASE: 5.4176235
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.5063724 | Vali Loss: 1.0719984 | Test Loss: 0.5326091 | Mae Loss: 0.8988531 | SMAPE: 64.9636002 | MASE: 6.0749760
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 14 | Train Loss: 0.5046358 | Vali Loss: 1.0108246 | Test Loss: 0.5333976 | Mae Loss: 0.8723772 | SMAPE: 63.9861526 | MASE: 4.8798847
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 15 | Train Loss: 0.5101517 | Vali Loss: 1.0283450 | Test Loss: 0.5328327 | Mae Loss: 0.8871412 | SMAPE: 57.0916367 | MASE: 5.4406714
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.6121654 | Vali Loss: 1.5202377 | Test Loss: 0.8152539 | Mae Loss: 1.0861127 | SMAPE: 57.6171036 | MASE: 5.1966891
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.6170523 | Vali Loss: 1.8480905 | Test Loss: 0.7028791 | Mae Loss: 1.2228903 | SMAPE: 72.6784286 | MASE: 7.6189857
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.5717888 | Vali Loss: 1.9230267 | Test Loss: 0.6987974 | Mae Loss: 1.2557408 | SMAPE: 73.5036469 | MASE: 7.3128181
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.5642973 | Vali Loss: 1.7272539 | Test Loss: 0.7065597 | Mae Loss: 1.1830619 | SMAPE: 64.1241760 | MASE: 6.3473988
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.5731234 | Vali Loss: 1.8809000 | Test Loss: 0.6993634 | Mae Loss: 1.2408309 | SMAPE: 68.1347046 | MASE: 5.9543519
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.5656823 | Vali Loss: 1.7496425 | Test Loss: 0.7003833 | Mae Loss: 1.1934656 | SMAPE: 76.1590958 | MASE: 6.2836666
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.5622646 | Vali Loss: 1.7828717 | Test Loss: 0.7001847 | Mae Loss: 1.2035636 | SMAPE: 79.2538147 | MASE: 6.9289689
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.5677214 | Vali Loss: 1.9319463 | Test Loss: 0.6982330 | Mae Loss: 1.2739691 | SMAPE: 72.4644928 | MASE: 7.7302341
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.5679548 | Vali Loss: 1.9037482 | Test Loss: 0.6981528 | Mae Loss: 1.2495565 | SMAPE: 58.0349808 | MASE: 5.7025037
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.5622537 | Vali Loss: 1.7738163 | Test Loss: 0.6968547 | Mae Loss: 1.2017642 | SMAPE: 63.3755989 | MASE: 5.4727407
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.5657750 | Vali Loss: 1.9000874 | Test Loss: 0.6983282 | Mae Loss: 1.2506968 | SMAPE: 73.2818298 | MASE: 7.3052931
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.7087837 | Vali Loss: 2.2942598 | Test Loss: 0.7058818 | Mae Loss: 1.3986024 | SMAPE: 73.2148819 | MASE: 6.6090565
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.6190274 | Vali Loss: 1.4666668 | Test Loss: 0.7189706 | Mae Loss: 1.0593406 | SMAPE: 61.5350723 | MASE: 5.6593852
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.5883217 | Vali Loss: 2.0864213 | Test Loss: 0.6700823 | Mae Loss: 1.3287379 | SMAPE: 70.2201157 | MASE: 6.7646155
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.5991420 | Vali Loss: 1.8134632 | Test Loss: 0.6691684 | Mae Loss: 1.2355446 | SMAPE: 61.2480087 | MASE: 5.6811318
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.5870477 | Vali Loss: 2.0764196 | Test Loss: 0.6634712 | Mae Loss: 1.3592454 | SMAPE: 71.8780746 | MASE: 8.0286732
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.5723817 | Vali Loss: 1.8557701 | Test Loss: 0.6611369 | Mae Loss: 1.2362701 | SMAPE: 66.9078979 | MASE: 6.5711732
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.5849199 | Vali Loss: 1.6353997 | Test Loss: 0.6602795 | Mae Loss: 1.1053234 | SMAPE: 65.2763977 | MASE: 6.3330750
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.5852789 | Vali Loss: 1.7653922 | Test Loss: 0.6629694 | Mae Loss: 1.2033557 | SMAPE: 67.4504929 | MASE: 7.0093498
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.5811084 | Vali Loss: 1.7787476 | Test Loss: 0.6610569 | Mae Loss: 1.1841460 | SMAPE: 69.8510132 | MASE: 6.6817279
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.5724607 | Vali Loss: 2.1350513 | Test Loss: 0.6617594 | Mae Loss: 1.3985964 | SMAPE: 68.2270889 | MASE: 7.3053384
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.5730491 | Vali Loss: 1.9300846 | Test Loss: 0.6626175 | Mae Loss: 1.2831217 | SMAPE: 66.7897949 | MASE: 6.1368189
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.5655933 | Vali Loss: 1.9938793 | Test Loss: 0.6630225 | Mae Loss: 1.2890139 | SMAPE: 69.2295990 | MASE: 6.6218586
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.7111778 | Vali Loss: 2.0584064 | Test Loss: 0.5950466 | Mae Loss: 1.3037398 | SMAPE: 67.6639404 | MASE: 6.6565638
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.6434008 | Vali Loss: 1.4701669 | Test Loss: 0.6568083 | Mae Loss: 1.0652945 | SMAPE: 63.5487251 | MASE: 6.5991492
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.5943141 | Vali Loss: 1.6516623 | Test Loss: 0.6078812 | Mae Loss: 1.1723604 | SMAPE: 61.1976089 | MASE: 6.0946455
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.5727187 | Vali Loss: 1.8075050 | Test Loss: 0.6017873 | Mae Loss: 1.2381636 | SMAPE: 63.6586533 | MASE: 6.7572608
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.5907528 | Vali Loss: 1.7230906 | Test Loss: 0.5959028 | Mae Loss: 1.1955416 | SMAPE: 60.5933266 | MASE: 5.9971294
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.6009076 | Vali Loss: 1.6193951 | Test Loss: 0.5957918 | Mae Loss: 1.1437889 | SMAPE: 60.5520668 | MASE: 6.0110312
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.5898053 | Vali Loss: 1.8788133 | Test Loss: 0.5940802 | Mae Loss: 1.2775078 | SMAPE: 62.9824867 | MASE: 6.7002268
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.5881117 | Vali Loss: 1.7557739 | Test Loss: 0.5926392 | Mae Loss: 1.2232955 | SMAPE: 62.0233612 | MASE: 6.2892523
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.5917038 | Vali Loss: 1.5062345 | Test Loss: 0.5920379 | Mae Loss: 1.0897694 | SMAPE: 63.7024879 | MASE: 6.8833928
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.5845224 | Vali Loss: 1.8021221 | Test Loss: 0.5927063 | Mae Loss: 1.2216941 | SMAPE: 63.6748238 | MASE: 6.3812838
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.5783740 | Vali Loss: 1.8239654 | Test Loss: 0.5923115 | Mae Loss: 1.2384725 | SMAPE: 65.0512238 | MASE: 6.8157196
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.5900216 | Vali Loss: 1.5824871 | Test Loss: 0.5909276 | Mae Loss: 1.1307484 | SMAPE: 63.8977165 | MASE: 6.4313474
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.3841305 | Vali Loss: 0.3444517 | Test Loss: 0.3789036 | Mae Loss: 0.4929559 | SMAPE: 1.6784840 | MASE: 2.6977477
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.3527490 | Vali Loss: 0.1765302 | Test Loss: 0.3338122 | Mae Loss: 0.3396643 | SMAPE: 1.4168310 | MASE: 1.7291440
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.2948900 | Vali Loss: 0.2004691 | Test Loss: 0.2259364 | Mae Loss: 0.3817753 | SMAPE: 1.1974264 | MASE: 2.0628374
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.2636245 | Vali Loss: 0.1922058 | Test Loss: 0.2144183 | Mae Loss: 0.3724981 | SMAPE: 1.4511086 | MASE: 1.9948238
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.2659153 | Vali Loss: 0.2233324 | Test Loss: 0.2019348 | Mae Loss: 0.4093812 | SMAPE: 1.3078887 | MASE: 2.0669017
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.2499865 | Vali Loss: 0.2389663 | Test Loss: 0.2037585 | Mae Loss: 0.4263404 | SMAPE: 1.2038326 | MASE: 2.0529041
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.2412713 | Vali Loss: 0.2187141 | Test Loss: 0.2052528 | Mae Loss: 0.4004196 | SMAPE: 1.3164427 | MASE: 2.0842431
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.2426462 | Vali Loss: 0.2320949 | Test Loss: 0.2045011 | Mae Loss: 0.4169329 | SMAPE: 1.6171836 | MASE: 2.6968906
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.2288729 | Vali Loss: 0.2138112 | Test Loss: 0.2032557 | Mae Loss: 0.3948697 | SMAPE: 1.4513564 | MASE: 2.1253750
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.2397323 | Vali Loss: 0.2167966 | Test Loss: 0.2031191 | Mae Loss: 0.4044535 | SMAPE: 1.3353516 | MASE: 2.0104229
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.2400021 | Vali Loss: 0.2239973 | Test Loss: 0.2033555 | Mae Loss: 0.4025363 | SMAPE: 1.5281602 | MASE: 1.9591001
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.2318242 | Vali Loss: 0.2302773 | Test Loss: 0.2030163 | Mae Loss: 0.4145961 | SMAPE: 1.0722831 | MASE: 1.6937624
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.6032206 | Vali Loss: 1.1704903 | Test Loss: 0.4830701 | Mae Loss: 0.9428713 | SMAPE: 3.4185081 | MASE: 5.1221747
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.5508306 | Vali Loss: 1.0466709 | Test Loss: 0.5623253 | Mae Loss: 0.8850881 | SMAPE: 3.7755191 | MASE: 5.3687348
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.5084219 | Vali Loss: 0.9793994 | Test Loss: 0.4728178 | Mae Loss: 0.8435720 | SMAPE: 3.5222795 | MASE: 5.1889129
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.4413457 | Vali Loss: 0.5854208 | Test Loss: 0.3598672 | Mae Loss: 0.6382191 | SMAPE: 2.3603940 | MASE: 3.3624959
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.3876014 | Vali Loss: 0.7039379 | Test Loss: 0.2952016 | Mae Loss: 0.7599568 | SMAPE: 2.2323895 | MASE: 3.4410791
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.3554395 | Vali Loss: 0.4769163 | Test Loss: 0.2758059 | Mae Loss: 0.5743647 | SMAPE: 2.4899244 | MASE: 3.5167069
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.3582790 | Vali Loss: 0.4536894 | Test Loss: 0.2634038 | Mae Loss: 0.5728616 | SMAPE: 1.9380758 | MASE: 3.0233970
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.3416934 | Vali Loss: 0.4302462 | Test Loss: 0.2593139 | Mae Loss: 0.5409476 | SMAPE: 3.0018239 | MASE: 4.4213891
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.3240135 | Vali Loss: 0.4714690 | Test Loss: 0.2560646 | Mae Loss: 0.5943840 | SMAPE: 2.2194214 | MASE: 3.1405349
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.3254859 | Vali Loss: 0.4392438 | Test Loss: 0.2545355 | Mae Loss: 0.5677508 | SMAPE: 1.7866260 | MASE: 2.7594328
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.3330267 | Vali Loss: 0.4331102 | Test Loss: 0.2535838 | Mae Loss: 0.5613992 | SMAPE: 2.0218856 | MASE: 2.9812558
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.3487951 | Vali Loss: 0.5347115 | Test Loss: 0.2531153 | Mae Loss: 0.6144487 | SMAPE: 1.9911060 | MASE: 2.9534464
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.3290665 | Vali Loss: 0.4544664 | Test Loss: 0.2532225 | Mae Loss: 0.5734946 | SMAPE: 2.3231215 | MASE: 3.7531912
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 14 | Train Loss: 0.3173164 | Vali Loss: 0.5994350 | Test Loss: 0.2532647 | Mae Loss: 0.6842279 | SMAPE: 2.3460903 | MASE: 3.5876026
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 15 | Train Loss: 0.3340612 | Vali Loss: 0.4816641 | Test Loss: 0.2524678 | Mae Loss: 0.5948891 | SMAPE: 2.3346708 | MASE: 3.5732427
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 16 | Train Loss: 0.3314539 | Vali Loss: 0.3539957 | Test Loss: 0.2531799 | Mae Loss: 0.4911125 | SMAPE: 2.4579132 | MASE: 3.6947730
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 17 | Train Loss: 0.3248577 | Vali Loss: 0.4451451 | Test Loss: 0.2532664 | Mae Loss: 0.5658379 | SMAPE: 2.7473593 | MASE: 3.7244580
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 18 | Train Loss: 0.3323077 | Vali Loss: 0.3896765 | Test Loss: 0.2532805 | Mae Loss: 0.5310332 | SMAPE: 1.9498566 | MASE: 2.8487639
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 19 | Train Loss: 0.3387143 | Vali Loss: 0.5305432 | Test Loss: 0.2530056 | Mae Loss: 0.6261367 | SMAPE: 2.4646988 | MASE: 3.6975868
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 20 | Train Loss: 0.3355445 | Vali Loss: 0.5079128 | Test Loss: 0.2529597 | Mae Loss: 0.5909153 | SMAPE: 2.0912440 | MASE: 3.0440991
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.7783092 | Vali Loss: 1.7079818 | Test Loss: 0.7175632 | Mae Loss: 1.1411737 | SMAPE: 3.5411577 | MASE: 5.5483127
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.5886634 | Vali Loss: 1.8605453 | Test Loss: 0.6369663 | Mae Loss: 1.2153721 | SMAPE: 5.1946759 | MASE: 8.0361633
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.5646507 | Vali Loss: 1.3322892 | Test Loss: 0.5666078 | Mae Loss: 0.9911805 | SMAPE: 3.5913506 | MASE: 5.7722402
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.4859788 | Vali Loss: 1.2165208 | Test Loss: 0.4275317 | Mae Loss: 0.9431722 | SMAPE: 3.7168150 | MASE: 5.4429984
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.4542575 | Vali Loss: 1.4962763 | Test Loss: 0.3885635 | Mae Loss: 1.0757936 | SMAPE: 2.5533030 | MASE: 3.9136720
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.4263860 | Vali Loss: 1.3695166 | Test Loss: 0.3789866 | Mae Loss: 1.0208317 | SMAPE: 2.9433200 | MASE: 4.3722739
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.4231358 | Vali Loss: 1.0317754 | Test Loss: 0.3884471 | Mae Loss: 0.8481278 | SMAPE: 3.1282291 | MASE: 4.5741787
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.4369543 | Vali Loss: 1.1001955 | Test Loss: 0.3861501 | Mae Loss: 0.9228938 | SMAPE: 3.3592358 | MASE: 4.7522259
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.4185548 | Vali Loss: 1.0908247 | Test Loss: 0.3812908 | Mae Loss: 0.8874109 | SMAPE: 3.1899109 | MASE: 4.9455004
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.4195556 | Vali Loss: 0.9354284 | Test Loss: 0.3793093 | Mae Loss: 0.8015102 | SMAPE: 3.6966696 | MASE: 5.2785773
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.3927811 | Vali Loss: 1.0532290 | Test Loss: 0.3767701 | Mae Loss: 0.8756350 | SMAPE: 4.0133467 | MASE: 6.0761266
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 12 | Train Loss: 0.3939445 | Vali Loss: 1.1812253 | Test Loss: 0.3763791 | Mae Loss: 0.9490200 | SMAPE: 2.9098511 | MASE: 4.5234394
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 13 | Train Loss: 0.3986457 | Vali Loss: 1.0922974 | Test Loss: 0.3759639 | Mae Loss: 0.8847414 | SMAPE: 3.0618541 | MASE: 4.7706366
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 14 | Train Loss: 0.4216233 | Vali Loss: 0.8753228 | Test Loss: 0.3753248 | Mae Loss: 0.7895089 | SMAPE: 3.0906212 | MASE: 4.5570087
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 15 | Train Loss: 0.4018407 | Vali Loss: 1.3269447 | Test Loss: 0.3759039 | Mae Loss: 1.0121270 | SMAPE: 2.7477081 | MASE: 4.2240214
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 16 | Train Loss: 0.4090508 | Vali Loss: 0.9949440 | Test Loss: 0.3742717 | Mae Loss: 0.8626890 | SMAPE: 3.4779084 | MASE: 5.2579598
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 17 | Train Loss: 0.4258173 | Vali Loss: 1.1534054 | Test Loss: 0.3751298 | Mae Loss: 0.9366719 | SMAPE: 2.9214289 | MASE: 4.5233774
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 18 | Train Loss: 0.4230147 | Vali Loss: 1.1344261 | Test Loss: 0.3747953 | Mae Loss: 0.9211449 | SMAPE: 3.1003110 | MASE: 4.8327847
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 19 | Train Loss: 0.4146466 | Vali Loss: 0.9345703 | Test Loss: 0.3747125 | Mae Loss: 0.7896574 | SMAPE: 3.4616237 | MASE: 5.2395844
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 20 | Train Loss: 0.4146277 | Vali Loss: 0.9630585 | Test Loss: 0.3746574 | Mae Loss: 0.8315971 | SMAPE: 3.0576353 | MASE: 4.8351369
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.7011578 | Vali Loss: 2.3419256 | Test Loss: 0.6316550 | Mae Loss: 1.4058750 | SMAPE: 4.7675042 | MASE: 7.3605189
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.6133340 | Vali Loss: 1.9938498 | Test Loss: 0.6255244 | Mae Loss: 1.2669270 | SMAPE: 4.3175216 | MASE: 6.6826000
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.6153988 | Vali Loss: 1.6181554 | Test Loss: 0.6299672 | Mae Loss: 1.1196992 | SMAPE: 4.6571026 | MASE: 6.8856540
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.6024001 | Vali Loss: 1.7463770 | Test Loss: 0.6092410 | Mae Loss: 1.2164125 | SMAPE: 4.2050481 | MASE: 6.1212206
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.5572223 | Vali Loss: 1.4481004 | Test Loss: 0.6239128 | Mae Loss: 1.0792391 | SMAPE: 4.1228147 | MASE: 6.1642466
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.5348543 | Vali Loss: 1.4306695 | Test Loss: 0.5924157 | Mae Loss: 1.0580184 | SMAPE: 3.9092331 | MASE: 5.6485333
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.5497120 | Vali Loss: 1.6196517 | Test Loss: 0.5869525 | Mae Loss: 1.1683820 | SMAPE: 4.3895607 | MASE: 6.9929166
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.5322049 | Vali Loss: 1.2931050 | Test Loss: 0.5853592 | Mae Loss: 0.9986404 | SMAPE: 3.9581056 | MASE: 5.8790956
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.5256150 | Vali Loss: 1.3878030 | Test Loss: 0.5840942 | Mae Loss: 1.0575669 | SMAPE: 3.7338245 | MASE: 5.6031117
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.5347212 | Vali Loss: 1.3487759 | Test Loss: 0.5840925 | Mae Loss: 1.0479358 | SMAPE: 3.9798844 | MASE: 5.8685036
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.5694259 | Vali Loss: 1.4690931 | Test Loss: 0.5846359 | Mae Loss: 1.0899725 | SMAPE: 3.8956187 | MASE: 5.7785969
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.5414902 | Vali Loss: 1.4019393 | Test Loss: 0.5842283 | Mae Loss: 1.0633110 | SMAPE: 3.6553676 | MASE: 5.1394806
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 13 | Train Loss: 0.5471102 | Vali Loss: 1.7035160 | Test Loss: 0.5830844 | Mae Loss: 1.2333354 | SMAPE: 3.6442783 | MASE: 5.3699718
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 14 | Train Loss: 0.5476817 | Vali Loss: 1.6051085 | Test Loss: 0.5836679 | Mae Loss: 1.1394542 | SMAPE: 3.5119548 | MASE: 5.2543993
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 15 | Train Loss: 0.5574343 | Vali Loss: 1.6324744 | Test Loss: 0.5839868 | Mae Loss: 1.1788769 | SMAPE: 3.6499832 | MASE: 5.3883224
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 16 | Train Loss: 0.5346337 | Vali Loss: 1.2866809 | Test Loss: 0.5836364 | Mae Loss: 1.0231879 | SMAPE: 3.7085478 | MASE: 5.4936752
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 17 | Train Loss: 0.5498506 | Vali Loss: 1.5430282 | Test Loss: 0.5839259 | Mae Loss: 1.1239210 | SMAPE: 3.9028537 | MASE: 5.7457347
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 18 | Train Loss: 0.5391847 | Vali Loss: 1.5231574 | Test Loss: 0.5842794 | Mae Loss: 1.1287340 | SMAPE: 3.8295801 | MASE: 5.6857281
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 19 | Train Loss: 0.5385569 | Vali Loss: 1.3223667 | Test Loss: 0.5835862 | Mae Loss: 1.0400546 | SMAPE: 3.8250084 | MASE: 5.6207166
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 20 | Train Loss: 0.5383663 | Vali Loss: 1.3517163 | Test Loss: 0.5850580 | Mae Loss: 1.0674566 | SMAPE: 3.8650041 | MASE: 5.7376118
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.9078337 | Vali Loss: 3.0911787 | Test Loss: 1.3642497 | Mae Loss: 1.5712508 | SMAPE: 5.2125177 | MASE: 7.7856011
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.8516901 | Vali Loss: 1.9862199 | Test Loss: 0.5170553 | Mae Loss: 1.2944170 | SMAPE: 4.2569256 | MASE: 6.2556839
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.5766435 | Vali Loss: 1.6481768 | Test Loss: 0.6162010 | Mae Loss: 1.1920067 | SMAPE: 4.0194731 | MASE: 6.1415200
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.5935668 | Vali Loss: 1.8546623 | Test Loss: 0.5483919 | Mae Loss: 1.2642083 | SMAPE: 4.6193328 | MASE: 7.1234436
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.5777059 | Vali Loss: 1.8048302 | Test Loss: 0.5305689 | Mae Loss: 1.2367013 | SMAPE: 4.4644051 | MASE: 6.7407203
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.5836173 | Vali Loss: 1.7198249 | Test Loss: 0.5253664 | Mae Loss: 1.1839181 | SMAPE: 4.3935308 | MASE: 6.5404377
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.5857129 | Vali Loss: 1.7627040 | Test Loss: 0.5260953 | Mae Loss: 1.2157271 | SMAPE: 4.4043207 | MASE: 6.6418381
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.5585505 | Vali Loss: 1.8269578 | Test Loss: 0.5259076 | Mae Loss: 1.2577525 | SMAPE: 4.2461767 | MASE: 6.4315248
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.5910139 | Vali Loss: 1.5490204 | Test Loss: 0.5274287 | Mae Loss: 1.1150539 | SMAPE: 4.2909470 | MASE: 6.3913522
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.5807649 | Vali Loss: 1.8133098 | Test Loss: 0.5279035 | Mae Loss: 1.2397411 | SMAPE: 4.3028617 | MASE: 6.5025263
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.5879941 | Vali Loss: 1.7388655 | Test Loss: 0.5276011 | Mae Loss: 1.2066066 | SMAPE: 4.5035701 | MASE: 6.6529703
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.5707505 | Vali Loss: 1.9256495 | Test Loss: 0.5283232 | Mae Loss: 1.3088242 | SMAPE: 4.3424511 | MASE: 6.4770079
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 13 | Train Loss: 0.5798237 | Vali Loss: 1.9976429 | Test Loss: 0.5282776 | Mae Loss: 1.3337418 | SMAPE: 4.1504216 | MASE: 6.2054224
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 14 | Train Loss: 0.5860183 | Vali Loss: 1.5472082 | Test Loss: 0.5286429 | Mae Loss: 1.1136506 | SMAPE: 4.3989658 | MASE: 6.6804061
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 15 | Train Loss: 0.5557035 | Vali Loss: 1.8517272 | Test Loss: 0.5286484 | Mae Loss: 1.2565141 | SMAPE: 4.3510523 | MASE: 6.5480251
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 16 | Train Loss: 0.5775999 | Vali Loss: 1.8084279 | Test Loss: 0.5278589 | Mae Loss: 1.2283690 | SMAPE: 4.2405806 | MASE: 6.2567563
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 17 | Train Loss: 0.5762680 | Vali Loss: 1.8418308 | Test Loss: 0.5282339 | Mae Loss: 1.2610388 | SMAPE: 4.0811491 | MASE: 5.9772606
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 18 | Train Loss: 0.5762440 | Vali Loss: 1.7886564 | Test Loss: 0.5291382 | Mae Loss: 1.2260350 | SMAPE: 3.8950303 | MASE: 5.7155671
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 19 | Train Loss: 0.5713996 | Vali Loss: 1.7379358 | Test Loss: 0.5277033 | Mae Loss: 1.2023604 | SMAPE: 4.1566849 | MASE: 6.2440658
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 20 | Train Loss: 0.5731785 | Vali Loss: 1.9050304 | Test Loss: 0.5276333 | Mae Loss: 1.2831862 | SMAPE: 4.2582431 | MASE: 6.4701037
