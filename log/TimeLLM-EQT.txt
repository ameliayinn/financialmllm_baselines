seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.4412117 | Vali Loss: 0.1873820 | Test Loss: 0.5256951 | Mae Loss: 0.3654350 | SMAPE: 27.8093071 | MASE: 1.8412591
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.4297674 | Vali Loss: 0.1518959 | Test Loss: 0.4903297 | Mae Loss: 0.3421676 | SMAPE: 37.5843849 | MASE: 2.1273417
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.3439222 | Vali Loss: 0.0904930 | Test Loss: 0.2825639 | Mae Loss: 0.2269841 | SMAPE: 21.9725876 | MASE: 1.3814955
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.2577125 | Vali Loss: 0.0807611 | Test Loss: 0.2600987 | Mae Loss: 0.2075039 | SMAPE: 21.5983353 | MASE: 1.3946877
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.2430431 | Vali Loss: 0.0831030 | Test Loss: 0.2419540 | Mae Loss: 0.2145514 | SMAPE: 23.0037689 | MASE: 1.2429131
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.2442742 | Vali Loss: 0.0799653 | Test Loss: 0.2391070 | Mae Loss: 0.2062980 | SMAPE: 22.9851284 | MASE: 1.3525002
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.2475410 | Vali Loss: 0.0809862 | Test Loss: 0.2436422 | Mae Loss: 0.2085709 | SMAPE: 16.4648762 | MASE: 1.0124314
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.2464347 | Vali Loss: 0.0644226 | Test Loss: 0.2455905 | Mae Loss: 0.1894556 | SMAPE: 20.2579594 | MASE: 1.3543804
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.2398248 | Vali Loss: 0.0767377 | Test Loss: 0.2467327 | Mae Loss: 0.1989787 | SMAPE: 18.3618164 | MASE: 1.1761645
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.2463489 | Vali Loss: 0.0644612 | Test Loss: 0.2467737 | Mae Loss: 0.1894117 | SMAPE: 18.0331936 | MASE: 1.2051656
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.9906664 | Vali Loss: 0.3737534 | Test Loss: 0.9999252 | Mae Loss: 0.5533891 | SMAPE: 50.9967690 | MASE: 3.5645225
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.9175838 | Vali Loss: 0.2994541 | Test Loss: 1.0529281 | Mae Loss: 0.5080037 | SMAPE: 52.0769043 | MASE: 3.9706364
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.8180405 | Vali Loss: 0.3043219 | Test Loss: 0.7370989 | Mae Loss: 0.4940387 | SMAPE: 43.7581940 | MASE: 3.0735731
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.6081889 | Vali Loss: 0.1770314 | Test Loss: 0.4814865 | Mae Loss: 0.3586557 | SMAPE: 27.1146183 | MASE: 2.1938636
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.4463449 | Vali Loss: 0.1261442 | Test Loss: 0.4700900 | Mae Loss: 0.2944200 | SMAPE: 23.4225922 | MASE: 1.6183890
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.4586298 | Vali Loss: 0.1118634 | Test Loss: 0.5006064 | Mae Loss: 0.2580079 | SMAPE: 25.7692394 | MASE: 1.8598895
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.4663639 | Vali Loss: 0.1319941 | Test Loss: 0.4920930 | Mae Loss: 0.2805507 | SMAPE: 28.3516579 | MASE: 2.0043683
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.4211601 | Vali Loss: 0.1058901 | Test Loss: 0.4875337 | Mae Loss: 0.2646801 | SMAPE: 24.6683178 | MASE: 2.2013919
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.4289084 | Vali Loss: 0.1240328 | Test Loss: 0.4863204 | Mae Loss: 0.2867325 | SMAPE: 29.5940075 | MASE: 2.2851312
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.4125138 | Vali Loss: 0.0895761 | Test Loss: 0.4852951 | Mae Loss: 0.2299499 | SMAPE: 30.8298683 | MASE: 2.0144126
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 1.2770329 | Vali Loss: 0.5303600 | Test Loss: 1.0426605 | Mae Loss: 0.6247647 | SMAPE: 63.4842224 | MASE: 3.5687850
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 1.2920070 | Vali Loss: 0.4068501 | Test Loss: 1.2737788 | Mae Loss: 0.5518147 | SMAPE: 51.0096626 | MASE: 3.4411800
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 1.2319125 | Vali Loss: 0.4307432 | Test Loss: 1.1733571 | Mae Loss: 0.5810759 | SMAPE: 51.7119179 | MASE: 2.9737818
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 1.0864754 | Vali Loss: 0.2950950 | Test Loss: 1.0207383 | Mae Loss: 0.4786645 | SMAPE: 55.1549263 | MASE: 4.0294938
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.8551407 | Vali Loss: 0.2386832 | Test Loss: 0.9199566 | Mae Loss: 0.4347265 | SMAPE: 46.4861183 | MASE: 3.0636163
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.7809263 | Vali Loss: 0.2283429 | Test Loss: 0.8883820 | Mae Loss: 0.4325817 | SMAPE: 37.8997993 | MASE: 2.7188673
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.7242489 | Vali Loss: 0.2097033 | Test Loss: 0.8222751 | Mae Loss: 0.4222033 | SMAPE: 35.1700935 | MASE: 2.8945091
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.6808418 | Vali Loss: 0.1723593 | Test Loss: 0.7999332 | Mae Loss: 0.3792646 | SMAPE: 41.4786911 | MASE: 3.0332034
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.6534219 | Vali Loss: 0.2012794 | Test Loss: 0.7919195 | Mae Loss: 0.3946805 | SMAPE: 34.5878601 | MASE: 2.4909892
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.6756640 | Vali Loss: 0.2485026 | Test Loss: 0.7905690 | Mae Loss: 0.4555808 | SMAPE: 32.6156197 | MASE: 2.6281738
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 1.6259930 | Vali Loss: 0.4338447 | Test Loss: 1.5240157 | Mae Loss: 0.5840942 | SMAPE: 60.2777367 | MASE: 3.8331890
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 1.4633638 | Vali Loss: 0.3954011 | Test Loss: 1.6527469 | Mae Loss: 0.5745986 | SMAPE: 45.3659401 | MASE: 2.9561291
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 1.4490252 | Vali Loss: 0.3555508 | Test Loss: 1.6297592 | Mae Loss: 0.5265283 | SMAPE: 51.2156982 | MASE: 3.5555499
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 1.3985462 | Vali Loss: 0.3024820 | Test Loss: 1.5854835 | Mae Loss: 0.4675981 | SMAPE: 53.2171860 | MASE: 3.6537309
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 1.3721895 | Vali Loss: 0.2774664 | Test Loss: 1.5599063 | Mae Loss: 0.4497604 | SMAPE: 44.8576546 | MASE: 3.1155000
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 1.2885108 | Vali Loss: 0.2820168 | Test Loss: 1.4578837 | Mae Loss: 0.4701353 | SMAPE: 46.1400223 | MASE: 3.3055227
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 1.1604959 | Vali Loss: 0.2499487 | Test Loss: 1.3882533 | Mae Loss: 0.4294047 | SMAPE: 39.3196449 | MASE: 2.7554705
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 1.1101169 | Vali Loss: 0.2339981 | Test Loss: 1.3658006 | Mae Loss: 0.4231965 | SMAPE: 41.8672447 | MASE: 3.0904355
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 1.1228076 | Vali Loss: 0.2447246 | Test Loss: 1.3505266 | Mae Loss: 0.4294043 | SMAPE: 41.3974380 | MASE: 2.8559401
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 1.0978240 | Vali Loss: 0.2288655 | Test Loss: 1.3464778 | Mae Loss: 0.4115620 | SMAPE: 40.1632957 | MASE: 3.0435505
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 1.7659488 | Vali Loss: 0.3727438 | Test Loss: 2.2538131 | Mae Loss: 0.5307513 | SMAPE: 54.3106613 | MASE: 3.6039472
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 1.5411446 | Vali Loss: 0.4379191 | Test Loss: 1.6562483 | Mae Loss: 0.5866504 | SMAPE: 61.1141815 | MASE: 4.0106354
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 1.3827871 | Vali Loss: 0.2885378 | Test Loss: 1.6071150 | Mae Loss: 0.4610619 | SMAPE: 45.4250946 | MASE: 3.0344682
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 1.0787589 | Vali Loss: 0.2690003 | Test Loss: 1.4717794 | Mae Loss: 0.4677705 | SMAPE: 39.6195221 | MASE: 2.6654272
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.9692667 | Vali Loss: 0.2395200 | Test Loss: 1.4353746 | Mae Loss: 0.4327547 | SMAPE: 41.7203598 | MASE: 2.9208965
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.9744890 | Vali Loss: 0.2829195 | Test Loss: 1.4296123 | Mae Loss: 0.4665954 | SMAPE: 42.1841278 | MASE: 2.9885395
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.9318053 | Vali Loss: 0.2326666 | Test Loss: 1.3942568 | Mae Loss: 0.4307141 | SMAPE: 37.6564903 | MASE: 2.9402339
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.9050767 | Vali Loss: 0.2248027 | Test Loss: 1.3787050 | Mae Loss: 0.4240255 | SMAPE: 37.9521179 | MASE: 2.7652287
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.8834342 | Vali Loss: 0.2661668 | Test Loss: 1.3774195 | Mae Loss: 0.4650695 | SMAPE: 39.3041687 | MASE: 2.9873455
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.9007758 | Vali Loss: 0.2254955 | Test Loss: 1.3768928 | Mae Loss: 0.4248527 | SMAPE: 38.5517082 | MASE: 2.9936988
