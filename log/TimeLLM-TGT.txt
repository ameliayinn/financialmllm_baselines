seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2145171 | Vali Loss: 0.0846724 | Test Loss: 0.2233705 | Mae Loss: 0.2142227 | SMAPE: 88.3181534 | MASE: 2.2763915
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.1682896 | Vali Loss: 0.1367872 | Test Loss: 0.3814457 | Mae Loss: 0.2824501 | SMAPE: 149.3955383 | MASE: 3.8820229
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.1552069 | Vali Loss: 0.1340864 | Test Loss: 0.3069084 | Mae Loss: 0.2767016 | SMAPE: 139.4460449 | MASE: 2.4269915
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.1571953 | Vali Loss: 0.1063574 | Test Loss: 0.2550142 | Mae Loss: 0.2389439 | SMAPE: 67.9437027 | MASE: 2.2159579
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.1417777 | Vali Loss: 0.1246525 | Test Loss: 0.3005036 | Mae Loss: 0.2594171 | SMAPE: 119.3281403 | MASE: 2.8870952
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1563633 | Vali Loss: 0.1349040 | Test Loss: 0.3087810 | Mae Loss: 0.2753398 | SMAPE: 117.9621429 | MASE: 2.7560711
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.1532739 | Vali Loss: 0.1332677 | Test Loss: 0.3028118 | Mae Loss: 0.2773918 | SMAPE: 105.9195404 | MASE: 2.7844920
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.1509561 | Vali Loss: 0.1058380 | Test Loss: 0.2969709 | Mae Loss: 0.2428603 | SMAPE: 105.4006348 | MASE: 1.9861736
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.1544869 | Vali Loss: 0.1296739 | Test Loss: 0.2954429 | Mae Loss: 0.2732858 | SMAPE: 95.1619263 | MASE: 2.3002591
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.1464855 | Vali Loss: 0.1051887 | Test Loss: 0.2944037 | Mae Loss: 0.2419550 | SMAPE: 120.7665939 | MASE: 2.7660534
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.3377975 | Vali Loss: 0.2326950 | Test Loss: 0.2859844 | Mae Loss: 0.4285372 | SMAPE: 156.8819427 | MASE: 3.3918781
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.2642415 | Vali Loss: 0.0948649 | Test Loss: 0.2838104 | Mae Loss: 0.2463875 | SMAPE: 123.2872238 | MASE: 3.0635238
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.3437475 | Vali Loss: 0.2067074 | Test Loss: 0.2923407 | Mae Loss: 0.4040089 | SMAPE: 160.4708405 | MASE: 4.4038105
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.2662058 | Vali Loss: 0.1737072 | Test Loss: 0.2871523 | Mae Loss: 0.3538266 | SMAPE: 156.5484772 | MASE: 3.3516240
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.2568259 | Vali Loss: 0.2410005 | Test Loss: 0.2950965 | Mae Loss: 0.4391972 | SMAPE: 167.4895020 | MASE: 3.6989574
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.2222154 | Vali Loss: 0.1917700 | Test Loss: 0.2938258 | Mae Loss: 0.3860134 | SMAPE: 159.9582977 | MASE: 4.4169502
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.2105362 | Vali Loss: 0.2211319 | Test Loss: 0.2860554 | Mae Loss: 0.4217684 | SMAPE: 154.5995026 | MASE: 2.9426837
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.2187664 | Vali Loss: 0.1594329 | Test Loss: 0.2784206 | Mae Loss: 0.3473513 | SMAPE: 170.2239380 | MASE: 5.4884157
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.2203681 | Vali Loss: 0.1854222 | Test Loss: 0.2745636 | Mae Loss: 0.3874272 | SMAPE: 182.2635956 | MASE: 4.4720535
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.2163294 | Vali Loss: 0.1660775 | Test Loss: 0.2722187 | Mae Loss: 0.3652928 | SMAPE: 172.4962006 | MASE: 3.1856542
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.4098752 | Vali Loss: 0.3535301 | Test Loss: 0.2878101 | Mae Loss: 0.5611566 | SMAPE: 187.2723083 | MASE: 4.9311833
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.4079055 | Vali Loss: 0.3290192 | Test Loss: 0.2762482 | Mae Loss: 0.5343214 | SMAPE: 185.8031464 | MASE: 4.8000240
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.3490449 | Vali Loss: 0.2416268 | Test Loss: 0.2488647 | Mae Loss: 0.4466503 | SMAPE: 182.3818665 | MASE: 3.5154498
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.2814963 | Vali Loss: 0.1774588 | Test Loss: 0.2301636 | Mae Loss: 0.3786374 | SMAPE: 190.8098145 | MASE: 4.5526700
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.2693300 | Vali Loss: 0.1580957 | Test Loss: 0.2144752 | Mae Loss: 0.3552285 | SMAPE: 183.4598236 | MASE: 3.4431682
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.2569281 | Vali Loss: 0.1536669 | Test Loss: 0.2123319 | Mae Loss: 0.3445275 | SMAPE: 166.7098694 | MASE: 2.7215116
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.2381938 | Vali Loss: 0.1485521 | Test Loss: 0.2048981 | Mae Loss: 0.3371239 | SMAPE: 177.9847565 | MASE: 3.8834245
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.2419052 | Vali Loss: 0.1185510 | Test Loss: 0.2038735 | Mae Loss: 0.2971365 | SMAPE: 172.7701416 | MASE: 3.3366640
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.2153827 | Vali Loss: 0.1425424 | Test Loss: 0.2045794 | Mae Loss: 0.3273080 | SMAPE: 168.2735138 | MASE: 3.3696949
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.2327035 | Vali Loss: 0.1365291 | Test Loss: 0.2048464 | Mae Loss: 0.3186629 | SMAPE: 171.0700226 | MASE: 3.3984089
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.6878055 | Vali Loss: 0.2574878 | Test Loss: 0.2673521 | Mae Loss: 0.4637613 | SMAPE: 185.6661835 | MASE: 4.7675414
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.4732748 | Vali Loss: 0.2991077 | Test Loss: 0.2824067 | Mae Loss: 0.5155086 | SMAPE: 183.4039612 | MASE: 4.5732517
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.4700408 | Vali Loss: 0.4045055 | Test Loss: 0.3364734 | Mae Loss: 0.6020532 | SMAPE: 186.1747131 | MASE: 5.9509001
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.4520328 | Vali Loss: 0.3417123 | Test Loss: 0.3257000 | Mae Loss: 0.5427663 | SMAPE: 187.2811737 | MASE: 5.7489438
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.4592941 | Vali Loss: 0.3437086 | Test Loss: 0.3133496 | Mae Loss: 0.5478694 | SMAPE: 187.6797485 | MASE: 5.5212393
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.4341389 | Vali Loss: 0.3346258 | Test Loss: 0.3107692 | Mae Loss: 0.5383955 | SMAPE: 190.0732269 | MASE: 5.7937260
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.4162542 | Vali Loss: 0.3382354 | Test Loss: 0.3208724 | Mae Loss: 0.5441352 | SMAPE: 183.0691681 | MASE: 4.9935904
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.4351032 | Vali Loss: 0.3848233 | Test Loss: 0.3247716 | Mae Loss: 0.5877014 | SMAPE: 186.1092987 | MASE: 5.9492431
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.4239950 | Vali Loss: 0.3730031 | Test Loss: 0.3249085 | Mae Loss: 0.5751306 | SMAPE: 186.0057373 | MASE: 5.7667742
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.4192870 | Vali Loss: 0.3532829 | Test Loss: 0.3223152 | Mae Loss: 0.5605248 | SMAPE: 188.5518494 | MASE: 5.9680223
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.5442222 | Vali Loss: 0.4036355 | Test Loss: 0.3330795 | Mae Loss: 0.5866550 | SMAPE: 186.6729431 | MASE: 6.7428184
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.3996720 | Vali Loss: 0.5908092 | Test Loss: 0.3940046 | Mae Loss: 0.7314793 | SMAPE: 191.2988586 | MASE: 8.4480267
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.3902141 | Vali Loss: 0.4318416 | Test Loss: 0.3293000 | Mae Loss: 0.6069782 | SMAPE: 186.8163452 | MASE: 6.3157053
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.3745305 | Vali Loss: 0.4795578 | Test Loss: 0.3546611 | Mae Loss: 0.6572644 | SMAPE: 185.6050262 | MASE: 6.4042273
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.3595895 | Vali Loss: 0.5134351 | Test Loss: 0.3621273 | Mae Loss: 0.6724464 | SMAPE: 187.9634705 | MASE: 7.3507676
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.3479718 | Vali Loss: 0.5363817 | Test Loss: 0.3507998 | Mae Loss: 0.6934355 | SMAPE: 187.2777405 | MASE: 7.0788136
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.3400665 | Vali Loss: 0.4941136 | Test Loss: 0.3430893 | Mae Loss: 0.6653000 | SMAPE: 189.4358215 | MASE: 7.5223465
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.3547835 | Vali Loss: 0.4593391 | Test Loss: 0.3414878 | Mae Loss: 0.6332909 | SMAPE: 188.3807831 | MASE: 6.8617830
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.3535929 | Vali Loss: 0.5450777 | Test Loss: 0.3413094 | Mae Loss: 0.7002376 | SMAPE: 189.5231934 | MASE: 7.7792640
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.3545484 | Vali Loss: 0.4761187 | Test Loss: 0.3419177 | Mae Loss: 0.6484447 | SMAPE: 189.5241547 | MASE: 8.1527863
