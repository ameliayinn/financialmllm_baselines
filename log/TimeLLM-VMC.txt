seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.4799749 | Vali Loss: 0.2307006 | Test Loss: 0.2419089 | Mae Loss: 0.3996144 | SMAPE: 39.2368317 | MASE: 1.8547128
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.4450645 | Vali Loss: 0.2137644 | Test Loss: 0.2408803 | Mae Loss: 0.3861386 | SMAPE: 44.0943909 | MASE: 1.8613006
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.4483151 | Vali Loss: 0.2357541 | Test Loss: 0.2411577 | Mae Loss: 0.4113635 | SMAPE: 30.2262573 | MASE: 1.3536786
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.4513695 | Vali Loss: 0.2329947 | Test Loss: 0.2412257 | Mae Loss: 0.4041502 | SMAPE: 35.8785934 | MASE: 1.5107476
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.4517716 | Vali Loss: 0.2301322 | Test Loss: 0.2411647 | Mae Loss: 0.3985318 | SMAPE: 41.6580124 | MASE: 1.6308914
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.4390415 | Vali Loss: 0.2248363 | Test Loss: 0.2411799 | Mae Loss: 0.3928648 | SMAPE: 48.6034584 | MASE: 2.2316287
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.4575879 | Vali Loss: 0.2290920 | Test Loss: 0.2411600 | Mae Loss: 0.3991571 | SMAPE: 36.8409004 | MASE: 1.6579413
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.4512033 | Vali Loss: 0.2134761 | Test Loss: 0.2411805 | Mae Loss: 0.3856457 | SMAPE: 43.5070839 | MASE: 1.8976716
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.4489925 | Vali Loss: 0.2304335 | Test Loss: 0.2411647 | Mae Loss: 0.4001586 | SMAPE: 36.6128998 | MASE: 1.5057472
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.4420380 | Vali Loss: 0.2134866 | Test Loss: 0.2411292 | Mae Loss: 0.3856263 | SMAPE: 49.7539215 | MASE: 2.6337688
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.7914133 | Vali Loss: 0.1328880 | Test Loss: 0.3634399 | Mae Loss: 0.2872104 | SMAPE: 24.2444477 | MASE: 1.1616244
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.6605451 | Vali Loss: 0.1418788 | Test Loss: 0.3267111 | Mae Loss: 0.3113437 | SMAPE: 34.9713974 | MASE: 1.7142001
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.4577044 | Vali Loss: 0.1860545 | Test Loss: 0.1740789 | Mae Loss: 0.3611727 | SMAPE: 33.0836220 | MASE: 1.6754426
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.3374368 | Vali Loss: 0.2292364 | Test Loss: 0.1691243 | Mae Loss: 0.3977974 | SMAPE: 36.1147957 | MASE: 1.8816811
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.3082956 | Vali Loss: 0.2259956 | Test Loss: 0.1738763 | Mae Loss: 0.3933156 | SMAPE: 38.0549660 | MASE: 1.7242934
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.3245632 | Vali Loss: 0.2289576 | Test Loss: 0.1736786 | Mae Loss: 0.4148554 | SMAPE: 30.7578869 | MASE: 1.5581156
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.2972512 | Vali Loss: 0.1977528 | Test Loss: 0.1724681 | Mae Loss: 0.3565332 | SMAPE: 36.6860809 | MASE: 1.6939254
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.2942101 | Vali Loss: 0.1471964 | Test Loss: 0.1731173 | Mae Loss: 0.2903558 | SMAPE: 33.4757309 | MASE: 1.5862470
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.3011772 | Vali Loss: 0.1694617 | Test Loss: 0.1727163 | Mae Loss: 0.3153391 | SMAPE: 37.9600372 | MASE: 1.8196813
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.2947728 | Vali Loss: 0.1728300 | Test Loss: 0.1726478 | Mae Loss: 0.3340086 | SMAPE: 35.9379883 | MASE: 1.7520877
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 1.0161106 | Vali Loss: 0.1870813 | Test Loss: 0.5040896 | Mae Loss: 0.3559274 | SMAPE: 34.7956505 | MASE: 1.6017159
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.9925602 | Vali Loss: 0.3011608 | Test Loss: 0.6610655 | Mae Loss: 0.4470033 | SMAPE: 49.4183464 | MASE: 2.6785707
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.9339183 | Vali Loss: 0.2185864 | Test Loss: 0.4994921 | Mae Loss: 0.3847034 | SMAPE: 39.1997871 | MASE: 1.7844697
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.7577162 | Vali Loss: 0.2674614 | Test Loss: 0.3802438 | Mae Loss: 0.4266679 | SMAPE: 41.2163048 | MASE: 2.0704434
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.6033292 | Vali Loss: 0.3206363 | Test Loss: 0.3066643 | Mae Loss: 0.4853186 | SMAPE: 42.2465248 | MASE: 1.9757429
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.5336113 | Vali Loss: 0.2606130 | Test Loss: 0.2734426 | Mae Loss: 0.4359772 | SMAPE: 39.6872940 | MASE: 1.8207192
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.5326573 | Vali Loss: 0.2816489 | Test Loss: 0.2538175 | Mae Loss: 0.4531557 | SMAPE: 47.6495552 | MASE: 2.4082541
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.5210526 | Vali Loss: 0.2774310 | Test Loss: 0.2466684 | Mae Loss: 0.4454383 | SMAPE: 44.0924797 | MASE: 2.0607958
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.4937930 | Vali Loss: 0.2486184 | Test Loss: 0.2427504 | Mae Loss: 0.4247811 | SMAPE: 53.1116905 | MASE: 2.7085879
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.4734708 | Vali Loss: 0.2918820 | Test Loss: 0.2403882 | Mae Loss: 0.4461812 | SMAPE: 45.0400009 | MASE: 2.2498813
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 1.4742077 | Vali Loss: 0.4449307 | Test Loss: 0.7794607 | Mae Loss: 0.5526983 | SMAPE: 54.1561890 | MASE: 2.6987941
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 1.3540568 | Vali Loss: 0.2871142 | Test Loss: 0.7773373 | Mae Loss: 0.4640893 | SMAPE: 44.6107254 | MASE: 2.1939762
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 1.3148355 | Vali Loss: 0.2641118 | Test Loss: 0.7374211 | Mae Loss: 0.4420015 | SMAPE: 43.9743004 | MASE: 2.2021248
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 1.2801439 | Vali Loss: 0.2283870 | Test Loss: 0.6286794 | Mae Loss: 0.4054621 | SMAPE: 41.4640884 | MASE: 1.9162955
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 1.0441298 | Vali Loss: 0.1550394 | Test Loss: 0.4675916 | Mae Loss: 0.3288066 | SMAPE: 38.2733841 | MASE: 1.8439635
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.8414125 | Vali Loss: 0.1773478 | Test Loss: 0.4161987 | Mae Loss: 0.3572862 | SMAPE: 34.2523766 | MASE: 1.6611435
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.8085346 | Vali Loss: 0.1435558 | Test Loss: 0.3832279 | Mae Loss: 0.3171309 | SMAPE: 35.1996078 | MASE: 1.6023035
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.7267199 | Vali Loss: 0.1284522 | Test Loss: 0.3669195 | Mae Loss: 0.2965185 | SMAPE: 34.8890953 | MASE: 1.7169658
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.7227717 | Vali Loss: 0.1522892 | Test Loss: 0.3580035 | Mae Loss: 0.3190604 | SMAPE: 31.0995045 | MASE: 1.4366109
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.7191139 | Vali Loss: 0.1294982 | Test Loss: 0.3533055 | Mae Loss: 0.2940835 | SMAPE: 32.9410210 | MASE: 1.5024382
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 1.7228945 | Vali Loss: 0.2627444 | Test Loss: 0.6933327 | Mae Loss: 0.3782280 | SMAPE: 50.6514130 | MASE: 2.0668464
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 1.5935018 | Vali Loss: 0.2009124 | Test Loss: 0.7724411 | Mae Loss: 0.3625530 | SMAPE: 42.3909798 | MASE: 1.8395016
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 1.5579647 | Vali Loss: 0.2561139 | Test Loss: 0.6791677 | Mae Loss: 0.4065658 | SMAPE: 52.5849686 | MASE: 2.0640681
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 1.5206334 | Vali Loss: 0.1594616 | Test Loss: 0.7091842 | Mae Loss: 0.3196910 | SMAPE: 41.2576408 | MASE: 1.7805500
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 1.5662321 | Vali Loss: 0.2050109 | Test Loss: 0.7099839 | Mae Loss: 0.3660020 | SMAPE: 40.5314636 | MASE: 1.7773737
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 1.4830722 | Vali Loss: 0.2474842 | Test Loss: 0.7047905 | Mae Loss: 0.3967257 | SMAPE: 40.7825012 | MASE: 1.7633550
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 1.4972977 | Vali Loss: 0.2032981 | Test Loss: 0.6954637 | Mae Loss: 0.3567237 | SMAPE: 40.4553375 | MASE: 1.7589581
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 1.5299114 | Vali Loss: 0.1928964 | Test Loss: 0.6921671 | Mae Loss: 0.3490680 | SMAPE: 40.5261803 | MASE: 1.7845471
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 1.4668581 | Vali Loss: 0.2597173 | Test Loss: 0.6897583 | Mae Loss: 0.4089113 | SMAPE: 39.4495926 | MASE: 1.6830971
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 1.4780830 | Vali Loss: 0.2038192 | Test Loss: 0.6888666 | Mae Loss: 0.3635565 | SMAPE: 39.7518234 | MASE: 1.7469481
