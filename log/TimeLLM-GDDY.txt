seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0670032 | Vali Loss: 0.0703042 | Test Loss: 0.2704816 | Mae Loss: 0.2114016 | SMAPE: 17.0944366 | MASE: 1.8433168
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0623270 | Vali Loss: 0.0907328 | Test Loss: 0.2115561 | Mae Loss: 0.2300694 | SMAPE: 12.8099527 | MASE: 2.2582419
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0515190 | Vali Loss: 0.0344532 | Test Loss: 0.1176058 | Mae Loss: 0.1431306 | SMAPE: 10.4523001 | MASE: 1.4630989
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0538032 | Vali Loss: 0.0505307 | Test Loss: 0.1139877 | Mae Loss: 0.1548794 | SMAPE: 14.0600233 | MASE: 1.8756758
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0463256 | Vali Loss: 0.0532837 | Test Loss: 0.1096111 | Mae Loss: 0.1634766 | SMAPE: 11.5690098 | MASE: 1.6125878
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0456483 | Vali Loss: 0.0519612 | Test Loss: 0.1066451 | Mae Loss: 0.1582313 | SMAPE: 6.6586390 | MASE: 1.2328510
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0428549 | Vali Loss: 0.0526402 | Test Loss: 0.1064011 | Mae Loss: 0.1612442 | SMAPE: 10.0049992 | MASE: 1.3459407
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0461062 | Vali Loss: 0.0524260 | Test Loss: 0.1059284 | Mae Loss: 0.1600181 | SMAPE: 6.1847391 | MASE: 1.1136035
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0458856 | Vali Loss: 0.0521800 | Test Loss: 0.1055617 | Mae Loss: 0.1587283 | SMAPE: 12.0973616 | MASE: 1.7679856
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0433978 | Vali Loss: 0.0522984 | Test Loss: 0.1052166 | Mae Loss: 0.1592979 | SMAPE: 8.0991077 | MASE: 1.4787757
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1187528 | Vali Loss: 0.0774073 | Test Loss: 0.3805688 | Mae Loss: 0.2128408 | SMAPE: 15.1554270 | MASE: 1.5908613
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0932786 | Vali Loss: 0.0905682 | Test Loss: 0.3761430 | Mae Loss: 0.2482245 | SMAPE: 20.4389915 | MASE: 2.1038203
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0923944 | Vali Loss: 0.1191083 | Test Loss: 0.3469771 | Mae Loss: 0.2829531 | SMAPE: 21.4080906 | MASE: 2.4057817
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0876562 | Vali Loss: 0.0579381 | Test Loss: 0.3508933 | Mae Loss: 0.1989708 | SMAPE: 15.2637005 | MASE: 2.0060360
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0858537 | Vali Loss: 0.1228859 | Test Loss: 0.3464580 | Mae Loss: 0.2918573 | SMAPE: 16.7758217 | MASE: 1.9049622
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0863434 | Vali Loss: 0.0814151 | Test Loss: 0.3289118 | Mae Loss: 0.2311180 | SMAPE: 19.2219658 | MASE: 2.5316241
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0814443 | Vali Loss: 0.0765746 | Test Loss: 0.3081995 | Mae Loss: 0.2147637 | SMAPE: 16.6683884 | MASE: 3.1733196
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0793095 | Vali Loss: 0.0884397 | Test Loss: 0.2928967 | Mae Loss: 0.2301302 | SMAPE: 23.2529926 | MASE: 2.5933917
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0773499 | Vali Loss: 0.1122637 | Test Loss: 0.2851403 | Mae Loss: 0.2647979 | SMAPE: 15.6003895 | MASE: 1.9733973
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0748387 | Vali Loss: 0.0816646 | Test Loss: 0.2800732 | Mae Loss: 0.2315061 | SMAPE: 13.4324160 | MASE: 1.5614289
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1871449 | Vali Loss: 0.0948126 | Test Loss: 0.5013835 | Mae Loss: 0.2641430 | SMAPE: 16.8079796 | MASE: 2.4824982
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1193368 | Vali Loss: 0.1666747 | Test Loss: 0.4320967 | Mae Loss: 0.3534736 | SMAPE: 23.4306545 | MASE: 2.8941178
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1127997 | Vali Loss: 0.0896444 | Test Loss: 0.4518015 | Mae Loss: 0.2578878 | SMAPE: 18.9496441 | MASE: 2.4398429
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.0974335 | Vali Loss: 0.1249184 | Test Loss: 0.4380011 | Mae Loss: 0.3152308 | SMAPE: 22.0752449 | MASE: 2.8278029
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1044339 | Vali Loss: 0.1224922 | Test Loss: 0.4598863 | Mae Loss: 0.3208856 | SMAPE: 15.4500437 | MASE: 2.5571136
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1015480 | Vali Loss: 0.1162620 | Test Loss: 0.4579050 | Mae Loss: 0.3057549 | SMAPE: 18.0652981 | MASE: 2.1506758
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0996281 | Vali Loss: 0.1078468 | Test Loss: 0.4475933 | Mae Loss: 0.2934351 | SMAPE: 20.6747360 | MASE: 3.0128355
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1086339 | Vali Loss: 0.1364248 | Test Loss: 0.4454006 | Mae Loss: 0.3312264 | SMAPE: 21.1479321 | MASE: 2.4143605
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1013833 | Vali Loss: 0.1139435 | Test Loss: 0.4455828 | Mae Loss: 0.2994569 | SMAPE: 23.3653164 | MASE: 3.4640570
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.1005068 | Vali Loss: 0.1054784 | Test Loss: 0.4460210 | Mae Loss: 0.2830434 | SMAPE: 21.5700054 | MASE: 2.5103927
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2268135 | Vali Loss: 0.1140293 | Test Loss: 0.5265092 | Mae Loss: 0.2978967 | SMAPE: 20.2769852 | MASE: 2.4328909
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1454007 | Vali Loss: 0.1585219 | Test Loss: 0.4678084 | Mae Loss: 0.3559304 | SMAPE: 21.2660789 | MASE: 2.6891551
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1421564 | Vali Loss: 0.0970050 | Test Loss: 0.4944343 | Mae Loss: 0.2693431 | SMAPE: 20.1228180 | MASE: 2.3314006
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1418116 | Vali Loss: 0.1180945 | Test Loss: 0.4764090 | Mae Loss: 0.3120120 | SMAPE: 22.2248116 | MASE: 2.6254425
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1285196 | Vali Loss: 0.1218544 | Test Loss: 0.4611694 | Mae Loss: 0.3146769 | SMAPE: 24.4703693 | MASE: 3.1705496
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1304673 | Vali Loss: 0.1190166 | Test Loss: 0.4568865 | Mae Loss: 0.3070853 | SMAPE: 21.3543892 | MASE: 2.4117086
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1404401 | Vali Loss: 0.1294459 | Test Loss: 0.4587198 | Mae Loss: 0.3284950 | SMAPE: 24.0446262 | MASE: 3.1751988
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1366028 | Vali Loss: 0.1125478 | Test Loss: 0.4593752 | Mae Loss: 0.2993183 | SMAPE: 22.9488468 | MASE: 2.7847865
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1407292 | Vali Loss: 0.1269311 | Test Loss: 0.4600972 | Mae Loss: 0.3194782 | SMAPE: 20.7155018 | MASE: 2.5261710
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1351948 | Vali Loss: 0.1253604 | Test Loss: 0.4602334 | Mae Loss: 0.3191929 | SMAPE: 23.8432255 | MASE: 2.7202561
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3112021 | Vali Loss: 0.1121689 | Test Loss: 0.5303906 | Mae Loss: 0.3075883 | SMAPE: 21.9389725 | MASE: 2.6367416
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1755943 | Vali Loss: 0.0975547 | Test Loss: 0.5691022 | Mae Loss: 0.2844750 | SMAPE: 19.0735683 | MASE: 2.0424278
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1780872 | Vali Loss: 0.1475710 | Test Loss: 0.4754824 | Mae Loss: 0.3524330 | SMAPE: 23.8710709 | MASE: 2.9673817
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1861717 | Vali Loss: 0.1155344 | Test Loss: 0.5362572 | Mae Loss: 0.3172378 | SMAPE: 20.8186932 | MASE: 2.6923110
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1746265 | Vali Loss: 0.1128292 | Test Loss: 0.5132795 | Mae Loss: 0.3079581 | SMAPE: 21.6070995 | MASE: 2.6124313
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1731844 | Vali Loss: 0.1166656 | Test Loss: 0.4985035 | Mae Loss: 0.3121364 | SMAPE: 22.2909355 | MASE: 2.6762593
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1770683 | Vali Loss: 0.1285695 | Test Loss: 0.4932691 | Mae Loss: 0.3281387 | SMAPE: 23.4793930 | MASE: 2.7051661
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1736742 | Vali Loss: 0.1181351 | Test Loss: 0.4899347 | Mae Loss: 0.3145834 | SMAPE: 22.8293610 | MASE: 2.7908728
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1747577 | Vali Loss: 0.1173024 | Test Loss: 0.4898968 | Mae Loss: 0.3087273 | SMAPE: 22.9173851 | MASE: 2.5940716
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1728678 | Vali Loss: 0.1175228 | Test Loss: 0.4895156 | Mae Loss: 0.3167603 | SMAPE: 24.6000919 | MASE: 2.7717996
