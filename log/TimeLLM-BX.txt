seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2664640 | Vali Loss: 0.0484582 | Test Loss: 0.2773180 | Mae Loss: 0.1804282 | SMAPE: 16.4711647 | MASE: 1.5487370
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.2331127 | Vali Loss: 0.0672134 | Test Loss: 0.2060059 | Mae Loss: 0.2129755 | SMAPE: 24.0716705 | MASE: 1.9275845
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.2248785 | Vali Loss: 0.0478663 | Test Loss: 0.2533386 | Mae Loss: 0.1808731 | SMAPE: 23.1477890 | MASE: 1.8637738
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.2224212 | Vali Loss: 0.0542444 | Test Loss: 0.2211475 | Mae Loss: 0.1903525 | SMAPE: 25.8454647 | MASE: 1.7956109
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.2083558 | Vali Loss: 0.0513097 | Test Loss: 0.1989888 | Mae Loss: 0.1852502 | SMAPE: 17.3374405 | MASE: 1.4304031
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1831013 | Vali Loss: 0.0428786 | Test Loss: 0.1690470 | Mae Loss: 0.1677941 | SMAPE: 14.9903507 | MASE: 1.2757461
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.1519281 | Vali Loss: 0.0367577 | Test Loss: 0.1435164 | Mae Loss: 0.1546567 | SMAPE: 18.1838989 | MASE: 1.5132594
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.1500122 | Vali Loss: 0.0363976 | Test Loss: 0.1250108 | Mae Loss: 0.1549430 | SMAPE: 17.4429474 | MASE: 1.4735304
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.1244206 | Vali Loss: 0.0351410 | Test Loss: 0.1152732 | Mae Loss: 0.1537551 | SMAPE: 19.3791084 | MASE: 1.3298863
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.1217674 | Vali Loss: 0.0354460 | Test Loss: 0.1130640 | Mae Loss: 0.1536186 | SMAPE: 11.9519119 | MASE: 1.1501460
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.4096864 | Vali Loss: 0.1137419 | Test Loss: 0.5518983 | Mae Loss: 0.2782867 | SMAPE: 31.7160912 | MASE: 2.4330950
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.4165003 | Vali Loss: 0.1803074 | Test Loss: 0.4192692 | Mae Loss: 0.3699752 | SMAPE: 54.9034348 | MASE: 3.6260934
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.3862954 | Vali Loss: 0.1104553 | Test Loss: 0.6161430 | Mae Loss: 0.2724556 | SMAPE: 34.0901718 | MASE: 2.5343037
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.3795251 | Vali Loss: 0.1033785 | Test Loss: 0.5410367 | Mae Loss: 0.2651672 | SMAPE: 30.7343121 | MASE: 2.2782388
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.3593289 | Vali Loss: 0.1457500 | Test Loss: 0.5020308 | Mae Loss: 0.3388409 | SMAPE: 34.1906357 | MASE: 2.5429943
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.3633829 | Vali Loss: 0.1107588 | Test Loss: 0.4699011 | Mae Loss: 0.2698412 | SMAPE: 39.7366867 | MASE: 2.8652291
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.3490084 | Vali Loss: 0.1233265 | Test Loss: 0.4520107 | Mae Loss: 0.2985458 | SMAPE: 25.0943661 | MASE: 2.1062477
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.3128690 | Vali Loss: 0.1277511 | Test Loss: 0.4385437 | Mae Loss: 0.3053858 | SMAPE: 44.3333092 | MASE: 2.9882216
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.3288611 | Vali Loss: 0.1089202 | Test Loss: 0.4302983 | Mae Loss: 0.2858773 | SMAPE: 33.7976379 | MASE: 2.4253988
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.3178653 | Vali Loss: 0.1013570 | Test Loss: 0.4260261 | Mae Loss: 0.2663755 | SMAPE: 28.9657898 | MASE: 2.2987120
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.5425528 | Vali Loss: 0.2184686 | Test Loss: 0.7450244 | Mae Loss: 0.3888232 | SMAPE: 46.9344635 | MASE: 3.5017900
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.6052911 | Vali Loss: 0.1915547 | Test Loss: 0.7516143 | Mae Loss: 0.3753863 | SMAPE: 49.1029396 | MASE: 3.5268209
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.5004916 | Vali Loss: 0.1371728 | Test Loss: 0.7422717 | Mae Loss: 0.3032169 | SMAPE: 37.6573105 | MASE: 3.0503016
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.5125884 | Vali Loss: 0.1566618 | Test Loss: 0.7148784 | Mae Loss: 0.3342141 | SMAPE: 42.9283829 | MASE: 3.0769911
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.5057954 | Vali Loss: 0.2362372 | Test Loss: 0.6397734 | Mae Loss: 0.4384033 | SMAPE: 34.9904823 | MASE: 2.8449101
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.4752754 | Vali Loss: 0.2108615 | Test Loss: 0.6440982 | Mae Loss: 0.4146518 | SMAPE: 38.4045410 | MASE: 3.1206074
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.4785443 | Vali Loss: 0.1634496 | Test Loss: 0.6352059 | Mae Loss: 0.3444114 | SMAPE: 42.7322311 | MASE: 3.1946902
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.4841753 | Vali Loss: 0.1866386 | Test Loss: 0.6389586 | Mae Loss: 0.3846791 | SMAPE: 45.7406921 | MASE: 3.2872963
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.4876258 | Vali Loss: 0.1868180 | Test Loss: 0.6406187 | Mae Loss: 0.3812360 | SMAPE: 44.9938202 | MASE: 3.4138405
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.4618996 | Vali Loss: 0.1484056 | Test Loss: 0.6408696 | Mae Loss: 0.3308941 | SMAPE: 46.1935387 | MASE: 3.3571527
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.6730562 | Vali Loss: 0.1358283 | Test Loss: 0.7796456 | Mae Loss: 0.3278358 | SMAPE: 34.0563545 | MASE: 2.8060935
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.6217067 | Vali Loss: 0.1332405 | Test Loss: 0.9227150 | Mae Loss: 0.2927772 | SMAPE: 30.6541500 | MASE: 2.7043645
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.5817119 | Vali Loss: 0.1437218 | Test Loss: 0.8838960 | Mae Loss: 0.3210432 | SMAPE: 28.5527706 | MASE: 2.3649521
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.5999499 | Vali Loss: 0.1088826 | Test Loss: 0.8912253 | Mae Loss: 0.2819774 | SMAPE: 30.6420841 | MASE: 2.5506082
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.6066365 | Vali Loss: 0.1257122 | Test Loss: 0.8643152 | Mae Loss: 0.3002629 | SMAPE: 26.9259090 | MASE: 2.2419543
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.5908045 | Vali Loss: 0.1464149 | Test Loss: 0.8747754 | Mae Loss: 0.3271871 | SMAPE: 33.5319710 | MASE: 2.7884147
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.6140966 | Vali Loss: 0.1192354 | Test Loss: 0.8761812 | Mae Loss: 0.2901870 | SMAPE: 27.6274414 | MASE: 2.3790841
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.6159868 | Vali Loss: 0.1362625 | Test Loss: 0.8793250 | Mae Loss: 0.3079895 | SMAPE: 29.4772243 | MASE: 2.4545076
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.5928633 | Vali Loss: 0.1325492 | Test Loss: 0.8802246 | Mae Loss: 0.3020164 | SMAPE: 35.1299477 | MASE: 3.0123417
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.6020158 | Vali Loss: 0.1054190 | Test Loss: 0.8805008 | Mae Loss: 0.2770326 | SMAPE: 27.6133175 | MASE: 2.3362622
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.9798947 | Vali Loss: 0.1900776 | Test Loss: 0.9479715 | Mae Loss: 0.3396743 | SMAPE: 32.8273773 | MASE: 3.2218349
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.6908404 | Vali Loss: 0.3161456 | Test Loss: 1.1313753 | Mae Loss: 0.4798094 | SMAPE: 42.8132401 | MASE: 4.5758424
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.6670560 | Vali Loss: 0.0924100 | Test Loss: 0.7346600 | Mae Loss: 0.2306157 | SMAPE: 26.8229694 | MASE: 2.4392135
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.6941992 | Vali Loss: 0.1891857 | Test Loss: 1.0396364 | Mae Loss: 0.3686272 | SMAPE: 31.1014767 | MASE: 3.1121669
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.6813248 | Vali Loss: 0.2130049 | Test Loss: 1.0205361 | Mae Loss: 0.3808874 | SMAPE: 34.3272209 | MASE: 3.4848428
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.6554080 | Vali Loss: 0.2475305 | Test Loss: 1.0091826 | Mae Loss: 0.4183452 | SMAPE: 33.3305969 | MASE: 3.3082047
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.6181184 | Vali Loss: 0.1984109 | Test Loss: 1.0082918 | Mae Loss: 0.3669771 | SMAPE: 31.9417896 | MASE: 3.1649144
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.6785846 | Vali Loss: 0.1820270 | Test Loss: 1.0062627 | Mae Loss: 0.3472312 | SMAPE: 33.8104706 | MASE: 3.4150722
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.7043611 | Vali Loss: 0.2577054 | Test Loss: 1.0004654 | Mae Loss: 0.4287172 | SMAPE: 33.0789566 | MASE: 3.2806225
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.6564186 | Vali Loss: 0.1905952 | Test Loss: 0.9991991 | Mae Loss: 0.3600970 | SMAPE: 33.3740044 | MASE: 3.2816336
