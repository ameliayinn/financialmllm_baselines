seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0883867 | Vali Loss: 0.1662271 | Test Loss: 0.0728543 | Mae Loss: 0.3582090 | SMAPE: 42.4599991 | MASE: 3.2716773
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0781455 | Vali Loss: 0.1223043 | Test Loss: 0.0432200 | Mae Loss: 0.3002273 | SMAPE: 28.0302258 | MASE: 2.3245130
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0605417 | Vali Loss: 0.0830103 | Test Loss: 0.0386227 | Mae Loss: 0.2374193 | SMAPE: 23.2727947 | MASE: 1.6736122
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0414072 | Vali Loss: 0.0636318 | Test Loss: 0.0397840 | Mae Loss: 0.2056985 | SMAPE: 24.9154396 | MASE: 2.1193240
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0362510 | Vali Loss: 0.0579023 | Test Loss: 0.0384088 | Mae Loss: 0.1935698 | SMAPE: 20.0032806 | MASE: 1.5177578
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0407236 | Vali Loss: 0.0628641 | Test Loss: 0.0374531 | Mae Loss: 0.2046958 | SMAPE: 21.1215534 | MASE: 1.5160069
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0402791 | Vali Loss: 0.0626709 | Test Loss: 0.0371356 | Mae Loss: 0.2037435 | SMAPE: 26.3377018 | MASE: 1.8346856
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0369708 | Vali Loss: 0.0627233 | Test Loss: 0.0367123 | Mae Loss: 0.2034755 | SMAPE: 23.1063290 | MASE: 1.7164910
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0396662 | Vali Loss: 0.0602944 | Test Loss: 0.0367936 | Mae Loss: 0.1973018 | SMAPE: 24.4992943 | MASE: 1.7764804
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0346954 | Vali Loss: 0.0626119 | Test Loss: 0.0366606 | Mae Loss: 0.2032218 | SMAPE: 20.2773533 | MASE: 1.3741425
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.2076869 | Vali Loss: 0.1099516 | Test Loss: 0.1404839 | Mae Loss: 0.2723409 | SMAPE: 29.0123577 | MASE: 2.5671613
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1538487 | Vali Loss: 0.1426275 | Test Loss: 0.1320060 | Mae Loss: 0.3152276 | SMAPE: 35.1657372 | MASE: 3.4298153
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.1191633 | Vali Loss: 0.1144565 | Test Loss: 0.0703559 | Mae Loss: 0.2883800 | SMAPE: 29.6012650 | MASE: 2.6502223
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0886804 | Vali Loss: 0.1099422 | Test Loss: 0.0723215 | Mae Loss: 0.2881347 | SMAPE: 28.0769997 | MASE: 2.4166713
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0664454 | Vali Loss: 0.0876476 | Test Loss: 0.0510186 | Mae Loss: 0.2701470 | SMAPE: 29.9535236 | MASE: 2.5465498
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0684679 | Vali Loss: 0.1224495 | Test Loss: 0.0507445 | Mae Loss: 0.2956358 | SMAPE: 31.7054119 | MASE: 2.6552844
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0658516 | Vali Loss: 0.1281208 | Test Loss: 0.0495793 | Mae Loss: 0.3031245 | SMAPE: 29.2757721 | MASE: 2.3989587
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0645478 | Vali Loss: 0.1356838 | Test Loss: 0.0442697 | Mae Loss: 0.3182567 | SMAPE: 31.8695164 | MASE: 2.4826305
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0697071 | Vali Loss: 0.1113136 | Test Loss: 0.0436377 | Mae Loss: 0.2954748 | SMAPE: 28.1832428 | MASE: 2.3341825
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0652349 | Vali Loss: 0.1178345 | Test Loss: 0.0439494 | Mae Loss: 0.2911763 | SMAPE: 32.6617470 | MASE: 2.9983597
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.3029532 | Vali Loss: 0.1901218 | Test Loss: 0.1692877 | Mae Loss: 0.3562590 | SMAPE: 27.8738194 | MASE: 2.4327681
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.2350446 | Vali Loss: 0.1792986 | Test Loss: 0.1677045 | Mae Loss: 0.3423370 | SMAPE: 34.7292023 | MASE: 3.1223657
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.2404647 | Vali Loss: 0.1289337 | Test Loss: 0.1831810 | Mae Loss: 0.2953191 | SMAPE: 27.8816662 | MASE: 2.5388005
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.2212234 | Vali Loss: 0.1707166 | Test Loss: 0.1651050 | Mae Loss: 0.3384454 | SMAPE: 35.9963341 | MASE: 3.3020186
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.2217143 | Vali Loss: 0.1938101 | Test Loss: 0.1639192 | Mae Loss: 0.3727078 | SMAPE: 26.1194878 | MASE: 2.2543440
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.2260328 | Vali Loss: 0.2045368 | Test Loss: 0.1681406 | Mae Loss: 0.3903817 | SMAPE: 28.8523045 | MASE: 2.5855708
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.2255968 | Vali Loss: 0.1947038 | Test Loss: 0.1671275 | Mae Loss: 0.3791112 | SMAPE: 37.4304161 | MASE: 3.1372161
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.2248023 | Vali Loss: 0.1901457 | Test Loss: 0.1657426 | Mae Loss: 0.3635573 | SMAPE: 33.8407211 | MASE: 3.1262507
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.2146789 | Vali Loss: 0.1728513 | Test Loss: 0.1643095 | Mae Loss: 0.3485476 | SMAPE: 33.2349243 | MASE: 3.0592682
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.2073914 | Vali Loss: 0.1505587 | Test Loss: 0.1634932 | Mae Loss: 0.3217774 | SMAPE: 36.9794731 | MASE: 3.1922195
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3752295 | Vali Loss: 0.1495070 | Test Loss: 0.1527863 | Mae Loss: 0.3118374 | SMAPE: 29.4053917 | MASE: 2.6671822
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.2639685 | Vali Loss: 0.1229643 | Test Loss: 0.1453090 | Mae Loss: 0.2964610 | SMAPE: 27.4203072 | MASE: 2.4020057
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2725212 | Vali Loss: 0.1329231 | Test Loss: 0.1506879 | Mae Loss: 0.2995137 | SMAPE: 33.4265633 | MASE: 3.0926054
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.2524484 | Vali Loss: 0.1448206 | Test Loss: 0.1327080 | Mae Loss: 0.3062750 | SMAPE: 29.3779888 | MASE: 2.6195512
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.2458526 | Vali Loss: 0.1433509 | Test Loss: 0.1207628 | Mae Loss: 0.3090921 | SMAPE: 31.3252392 | MASE: 2.6835334
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.2029677 | Vali Loss: 0.1160015 | Test Loss: 0.1113711 | Mae Loss: 0.2763789 | SMAPE: 31.3760872 | MASE: 2.6648226
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1931361 | Vali Loss: 0.1412557 | Test Loss: 0.1025602 | Mae Loss: 0.3008327 | SMAPE: 27.8192463 | MASE: 2.5977261
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1915821 | Vali Loss: 0.1373938 | Test Loss: 0.0971907 | Mae Loss: 0.3001296 | SMAPE: 30.1604652 | MASE: 2.7053716
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1876495 | Vali Loss: 0.1500919 | Test Loss: 0.0949838 | Mae Loss: 0.3155867 | SMAPE: 26.8602066 | MASE: 2.4341214
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1774439 | Vali Loss: 0.1423818 | Test Loss: 0.0932679 | Mae Loss: 0.3022060 | SMAPE: 30.5109978 | MASE: 2.8186998
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3601016 | Vali Loss: 0.1234724 | Test Loss: 0.2003273 | Mae Loss: 0.2923129 | SMAPE: 32.1202316 | MASE: 2.8959353
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.2396642 | Vali Loss: 0.1526130 | Test Loss: 0.1401501 | Mae Loss: 0.3330497 | SMAPE: 33.5398293 | MASE: 2.9849119
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.2268524 | Vali Loss: 0.1462547 | Test Loss: 0.1379538 | Mae Loss: 0.3077425 | SMAPE: 30.4031734 | MASE: 2.7593167
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.2356494 | Vali Loss: 0.1585635 | Test Loss: 0.1360186 | Mae Loss: 0.3392189 | SMAPE: 30.7315731 | MASE: 2.9074328
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2104714 | Vali Loss: 0.1528592 | Test Loss: 0.1304569 | Mae Loss: 0.3239889 | SMAPE: 33.8191376 | MASE: 3.1054657
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.2191036 | Vali Loss: 0.1474059 | Test Loss: 0.1318844 | Mae Loss: 0.3239521 | SMAPE: 33.1220207 | MASE: 3.0141473
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2137502 | Vali Loss: 0.1608444 | Test Loss: 0.1325759 | Mae Loss: 0.3384749 | SMAPE: 34.6602097 | MASE: 3.1069651
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.2153960 | Vali Loss: 0.1561816 | Test Loss: 0.1320653 | Mae Loss: 0.3210093 | SMAPE: 33.4873962 | MASE: 3.0162804
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.2091065 | Vali Loss: 0.1509609 | Test Loss: 0.1323183 | Mae Loss: 0.3263167 | SMAPE: 35.0814247 | MASE: 3.2077651
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.2256586 | Vali Loss: 0.1468912 | Test Loss: 0.1324113 | Mae Loss: 0.3213100 | SMAPE: 36.4630775 | MASE: 3.3605556
