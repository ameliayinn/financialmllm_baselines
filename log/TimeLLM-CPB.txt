seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.1325677 | Vali Loss: 0.0449224 | Test Loss: 0.0907008 | Mae Loss: 0.1449995 | SMAPE: 4.4023261 | MASE: 1.0113800
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.1136107 | Vali Loss: 0.0458633 | Test Loss: 0.0905642 | Mae Loss: 0.1497162 | SMAPE: 5.2989521 | MASE: 1.2991894
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.1319068 | Vali Loss: 0.0451461 | Test Loss: 0.0914514 | Mae Loss: 0.1458256 | SMAPE: 7.2666421 | MASE: 1.2758046
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.1340719 | Vali Loss: 0.0437414 | Test Loss: 0.0922113 | Mae Loss: 0.1431651 | SMAPE: 5.5972323 | MASE: 1.2913004
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.1331122 | Vali Loss: 0.0445585 | Test Loss: 0.0929580 | Mae Loss: 0.1440471 | SMAPE: 5.1211329 | MASE: 1.1474882
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1224472 | Vali Loss: 0.0453076 | Test Loss: 0.0936427 | Mae Loss: 0.1486449 | SMAPE: 4.1478992 | MASE: 1.0561846
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.1334864 | Vali Loss: 0.0452364 | Test Loss: 0.0943390 | Mae Loss: 0.1481012 | SMAPE: 5.7027574 | MASE: 1.2371324
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.1325897 | Vali Loss: 0.0450961 | Test Loss: 0.0949469 | Mae Loss: 0.1481929 | SMAPE: 5.8253369 | MASE: 1.3799666
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.1318383 | Vali Loss: 0.0451296 | Test Loss: 0.0952978 | Mae Loss: 0.1489046 | SMAPE: 6.0727739 | MASE: 1.2525403
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.1247275 | Vali Loss: 0.0449728 | Test Loss: 0.0956097 | Mae Loss: 0.1479152 | SMAPE: 4.0906115 | MASE: 1.1736733
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.2113782 | Vali Loss: 0.0483218 | Test Loss: 0.3408238 | Mae Loss: 0.1722213 | SMAPE: 7.4714327 | MASE: 1.4192845
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1753097 | Vali Loss: 0.0490959 | Test Loss: 0.3498307 | Mae Loss: 0.1775095 | SMAPE: 10.4361048 | MASE: 2.1123850
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.1696113 | Vali Loss: 0.0358368 | Test Loss: 0.3151508 | Mae Loss: 0.1585450 | SMAPE: 7.5567112 | MASE: 1.6343497
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.1693101 | Vali Loss: 0.0340602 | Test Loss: 0.3428340 | Mae Loss: 0.1472745 | SMAPE: 7.2994380 | MASE: 1.5426880
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.1691799 | Vali Loss: 0.0335665 | Test Loss: 0.2825463 | Mae Loss: 0.1532766 | SMAPE: 5.3918591 | MASE: 1.0618113
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.1727573 | Vali Loss: 0.0235767 | Test Loss: 0.2962975 | Mae Loss: 0.1234025 | SMAPE: 8.8098946 | MASE: 1.7581795
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.1624040 | Vali Loss: 0.0348741 | Test Loss: 0.3031087 | Mae Loss: 0.1533775 | SMAPE: 6.8255978 | MASE: 1.8105085
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.1578859 | Vali Loss: 0.0255955 | Test Loss: 0.3075934 | Mae Loss: 0.1262990 | SMAPE: 9.7108889 | MASE: 2.0884337
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.1658370 | Vali Loss: 0.0444364 | Test Loss: 0.3090925 | Mae Loss: 0.1746970 | SMAPE: 10.2310944 | MASE: 1.7909650
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.1577799 | Vali Loss: 0.0348429 | Test Loss: 0.3101957 | Mae Loss: 0.1547207 | SMAPE: 7.9593749 | MASE: 1.3707463
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.2666309 | Vali Loss: 0.2362221 | Test Loss: 0.4908120 | Mae Loss: 0.4190136 | SMAPE: 17.9284267 | MASE: 3.8196757
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.2112956 | Vali Loss: 0.0775776 | Test Loss: 0.4296089 | Mae Loss: 0.2372485 | SMAPE: 15.3847666 | MASE: 3.5322742
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.2019184 | Vali Loss: 0.0629253 | Test Loss: 0.3701856 | Mae Loss: 0.2002089 | SMAPE: 11.7352591 | MASE: 2.1486537
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1936281 | Vali Loss: 0.0681947 | Test Loss: 0.3975204 | Mae Loss: 0.2257558 | SMAPE: 14.7428541 | MASE: 3.0448236
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1949987 | Vali Loss: 0.0795230 | Test Loss: 0.3948829 | Mae Loss: 0.2480562 | SMAPE: 12.4054956 | MASE: 2.4009099
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1777261 | Vali Loss: 0.0838872 | Test Loss: 0.4071646 | Mae Loss: 0.2520085 | SMAPE: 12.1290121 | MASE: 2.1788080
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.1854139 | Vali Loss: 0.0768897 | Test Loss: 0.3969816 | Mae Loss: 0.2376081 | SMAPE: 12.6892967 | MASE: 3.1368999
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1992174 | Vali Loss: 0.0754486 | Test Loss: 0.3926866 | Mae Loss: 0.2389809 | SMAPE: 14.3665867 | MASE: 2.7828603
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1942137 | Vali Loss: 0.0667258 | Test Loss: 0.3909497 | Mae Loss: 0.2218603 | SMAPE: 13.3818817 | MASE: 3.4754283
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.1885620 | Vali Loss: 0.0594141 | Test Loss: 0.3905647 | Mae Loss: 0.2044403 | SMAPE: 13.1431656 | MASE: 2.7295122
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3796736 | Vali Loss: 0.1706801 | Test Loss: 0.4205844 | Mae Loss: 0.3230879 | SMAPE: 17.3496113 | MASE: 3.1934338
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.2429922 | Vali Loss: 0.1248606 | Test Loss: 0.4330469 | Mae Loss: 0.2799957 | SMAPE: 15.7677679 | MASE: 2.7298810
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2267986 | Vali Loss: 0.1303149 | Test Loss: 0.4104836 | Mae Loss: 0.2833005 | SMAPE: 13.8372526 | MASE: 2.7393804
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.2098873 | Vali Loss: 0.1066427 | Test Loss: 0.3957142 | Mae Loss: 0.2465959 | SMAPE: 17.2469730 | MASE: 3.0952055
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.2224108 | Vali Loss: 0.1063346 | Test Loss: 0.4128217 | Mae Loss: 0.2454240 | SMAPE: 11.6030092 | MASE: 2.3385403
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.2267089 | Vali Loss: 0.1111304 | Test Loss: 0.4160499 | Mae Loss: 0.2492177 | SMAPE: 16.8565006 | MASE: 3.0060890
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.2158415 | Vali Loss: 0.0755207 | Test Loss: 0.4217118 | Mae Loss: 0.1995061 | SMAPE: 11.7704000 | MASE: 2.3964286
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.2296107 | Vali Loss: 0.1197287 | Test Loss: 0.4223476 | Mae Loss: 0.2645965 | SMAPE: 13.5152731 | MASE: 2.5045147
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.2200601 | Vali Loss: 0.0874777 | Test Loss: 0.4234237 | Mae Loss: 0.2167385 | SMAPE: 14.0178356 | MASE: 2.4770899
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.2246245 | Vali Loss: 0.0957331 | Test Loss: 0.4233771 | Mae Loss: 0.2324503 | SMAPE: 12.5414658 | MASE: 2.4129989
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.4258766 | Vali Loss: 0.0945859 | Test Loss: 0.6231677 | Mae Loss: 0.2491393 | SMAPE: 16.4501152 | MASE: 3.2165365
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.2695547 | Vali Loss: 0.1459005 | Test Loss: 0.4927984 | Mae Loss: 0.3165878 | SMAPE: 15.3862896 | MASE: 2.7845557
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.2670819 | Vali Loss: 0.1554489 | Test Loss: 0.4485632 | Mae Loss: 0.3309568 | SMAPE: 18.7997608 | MASE: 3.4305007
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.2674710 | Vali Loss: 0.1849294 | Test Loss: 0.4365359 | Mae Loss: 0.3796999 | SMAPE: 16.4703693 | MASE: 3.3737276
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2579751 | Vali Loss: 0.1428697 | Test Loss: 0.4647218 | Mae Loss: 0.3166926 | SMAPE: 13.8438892 | MASE: 2.7956049
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.2515751 | Vali Loss: 0.1800243 | Test Loss: 0.4548820 | Mae Loss: 0.3635931 | SMAPE: 17.6991386 | MASE: 3.3381350
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2502927 | Vali Loss: 0.1701934 | Test Loss: 0.4530043 | Mae Loss: 0.3571146 | SMAPE: 16.0523033 | MASE: 3.1078498
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.2570340 | Vali Loss: 0.1453680 | Test Loss: 0.4493426 | Mae Loss: 0.3222301 | SMAPE: 15.2886715 | MASE: 2.9655464
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.2517693 | Vali Loss: 0.1958169 | Test Loss: 0.4481716 | Mae Loss: 0.3836942 | SMAPE: 16.8277569 | MASE: 3.2481143
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.2779012 | Vali Loss: 0.1616966 | Test Loss: 0.4475878 | Mae Loss: 0.3459439 | SMAPE: 15.2637539 | MASE: 3.0295246
