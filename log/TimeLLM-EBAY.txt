seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2224258 | Vali Loss: 0.1133922 | Test Loss: 0.2773298 | Mae Loss: 0.2722980 | SMAPE: 13.7601461 | MASE: 1.9688267
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.1734398 | Vali Loss: 0.0653238 | Test Loss: 0.1373593 | Mae Loss: 0.2051139 | SMAPE: 12.9010420 | MASE: 2.2443738
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.1420733 | Vali Loss: 0.0635505 | Test Loss: 0.1174332 | Mae Loss: 0.2064490 | SMAPE: 10.9580059 | MASE: 2.0115325
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.1195718 | Vali Loss: 0.0452143 | Test Loss: 0.1002790 | Mae Loss: 0.1617295 | SMAPE: 8.2232256 | MASE: 1.6355680
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.1127991 | Vali Loss: 0.0371046 | Test Loss: 0.1083478 | Mae Loss: 0.1434638 | SMAPE: 8.5448627 | MASE: 1.5445772
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1152889 | Vali Loss: 0.0462704 | Test Loss: 0.1126852 | Mae Loss: 0.1575690 | SMAPE: 6.8139033 | MASE: 1.1483287
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.1033141 | Vali Loss: 0.0450484 | Test Loss: 0.1118960 | Mae Loss: 0.1593170 | SMAPE: 9.4318752 | MASE: 1.6063331
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.1147398 | Vali Loss: 0.0448720 | Test Loss: 0.1112618 | Mae Loss: 0.1576396 | SMAPE: 10.7355499 | MASE: 1.8679637
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0943516 | Vali Loss: 0.0466873 | Test Loss: 0.1118126 | Mae Loss: 0.1614013 | SMAPE: 6.8737173 | MASE: 1.4209964
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.1058097 | Vali Loss: 0.0462480 | Test Loss: 0.1119848 | Mae Loss: 0.1605665 | SMAPE: 8.1152744 | MASE: 1.1030850
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.3647596 | Vali Loss: 0.3687847 | Test Loss: 0.6120242 | Mae Loss: 0.4866745 | SMAPE: 19.1742897 | MASE: 2.9941964
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.2902704 | Vali Loss: 0.1286854 | Test Loss: 0.5014445 | Mae Loss: 0.2879631 | SMAPE: 16.0132885 | MASE: 2.7930975
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.2007602 | Vali Loss: 0.1644105 | Test Loss: 0.3222698 | Mae Loss: 0.3198397 | SMAPE: 14.1300411 | MASE: 2.5761693
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.1806813 | Vali Loss: 0.0984554 | Test Loss: 0.2710373 | Mae Loss: 0.2618588 | SMAPE: 12.1085072 | MASE: 1.8246386
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.1625521 | Vali Loss: 0.0688361 | Test Loss: 0.2647427 | Mae Loss: 0.2238481 | SMAPE: 11.2490292 | MASE: 2.1863923
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.1718718 | Vali Loss: 0.0898968 | Test Loss: 0.2762197 | Mae Loss: 0.2491707 | SMAPE: 16.0846939 | MASE: 2.4108014
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.1596506 | Vali Loss: 0.0589037 | Test Loss: 0.2647374 | Mae Loss: 0.2012964 | SMAPE: 12.3399363 | MASE: 1.7701812
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.1597633 | Vali Loss: 0.0621067 | Test Loss: 0.2638367 | Mae Loss: 0.2026834 | SMAPE: 14.5838633 | MASE: 2.3048320
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.1625832 | Vali Loss: 0.0794981 | Test Loss: 0.2635178 | Mae Loss: 0.2372892 | SMAPE: 11.2861576 | MASE: 2.2652078
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.1555292 | Vali Loss: 0.0965819 | Test Loss: 0.2632910 | Mae Loss: 0.2701147 | SMAPE: 10.9545851 | MASE: 2.0250006
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.3257959 | Vali Loss: 0.4555643 | Test Loss: 0.9784257 | Mae Loss: 0.5657145 | SMAPE: 30.4203033 | MASE: 4.7949615
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.3042967 | Vali Loss: 0.3327813 | Test Loss: 1.0806424 | Mae Loss: 0.4845451 | SMAPE: 20.9299088 | MASE: 3.0918727
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.2850525 | Vali Loss: 0.5025718 | Test Loss: 1.0392564 | Mae Loss: 0.6194251 | SMAPE: 29.1309204 | MASE: 4.9983225
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.2701680 | Vali Loss: 0.3471121 | Test Loss: 1.0404448 | Mae Loss: 0.5082384 | SMAPE: 27.4097233 | MASE: 4.2872062
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.2728754 | Vali Loss: 0.3721992 | Test Loss: 0.9888957 | Mae Loss: 0.5408610 | SMAPE: 29.9010448 | MASE: 4.6808729
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.2654118 | Vali Loss: 0.3239704 | Test Loss: 0.9920601 | Mae Loss: 0.4880885 | SMAPE: 27.1768475 | MASE: 4.5251236
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.2685500 | Vali Loss: 0.4011408 | Test Loss: 0.9999283 | Mae Loss: 0.5476748 | SMAPE: 22.3073883 | MASE: 3.0815439
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.2809671 | Vali Loss: 0.2974443 | Test Loss: 1.0045833 | Mae Loss: 0.4765846 | SMAPE: 28.2230759 | MASE: 4.6273484
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.2561807 | Vali Loss: 0.3186372 | Test Loss: 1.0058333 | Mae Loss: 0.4821680 | SMAPE: 20.8359680 | MASE: 3.0413280
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.2552555 | Vali Loss: 0.4411964 | Test Loss: 1.0037088 | Mae Loss: 0.5709330 | SMAPE: 26.5239601 | MASE: 3.9994664
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2960316 | Vali Loss: 0.7635931 | Test Loss: 1.1209988 | Mae Loss: 0.8139213 | SMAPE: 42.3061676 | MASE: 6.6077714
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.2485552 | Vali Loss: 0.6852114 | Test Loss: 1.1656997 | Mae Loss: 0.7896299 | SMAPE: 37.0020599 | MASE: 5.8498001
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2463284 | Vali Loss: 0.6745681 | Test Loss: 1.1794524 | Mae Loss: 0.7741179 | SMAPE: 36.1738052 | MASE: 5.5562062
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.2479302 | Vali Loss: 0.5928964 | Test Loss: 1.1680502 | Mae Loss: 0.7128834 | SMAPE: 40.1936951 | MASE: 6.3386354
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.2399829 | Vali Loss: 0.5750306 | Test Loss: 1.1886819 | Mae Loss: 0.7049968 | SMAPE: 33.0768585 | MASE: 4.9698858
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.2352679 | Vali Loss: 0.6362367 | Test Loss: 1.1916460 | Mae Loss: 0.7520835 | SMAPE: 38.9601326 | MASE: 6.0987511
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.2319963 | Vali Loss: 0.5542129 | Test Loss: 1.1862384 | Mae Loss: 0.6873662 | SMAPE: 33.3025322 | MASE: 5.0797925
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.2225250 | Vali Loss: 0.6270390 | Test Loss: 1.1822591 | Mae Loss: 0.7401255 | SMAPE: 36.4561157 | MASE: 5.4594603
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.2370592 | Vali Loss: 0.5627996 | Test Loss: 1.1814439 | Mae Loss: 0.6891092 | SMAPE: 38.2270050 | MASE: 6.1623435
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.2257583 | Vali Loss: 0.5702244 | Test Loss: 1.1814510 | Mae Loss: 0.7010264 | SMAPE: 35.6300087 | MASE: 5.3939652
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3689302 | Vali Loss: 0.8515946 | Test Loss: 1.1072789 | Mae Loss: 0.8854942 | SMAPE: 43.1988525 | MASE: 6.4645896
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.2848116 | Vali Loss: 0.5066205 | Test Loss: 1.4412711 | Mae Loss: 0.6539356 | SMAPE: 32.1688995 | MASE: 4.8333988
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.2647486 | Vali Loss: 0.5324321 | Test Loss: 1.3696142 | Mae Loss: 0.6767476 | SMAPE: 36.0600891 | MASE: 5.6790409
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.2707744 | Vali Loss: 0.4682767 | Test Loss: 1.4198508 | Mae Loss: 0.6458289 | SMAPE: 31.7958927 | MASE: 5.0158582
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2681755 | Vali Loss: 0.4976560 | Test Loss: 1.4101732 | Mae Loss: 0.6600841 | SMAPE: 30.5998001 | MASE: 4.6619878
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.2732948 | Vali Loss: 0.5201162 | Test Loss: 1.4054156 | Mae Loss: 0.6796783 | SMAPE: 33.6796951 | MASE: 5.0865116
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2689883 | Vali Loss: 0.4820961 | Test Loss: 1.4065165 | Mae Loss: 0.6526350 | SMAPE: 31.8888512 | MASE: 4.8727694
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.2574482 | Vali Loss: 0.4703004 | Test Loss: 1.4082473 | Mae Loss: 0.6363901 | SMAPE: 30.9271507 | MASE: 4.6734962
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.2720936 | Vali Loss: 0.5097723 | Test Loss: 1.4079900 | Mae Loss: 0.6704038 | SMAPE: 31.5931644 | MASE: 4.9120574
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.2755436 | Vali Loss: 0.4878159 | Test Loss: 1.4080509 | Mae Loss: 0.6585624 | SMAPE: 30.3287086 | MASE: 4.6448245
