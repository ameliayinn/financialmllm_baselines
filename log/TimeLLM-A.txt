seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.3007095 | Vali Loss: 0.0724858 | Test Loss: 0.2316845 | SMAPE: 24.25 | MASE: 1.62
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.2742498 | Vali Loss: 0.0570407 | Test Loss: 0.1902101 | SMAPE: 33.43 | MASE: 1.46
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.2474075 | Vali Loss: 0.0613484 | Test Loss: 0.1929252 | SMAPE: 27.06 | MASE: 1.27
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.2195269 | Vali Loss: 0.0587344 | Test Loss: 0.1878344 | SMAPE: 19.05 | MASE: 1.04
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.2143205 | Vali Loss: 0.0538175 | Test Loss: 0.1861768 | SMAPE: 17.00 | MASE: 1.37
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.2072171 | Vali Loss: 0.0450861 | Test Loss: 0.1850873 | SMAPE: 29.66 | MASE: 1.03
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.2063099 | Vali Loss: 0.0544199 | Test Loss: 0.1853866 | SMAPE: 25.87 | MASE: 1.14
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.2062061 | Vali Loss: 0.0562372 | Test Loss: 0.1851931 | SMAPE: 21.47 | MASE: 1.42
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.2048847 | Vali Loss: 0.0527749 | Test Loss: 0.1851891 | SMAPE: 23.47 | MASE: 1.06
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.2033314 | Vali Loss: 0.0454009 | Test Loss: 0.1849342 | SMAPE: 38.07 | MASE: 0.99
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.3480154 | Vali Loss: 0.1979485 | Test Loss: 0.2371923 | SMAPE: 38.86 | MASE: 2.68
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.3346877 | Vali Loss: 0.1729793 | Test Loss: 0.2302789 | SMAPE: 37.47 | MASE: 2.94
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.3277524 | Vali Loss: 0.1597752 | Test Loss: 0.2238973 | SMAPE: 33.26 | MASE: 3.15
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.3007842 | Vali Loss: 0.0963299 | Test Loss: 0.1995515 | SMAPE: 45.78 | MASE: 1.44
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.2706679 | Vali Loss: 0.0852568 | Test Loss: 0.1928374 | SMAPE: 19.22 | MASE: 2.78
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.2484714 | Vali Loss: 0.0804458 | Test Loss: 0.1929807 | SMAPE: 19.63 | MASE: 1.76
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.2469389 | Vali Loss: 0.0750611 | Test Loss: 0.1924360 | SMAPE: 30.92 | MASE: 1.44
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.2442215 | Vali Loss: 0.0768084 | Test Loss: 0.1925417 | SMAPE: 17.00 | MASE: 2.41
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.2409546 | Vali Loss: 0.0759575 | Test Loss: 0.1927918 | SMAPE: 23.52 | MASE: 1.79
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.2417717 | Vali Loss: 0.0739530 | Test Loss: 0.1926932 | SMAPE: 19.63 | MASE: 2.29
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.4242978 | Vali Loss: 0.2840527 | Test Loss: 0.2681714 | SMAPE: 44.55 | MASE: 3.52
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.3903536 | Vali Loss: 0.2143235 | Test Loss: 0.2364730 | SMAPE: 37.89 | MASE: 3.13
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.3181541 | Vali Loss: 0.1200959 | Test Loss: 0.2213323 | SMAPE: 27.93 | MASE: 2.45
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.2753995 | Vali Loss: 0.0877047 | Test Loss: 0.2087632 | SMAPE: 27.77 | MASE: 1.78
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.2557149 | Vali Loss: 0.0989718 | Test Loss: 0.2092067 | SMAPE: 27.77 | MASE: 1.98
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.2515559 | Vali Loss: 0.0926342 | Test Loss: 0.2100976 | SMAPE: 25.61 | MASE: 2.00
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.2457672 | Vali Loss: 0.0787263 | Test Loss: 0.2102512 | SMAPE: 25.19 | MASE: 1.97
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.2467014 | Vali Loss: 0.0827917 | Test Loss: 0.2102288 | SMAPE: 24.96 | MASE: 1.88
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.2416288 | Vali Loss: 0.0834040 | Test Loss: 0.2103944 | SMAPE: 23.82 | MASE: 1.69
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.2421272 | Vali Loss: 0.0820824 | Test Loss: 0.2107438 | SMAPE: 21.45 | MASE: 2.19
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.4787192 | Vali Loss: 0.3039055 | Test Loss: 0.2667712 | SMAPE: 35.89 | MASE: 3.97
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.4428063 | Vali Loss: 0.2222363 | Test Loss: 0.2499365 | SMAPE: 43.52 | MASE: 2.75
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.3488904 | Vali Loss: 0.0893833 | Test Loss: 0.2498438 | SMAPE: 25.97 | MASE: 2.21
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.3021927 | Vali Loss: 0.0802438 | Test Loss: 0.2477194 | SMAPE: 27.12 | MASE: 2.32
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2867596 | Vali Loss: 0.1212082 | Test Loss: 0.2534729 | SMAPE: 28.93 | MASE: 3.06
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.2784656 | Vali Loss: 0.1121434 | Test Loss: 0.2458041 | SMAPE: 22.72 | MASE: 3.13
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2729399 | Vali Loss: 0.1193151 | Test Loss: 0.2465821 | SMAPE: 34.50 | MASE: 1.75
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.2703436 | Vali Loss: 0.1390833 | Test Loss: 0.2503432 | SMAPE: 28.66 | MASE: 3.19
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.2728198 | Vali Loss: 0.1367561 | Test Loss: 0.2493731 | SMAPE: 19.43 | MASE: 5.19
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.2691519 | Vali Loss: 0.1351987 | Test Loss: 0.2495370 | SMAPE: 31.25 | MASE: 3.02
seq_len: 150 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 1.1140483 | Vali Loss: 0.7074468 | Test Loss: 0.5279162 | Mae Loss: 0.7311068 | SMAPE: 88.5407410 | MASE: 6.8422947
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2418873 | Vali Loss: 0.0635320 | Test Loss: 0.1852331 | Mae Loss: 0.1701268 | SMAPE: 16.5859051 | MASE: 1.0940328
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2489034 | Vali Loss: 0.0580687 | Test Loss: 0.1594978 | Mae Loss: 0.1653479 | SMAPE: 32.8464966 | MASE: 1.6491727
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2418873 | Vali Loss: 0.0635320 | Test Loss: 0.1852331 | Mae Loss: 0.1701268 | SMAPE: 16.5859051 | MASE: 1.0940328
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.2322457 | Vali Loss: 0.0704312 | Test Loss: 0.1653009 | Mae Loss: 0.1899882 | SMAPE: 19.7040482 | MASE: 1.5208131
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.2205017 | Vali Loss: 0.0612564 | Test Loss: 0.1575786 | Mae Loss: 0.1895295 | SMAPE: 24.3996735 | MASE: 1.5000681
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.2003554 | Vali Loss: 0.0548089 | Test Loss: 0.1542080 | Mae Loss: 0.1711188 | SMAPE: 25.7850704 | MASE: 1.0234293
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.1861194 | Vali Loss: 0.0552191 | Test Loss: 0.1496356 | Mae Loss: 0.1712535 | SMAPE: 18.2671490 | MASE: 1.5181586
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1765476 | Vali Loss: 0.0498876 | Test Loss: 0.1488435 | Mae Loss: 0.1658829 | SMAPE: 31.9006386 | MASE: 1.2882369
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.1745080 | Vali Loss: 0.0554067 | Test Loss: 0.1488483 | Mae Loss: 0.1713640 | SMAPE: 13.4046316 | MASE: 1.6911011
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.1805925 | Vali Loss: 0.0541306 | Test Loss: 0.1491799 | Mae Loss: 0.1709773 | SMAPE: 20.7464123 | MASE: 1.4602343
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.1861986 | Vali Loss: 0.0508057 | Test Loss: 0.1491096 | Mae Loss: 0.1662245 | SMAPE: 8.1861038 | MASE: 1.3431807
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.1773326 | Vali Loss: 0.0558213 | Test Loss: 0.1491702 | Mae Loss: 0.1728143 | SMAPE: 18.4697895 | MASE: 1.2021967
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.1745603 | Vali Loss: 0.0543138 | Test Loss: 0.1490124 | Mae Loss: 0.1714256 | SMAPE: 5.9932656 | MASE: 1.4990768
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.1805368 | Vali Loss: 0.0549180 | Test Loss: 0.1489491 | Mae Loss: 0.1706836 | SMAPE: 9.1402426 | MASE: 1.3491023
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.1755372 | Vali Loss: 0.0535982 | Test Loss: 0.1490280 | Mae Loss: 0.1684574 | SMAPE: 13.4975910 | MASE: 1.2690123
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.1718618 | Vali Loss: 0.0549149 | Test Loss: 0.1490622 | Mae Loss: 0.1701291 | SMAPE: 17.0311661 | MASE: 1.2476680
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.1750683 | Vali Loss: 0.0543792 | Test Loss: 0.1489651 | Mae Loss: 0.1694345 | SMAPE: 11.4125547 | MASE: 1.0126717
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.1668492 | Vali Loss: 0.0559671 | Test Loss: 0.1490140 | Mae Loss: 0.1732509 | SMAPE: 6.2755570 | MASE: 1.7487240
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2452957 | Vali Loss: 0.0651447 | Test Loss: 0.1845617 | Mae Loss: 0.2118975 | SMAPE: 18.7199001 | MASE: 1.7548764
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.2443704 | Vali Loss: 0.0852299 | Test Loss: 0.1928537 | Mae Loss: 0.2406333 | SMAPE: 16.3329277 | MASE: 1.7293526
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.2539960 | Vali Loss: 0.0844349 | Test Loss: 0.1866639 | Mae Loss: 0.2445165 | SMAPE: 21.2920666 | MASE: 1.6459252
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.2434052 | Vali Loss: 0.0787347 | Test Loss: 0.1830619 | Mae Loss: 0.2330421 | SMAPE: 20.3604755 | MASE: 1.2812570
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.2373626 | Vali Loss: 0.0765741 | Test Loss: 0.1788968 | Mae Loss: 0.2282186 | SMAPE: 22.7431412 | MASE: 2.1684618
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.2315822 | Vali Loss: 0.0691049 | Test Loss: 0.1752150 | Mae Loss: 0.2219884 | SMAPE: 20.7731133 | MASE: 1.3691591
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.2278849 | Vali Loss: 0.0750720 | Test Loss: 0.1731866 | Mae Loss: 0.2246000 | SMAPE: 15.5606508 | MASE: 2.5592930
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.2290855 | Vali Loss: 0.0758833 | Test Loss: 0.1725245 | Mae Loss: 0.2260243 | SMAPE: 19.9482288 | MASE: 1.7199914
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.2277779 | Vali Loss: 0.0726380 | Test Loss: 0.1713204 | Mae Loss: 0.2222510 | SMAPE: 12.6528482 | MASE: 1.9955711
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.2275552 | Vali Loss: 0.0751530 | Test Loss: 0.1710795 | Mae Loss: 0.2259350 | SMAPE: 14.0344667 | MASE: 1.5304291
