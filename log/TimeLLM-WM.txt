seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.1849358 | Vali Loss: 0.3062489 | Test Loss: 0.4327173 | Mae Loss: 0.4095481 | SMAPE: 17.5153313 | MASE: 3.7168803
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.1452446 | Vali Loss: 0.2530021 | Test Loss: 0.5652519 | Mae Loss: 0.3921379 | SMAPE: 16.7751579 | MASE: 3.8052714
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.1295806 | Vali Loss: 0.1710220 | Test Loss: 0.2951115 | Mae Loss: 0.2708849 | SMAPE: 14.8227186 | MASE: 1.9859138
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0815458 | Vali Loss: 0.1322720 | Test Loss: 0.2711293 | Mae Loss: 0.2311221 | SMAPE: 12.2278852 | MASE: 1.5928373
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0897390 | Vali Loss: 0.1227787 | Test Loss: 0.2626595 | Mae Loss: 0.2047890 | SMAPE: 13.7493849 | MASE: 1.6958590
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0810555 | Vali Loss: 0.1196477 | Test Loss: 0.2528712 | Mae Loss: 0.1942161 | SMAPE: 10.2401514 | MASE: 1.2504112
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0893048 | Vali Loss: 0.0643936 | Test Loss: 0.2505723 | Mae Loss: 0.1604370 | SMAPE: 14.0130367 | MASE: 1.3798869
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0785736 | Vali Loss: 0.1273853 | Test Loss: 0.2489667 | Mae Loss: 0.2116264 | SMAPE: 11.7495203 | MASE: 1.4470493
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0822862 | Vali Loss: 0.0965517 | Test Loss: 0.2481702 | Mae Loss: 0.1812884 | SMAPE: 12.6797304 | MASE: 1.6170493
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0751727 | Vali Loss: 0.1270737 | Test Loss: 0.2477710 | Mae Loss: 0.2090453 | SMAPE: 8.2758427 | MASE: 1.4468403
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.2884352 | Vali Loss: 0.5578741 | Test Loss: 0.6695086 | Mae Loss: 0.5756449 | SMAPE: 23.9089527 | MASE: 3.5227439
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.2468215 | Vali Loss: 0.3799768 | Test Loss: 0.9323628 | Mae Loss: 0.5499172 | SMAPE: 21.4583492 | MASE: 3.6982963
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.2350150 | Vali Loss: 0.3206583 | Test Loss: 0.7419183 | Mae Loss: 0.4851653 | SMAPE: 21.0826855 | MASE: 2.3935125
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.1994776 | Vali Loss: 0.4335217 | Test Loss: 0.6110153 | Mae Loss: 0.5463915 | SMAPE: 18.9832096 | MASE: 4.2482729
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.1636032 | Vali Loss: 0.2065383 | Test Loss: 0.5950941 | Mae Loss: 0.3445373 | SMAPE: 16.0439415 | MASE: 2.1731668
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.1561739 | Vali Loss: 0.1940163 | Test Loss: 0.5483632 | Mae Loss: 0.3376309 | SMAPE: 19.1127167 | MASE: 2.2352965
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.1430275 | Vali Loss: 0.2328805 | Test Loss: 0.5368154 | Mae Loss: 0.3530588 | SMAPE: 17.3587074 | MASE: 2.1257527
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.1357942 | Vali Loss: 0.2799763 | Test Loss: 0.5338184 | Mae Loss: 0.3938347 | SMAPE: 14.4169722 | MASE: 1.6646062
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.1439600 | Vali Loss: 0.2506714 | Test Loss: 0.5310313 | Mae Loss: 0.3478125 | SMAPE: 10.3299398 | MASE: 2.0592890
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.1447832 | Vali Loss: 0.2541827 | Test Loss: 0.5301713 | Mae Loss: 0.3649060 | SMAPE: 14.6335211 | MASE: 2.4973040
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.3407527 | Vali Loss: 0.4472413 | Test Loss: 0.8480225 | Mae Loss: 0.6192074 | SMAPE: 28.5775814 | MASE: 3.9166183
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.2804893 | Vali Loss: 0.4610731 | Test Loss: 0.8058607 | Mae Loss: 0.6252655 | SMAPE: 27.6578102 | MASE: 3.1370482
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.2830639 | Vali Loss: 0.4356707 | Test Loss: 0.8386758 | Mae Loss: 0.6319848 | SMAPE: 29.5502129 | MASE: 3.8096306
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.2500713 | Vali Loss: 0.4180376 | Test Loss: 0.7784266 | Mae Loss: 0.6045451 | SMAPE: 25.2275906 | MASE: 3.4477680
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.2446650 | Vali Loss: 0.3657657 | Test Loss: 0.7610160 | Mae Loss: 0.5464341 | SMAPE: 28.2467518 | MASE: 4.2522030
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.2436203 | Vali Loss: 0.3199666 | Test Loss: 0.7416411 | Mae Loss: 0.5108387 | SMAPE: 25.9471378 | MASE: 3.6363006
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.2382361 | Vali Loss: 0.2974486 | Test Loss: 0.7405802 | Mae Loss: 0.5052640 | SMAPE: 21.9324589 | MASE: 2.9430442
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.2444035 | Vali Loss: 0.3584471 | Test Loss: 0.7368475 | Mae Loss: 0.5468805 | SMAPE: 23.4848080 | MASE: 3.1594284
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.2268742 | Vali Loss: 0.3386462 | Test Loss: 0.7325975 | Mae Loss: 0.5341297 | SMAPE: 25.5414543 | MASE: 2.5813119
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.2001720 | Vali Loss: 0.3185527 | Test Loss: 0.7312528 | Mae Loss: 0.5266898 | SMAPE: 19.2669601 | MASE: 2.3391039
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3091805 | Vali Loss: 0.5054730 | Test Loss: 1.3317955 | Mae Loss: 0.6847525 | SMAPE: 32.7577820 | MASE: 3.5488050
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.2450653 | Vali Loss: 0.5267947 | Test Loss: 1.4241877 | Mae Loss: 0.6956930 | SMAPE: 31.5456543 | MASE: 3.6836624
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2331727 | Vali Loss: 0.4490939 | Test Loss: 0.9078291 | Mae Loss: 0.6486880 | SMAPE: 26.6037159 | MASE: 2.9475510
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.2350091 | Vali Loss: 0.4635224 | Test Loss: 1.1617601 | Mae Loss: 0.6654808 | SMAPE: 31.6413822 | MASE: 3.7288594
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.2410457 | Vali Loss: 0.4632061 | Test Loss: 1.1051509 | Mae Loss: 0.6646792 | SMAPE: 28.9444809 | MASE: 3.3527751
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.2204374 | Vali Loss: 0.4742030 | Test Loss: 1.0759106 | Mae Loss: 0.6732289 | SMAPE: 28.6824532 | MASE: 3.8365335
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.2144409 | Vali Loss: 0.4414181 | Test Loss: 1.0820116 | Mae Loss: 0.6500823 | SMAPE: 29.4349728 | MASE: 2.8664675
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.2231939 | Vali Loss: 0.4760811 | Test Loss: 1.0936585 | Mae Loss: 0.6778030 | SMAPE: 29.8734512 | MASE: 3.5199101
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.2321903 | Vali Loss: 0.4618942 | Test Loss: 1.1050072 | Mae Loss: 0.6654283 | SMAPE: 30.2841778 | MASE: 3.5594692
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.2240232 | Vali Loss: 0.4592201 | Test Loss: 1.1094168 | Mae Loss: 0.6655691 | SMAPE: 29.4858150 | MASE: 3.2786899
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3768826 | Vali Loss: 0.4723984 | Test Loss: 1.4502923 | Mae Loss: 0.6441625 | SMAPE: 31.1571083 | MASE: 3.4410617
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.2573582 | Vali Loss: 0.6595489 | Test Loss: 1.7420529 | Mae Loss: 0.7660565 | SMAPE: 35.7655678 | MASE: 4.5915279
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.2679690 | Vali Loss: 0.4752269 | Test Loss: 1.5277856 | Mae Loss: 0.6492908 | SMAPE: 31.5105400 | MASE: 3.4202933
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.2442219 | Vali Loss: 0.5153217 | Test Loss: 1.4700713 | Mae Loss: 0.6886864 | SMAPE: 30.9344349 | MASE: 2.7537708
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2603848 | Vali Loss: 0.4992971 | Test Loss: 1.4871209 | Mae Loss: 0.6741381 | SMAPE: 30.8118515 | MASE: 3.1612968
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.2487273 | Vali Loss: 0.5482292 | Test Loss: 1.4878841 | Mae Loss: 0.7083428 | SMAPE: 32.3409424 | MASE: 3.4909942
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2429635 | Vali Loss: 0.5196578 | Test Loss: 1.4862709 | Mae Loss: 0.6900485 | SMAPE: 31.5471535 | MASE: 3.2739911
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.2574222 | Vali Loss: 0.4781892 | Test Loss: 1.4758624 | Mae Loss: 0.6594197 | SMAPE: 30.4764385 | MASE: 3.5523152
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.2507034 | Vali Loss: 0.5615652 | Test Loss: 1.4784390 | Mae Loss: 0.7211633 | SMAPE: 31.0514679 | MASE: 3.4539821
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.2393118 | Vali Loss: 0.4975959 | Test Loss: 1.4789644 | Mae Loss: 0.6748060 | SMAPE: 30.5201645 | MASE: 3.3983009
