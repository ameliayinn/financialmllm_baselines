seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.1542930 | Vali Loss: 0.1759194 | Test Loss: 0.2177935 | Mae Loss: 0.3747967 | SMAPE: 46.9344711 | MASE: 3.3385286
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.1380115 | Vali Loss: 0.2429479 | Test Loss: 0.2229233 | Mae Loss: 0.4392371 | SMAPE: 74.6260529 | MASE: 2.5727880
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.1588010 | Vali Loss: 0.1360691 | Test Loss: 0.2302352 | Mae Loss: 0.3213776 | SMAPE: 33.1054802 | MASE: 2.4612424
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.1439687 | Vali Loss: 0.1419048 | Test Loss: 0.2283322 | Mae Loss: 0.3338746 | SMAPE: 43.0458488 | MASE: 1.6433572
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.1435018 | Vali Loss: 0.1367796 | Test Loss: 0.2295701 | Mae Loss: 0.3235195 | SMAPE: 43.4920731 | MASE: 1.8810871
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1370028 | Vali Loss: 0.1345977 | Test Loss: 0.2310683 | Mae Loss: 0.3207932 | SMAPE: 38.3060150 | MASE: 2.1152289
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.1420553 | Vali Loss: 0.1387919 | Test Loss: 0.2304744 | Mae Loss: 0.3303124 | SMAPE: 37.3683853 | MASE: 2.2894857
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.1387564 | Vali Loss: 0.1393165 | Test Loss: 0.2306385 | Mae Loss: 0.3307447 | SMAPE: 42.4879990 | MASE: 2.2280326
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.1427691 | Vali Loss: 0.1398146 | Test Loss: 0.2304698 | Mae Loss: 0.3303871 | SMAPE: 40.4502258 | MASE: 2.5297081
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.1343793 | Vali Loss: 0.1384218 | Test Loss: 0.2310407 | Mae Loss: 0.3298405 | SMAPE: 36.8383102 | MASE: 2.2828577
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.3472916 | Vali Loss: 0.1634115 | Test Loss: 0.3122230 | Mae Loss: 0.3091280 | SMAPE: 39.7808037 | MASE: 2.3575881
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.2954935 | Vali Loss: 0.1776672 | Test Loss: 0.3260578 | Mae Loss: 0.3342612 | SMAPE: 41.0360069 | MASE: 2.3568993
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.3021510 | Vali Loss: 0.1607619 | Test Loss: 0.3030519 | Mae Loss: 0.3269376 | SMAPE: 36.7642479 | MASE: 2.1361229
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.2599275 | Vali Loss: 0.0950266 | Test Loss: 0.2430869 | Mae Loss: 0.2694089 | SMAPE: 36.2956772 | MASE: 2.2195587
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.1544408 | Vali Loss: 0.1317304 | Test Loss: 0.1964845 | Mae Loss: 0.3102329 | SMAPE: 38.5873260 | MASE: 2.2451510
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.1487806 | Vali Loss: 0.1087094 | Test Loss: 0.1862541 | Mae Loss: 0.2842926 | SMAPE: 38.2701111 | MASE: 2.4232342
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.1178344 | Vali Loss: 0.1243881 | Test Loss: 0.1840026 | Mae Loss: 0.3164706 | SMAPE: 34.0392761 | MASE: 1.9343913
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.1199021 | Vali Loss: 0.1361084 | Test Loss: 0.1789283 | Mae Loss: 0.3244477 | SMAPE: 43.2229385 | MASE: 2.2943990
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.1191402 | Vali Loss: 0.1686610 | Test Loss: 0.1766663 | Mae Loss: 0.3708327 | SMAPE: 42.1850090 | MASE: 2.6213307
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.1178370 | Vali Loss: 0.1585923 | Test Loss: 0.1767252 | Mae Loss: 0.3470792 | SMAPE: 40.4828033 | MASE: 2.7445087
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.4462349 | Vali Loss: 0.4193774 | Test Loss: 0.3473133 | Mae Loss: 0.5637459 | SMAPE: 57.4197044 | MASE: 4.4485316
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.3405371 | Vali Loss: 0.3811937 | Test Loss: 0.3306028 | Mae Loss: 0.5275740 | SMAPE: 51.3064384 | MASE: 3.1320074
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.3548333 | Vali Loss: 0.3569588 | Test Loss: 0.3215138 | Mae Loss: 0.5428627 | SMAPE: 53.6814804 | MASE: 3.8723552
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.3506445 | Vali Loss: 0.3543773 | Test Loss: 0.3184756 | Mae Loss: 0.5237103 | SMAPE: 56.8837929 | MASE: 3.5953372
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.3440883 | Vali Loss: 0.3317252 | Test Loss: 0.3266868 | Mae Loss: 0.4940587 | SMAPE: 54.3594131 | MASE: 3.9432452
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.3443070 | Vali Loss: 0.3448122 | Test Loss: 0.3190930 | Mae Loss: 0.5201594 | SMAPE: 57.2232246 | MASE: 4.6559496
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.3283386 | Vali Loss: 0.4043341 | Test Loss: 0.3181186 | Mae Loss: 0.5741343 | SMAPE: 53.2215652 | MASE: 3.4458458
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.3476941 | Vali Loss: 0.3492872 | Test Loss: 0.3171539 | Mae Loss: 0.5244994 | SMAPE: 56.6385345 | MASE: 3.9583316
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.3315470 | Vali Loss: 0.3296299 | Test Loss: 0.3167226 | Mae Loss: 0.5081832 | SMAPE: 45.9655685 | MASE: 2.8623559
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.3140851 | Vali Loss: 0.3911760 | Test Loss: 0.3167618 | Mae Loss: 0.5799781 | SMAPE: 58.4906273 | MASE: 4.1422524
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3955531 | Vali Loss: 0.3306405 | Test Loss: 0.3410980 | Mae Loss: 0.4924959 | SMAPE: 52.7968483 | MASE: 3.7226715
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.3589063 | Vali Loss: 0.4198986 | Test Loss: 0.3328240 | Mae Loss: 0.5629146 | SMAPE: 50.2139511 | MASE: 3.8013771
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.3374712 | Vali Loss: 0.4498259 | Test Loss: 0.2976526 | Mae Loss: 0.5861760 | SMAPE: 57.2335739 | MASE: 4.2843332
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.3249002 | Vali Loss: 0.4173323 | Test Loss: 0.2938342 | Mae Loss: 0.5459886 | SMAPE: 58.4295998 | MASE: 4.2551851
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.3218230 | Vali Loss: 0.5087496 | Test Loss: 0.2834801 | Mae Loss: 0.6197257 | SMAPE: 57.6465836 | MASE: 4.2253938
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.3110034 | Vali Loss: 0.4620758 | Test Loss: 0.2637386 | Mae Loss: 0.5901498 | SMAPE: 63.6487007 | MASE: 4.6113071
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.2772937 | Vali Loss: 0.4284086 | Test Loss: 0.2500045 | Mae Loss: 0.5614376 | SMAPE: 49.6179657 | MASE: 3.6177151
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.2920656 | Vali Loss: 0.4855738 | Test Loss: 0.2431138 | Mae Loss: 0.6189737 | SMAPE: 58.5347824 | MASE: 4.1172609
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.2887420 | Vali Loss: 0.4567643 | Test Loss: 0.2394524 | Mae Loss: 0.5927874 | SMAPE: 57.5640373 | MASE: 4.3020759
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.2842086 | Vali Loss: 0.4595467 | Test Loss: 0.2373224 | Mae Loss: 0.5862567 | SMAPE: 59.4937973 | MASE: 4.3986077
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.4629332 | Vali Loss: 0.5383337 | Test Loss: 0.3027725 | Mae Loss: 0.6448858 | SMAPE: 61.3692360 | MASE: 4.6359134
