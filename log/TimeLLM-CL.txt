seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.2437897 | Vali Loss: 0.0957847 | Test Loss: 0.3341723 | Mae Loss: 0.2323213 | SMAPE: 88.0512085 | MASE: 1.6084023
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.2176455 | Vali Loss: 0.1040800 | Test Loss: 0.3386140 | Mae Loss: 0.2445081 | SMAPE: 112.0022659 | MASE: 1.9907521
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.1731051 | Vali Loss: 0.0908611 | Test Loss: 0.1772699 | Mae Loss: 0.2209139 | SMAPE: 96.4497223 | MASE: 1.1784450
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.1184342 | Vali Loss: 0.1046472 | Test Loss: 0.1426594 | Mae Loss: 0.2417539 | SMAPE: 108.4510117 | MASE: 1.9236392
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.1174728 | Vali Loss: 0.0837722 | Test Loss: 0.1333821 | Mae Loss: 0.2176185 | SMAPE: 93.5972214 | MASE: 1.4122527
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1138495 | Vali Loss: 0.1050576 | Test Loss: 0.1268979 | Mae Loss: 0.2478683 | SMAPE: 80.3763657 | MASE: 1.4880514
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.1062155 | Vali Loss: 0.1074841 | Test Loss: 0.1211426 | Mae Loss: 0.2502398 | SMAPE: 93.9849167 | MASE: 1.5192255
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0806384 | Vali Loss: 0.1081912 | Test Loss: 0.1189000 | Mae Loss: 0.2490110 | SMAPE: 92.1047440 | MASE: 1.4108518
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.1100535 | Vali Loss: 0.1071072 | Test Loss: 0.1181144 | Mae Loss: 0.2442408 | SMAPE: 85.1677399 | MASE: 1.5845581
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0853170 | Vali Loss: 0.1093327 | Test Loss: 0.1176304 | Mae Loss: 0.2490518 | SMAPE: 74.4919968 | MASE: 1.6427286
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.4360978 | Vali Loss: 0.1201256 | Test Loss: 0.7949871 | Mae Loss: 0.2825395 | SMAPE: 115.2980194 | MASE: 1.5493982
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.3796397 | Vali Loss: 0.1039441 | Test Loss: 0.4145447 | Mae Loss: 0.2479140 | SMAPE: 124.7781982 | MASE: 1.4883097
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.2493593 | Vali Loss: 0.1860841 | Test Loss: 0.3558003 | Mae Loss: 0.3230938 | SMAPE: 82.9872513 | MASE: 1.2810487
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.1958777 | Vali Loss: 0.1408836 | Test Loss: 0.2388024 | Mae Loss: 0.2590663 | SMAPE: 107.8735199 | MASE: 1.8618565
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.1584856 | Vali Loss: 0.1057770 | Test Loss: 0.2710457 | Mae Loss: 0.2430924 | SMAPE: 111.8624191 | MASE: 1.6200737
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.1637875 | Vali Loss: 0.1770022 | Test Loss: 0.2954919 | Mae Loss: 0.3064063 | SMAPE: 94.6216431 | MASE: 1.7755312
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.1259786 | Vali Loss: 0.1028186 | Test Loss: 0.2907950 | Mae Loss: 0.2429625 | SMAPE: 79.8120270 | MASE: 1.9540937
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.1317527 | Vali Loss: 0.1305558 | Test Loss: 0.2893894 | Mae Loss: 0.2747919 | SMAPE: 113.8737183 | MASE: 1.7817458
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.1480977 | Vali Loss: 0.1207383 | Test Loss: 0.2871829 | Mae Loss: 0.2609448 | SMAPE: 111.4713440 | MASE: 1.6803173
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.1368315 | Vali Loss: 0.1584233 | Test Loss: 0.2863096 | Mae Loss: 0.2931381 | SMAPE: 109.7903976 | MASE: 1.4773034
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.7071769 | Vali Loss: 0.2461112 | Test Loss: 0.4808376 | Mae Loss: 0.3920087 | SMAPE: 138.0944061 | MASE: 1.9751558
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.6597260 | Vali Loss: 0.2198273 | Test Loss: 0.5016381 | Mae Loss: 0.3619707 | SMAPE: 139.1133728 | MASE: 1.8877106
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.6253198 | Vali Loss: 0.1737841 | Test Loss: 0.4387710 | Mae Loss: 0.3263483 | SMAPE: 140.1007233 | MASE: 1.8010447
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.5841990 | Vali Loss: 0.2221601 | Test Loss: 0.4256843 | Mae Loss: 0.3718902 | SMAPE: 156.6750488 | MASE: 2.1348417
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.5768010 | Vali Loss: 0.1931851 | Test Loss: 0.4338777 | Mae Loss: 0.3549941 | SMAPE: 141.6969910 | MASE: 2.2686996
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.6080783 | Vali Loss: 0.2110215 | Test Loss: 0.4428057 | Mae Loss: 0.3695981 | SMAPE: 136.4033203 | MASE: 1.7003436
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.5725403 | Vali Loss: 0.2311365 | Test Loss: 0.4430041 | Mae Loss: 0.3905762 | SMAPE: 147.6009369 | MASE: 2.3624127
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.5972414 | Vali Loss: 0.2065749 | Test Loss: 0.4419672 | Mae Loss: 0.3662982 | SMAPE: 143.7032166 | MASE: 1.8053473
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.5521969 | Vali Loss: 0.2189790 | Test Loss: 0.4402465 | Mae Loss: 0.3686518 | SMAPE: 132.0993652 | MASE: 2.1989048
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.5312431 | Vali Loss: 0.1785814 | Test Loss: 0.4391166 | Mae Loss: 0.3388116 | SMAPE: 151.0863495 | MASE: 1.8911594
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.7207059 | Vali Loss: 0.2353377 | Test Loss: 0.4342772 | Mae Loss: 0.3912994 | SMAPE: 150.7951202 | MASE: 2.0536239
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.6491974 | Vali Loss: 0.1479690 | Test Loss: 0.2853221 | Mae Loss: 0.3290640 | SMAPE: 176.8476868 | MASE: 2.0647054
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.6152298 | Vali Loss: 0.1925811 | Test Loss: 0.3023969 | Mae Loss: 0.3422535 | SMAPE: 175.5335693 | MASE: 2.1827512
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.5252611 | Vali Loss: 0.2167413 | Test Loss: 0.2791424 | Mae Loss: 0.3624499 | SMAPE: 158.2077332 | MASE: 1.8133262
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.4277947 | Vali Loss: 0.1893296 | Test Loss: 0.2673256 | Mae Loss: 0.3323671 | SMAPE: 130.5349274 | MASE: 1.7999583
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.3161516 | Vali Loss: 0.1584895 | Test Loss: 0.2731004 | Mae Loss: 0.2945092 | SMAPE: 141.8395844 | MASE: 1.7541456
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.2904040 | Vali Loss: 0.1846678 | Test Loss: 0.2723767 | Mae Loss: 0.3265431 | SMAPE: 124.8340149 | MASE: 1.8162411
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.2820488 | Vali Loss: 0.1488924 | Test Loss: 0.2719527 | Mae Loss: 0.2949867 | SMAPE: 128.5880890 | MASE: 1.7580525
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.2759581 | Vali Loss: 0.2020549 | Test Loss: 0.2732192 | Mae Loss: 0.3440170 | SMAPE: 130.5591583 | MASE: 1.6853122
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.2787102 | Vali Loss: 0.1798405 | Test Loss: 0.2736413 | Mae Loss: 0.3245506 | SMAPE: 130.4870148 | MASE: 1.7000433
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.7752948 | Vali Loss: 0.1871032 | Test Loss: 0.2051747 | Mae Loss: 0.3520378 | SMAPE: 180.4907837 | MASE: 2.2951612
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.6396536 | Vali Loss: 0.2015528 | Test Loss: 0.1991338 | Mae Loss: 0.3620414 | SMAPE: 179.5015869 | MASE: 2.1566668
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.6202446 | Vali Loss: 0.2670004 | Test Loss: 0.1957373 | Mae Loss: 0.3994979 | SMAPE: 184.4723969 | MASE: 2.0926530
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.6197630 | Vali Loss: 0.1783410 | Test Loss: 0.1889933 | Mae Loss: 0.3528159 | SMAPE: 194.4363556 | MASE: 2.2788646
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.6067185 | Vali Loss: 0.2251223 | Test Loss: 0.1943107 | Mae Loss: 0.3761307 | SMAPE: 191.0655212 | MASE: 2.2244678
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.5905725 | Vali Loss: 0.1852546 | Test Loss: 0.1921316 | Mae Loss: 0.3454691 | SMAPE: 193.8631287 | MASE: 2.2133336
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.5960674 | Vali Loss: 0.2090557 | Test Loss: 0.1914525 | Mae Loss: 0.3703388 | SMAPE: 195.3667755 | MASE: 2.1337755
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.6067515 | Vali Loss: 0.2774000 | Test Loss: 0.1907798 | Mae Loss: 0.4145589 | SMAPE: 193.1979218 | MASE: 2.2750340
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.5985298 | Vali Loss: 0.2180516 | Test Loss: 0.1905301 | Mae Loss: 0.3687872 | SMAPE: 195.6629333 | MASE: 2.2617278
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.5948647 | Vali Loss: 0.2172217 | Test Loss: 0.1902960 | Mae Loss: 0.3732238 | SMAPE: 195.3537140 | MASE: 2.1844058
