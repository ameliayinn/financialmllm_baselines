seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.1724856 | Vali Loss: 0.0575949 | Test Loss: 0.1476816 | Mae Loss: 0.1953486 | SMAPE: 47.3118401 | MASE: 1.0890046
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.1371112 | Vali Loss: 0.1074656 | Test Loss: 0.1551066 | Mae Loss: 0.2450666 | SMAPE: 63.3679504 | MASE: 2.0328894
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.1267047 | Vali Loss: 0.1175882 | Test Loss: 0.1600196 | Mae Loss: 0.2599142 | SMAPE: 53.5418930 | MASE: 1.9318205
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.1182702 | Vali Loss: 0.0918940 | Test Loss: 0.1310980 | Mae Loss: 0.2271943 | SMAPE: 35.2532463 | MASE: 1.3307735
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.1106976 | Vali Loss: 0.0841222 | Test Loss: 0.1243297 | Mae Loss: 0.2145799 | SMAPE: 56.3177338 | MASE: 1.7930129
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.1025947 | Vali Loss: 0.0825402 | Test Loss: 0.1109916 | Mae Loss: 0.2181243 | SMAPE: 55.4110870 | MASE: 1.6759354
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0983897 | Vali Loss: 0.0728423 | Test Loss: 0.0975341 | Mae Loss: 0.2061863 | SMAPE: 41.1806335 | MASE: 1.2865189
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0858633 | Vali Loss: 0.0635205 | Test Loss: 0.0924005 | Mae Loss: 0.1923688 | SMAPE: 41.2415352 | MASE: 1.2821295
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0760580 | Vali Loss: 0.0688907 | Test Loss: 0.0901867 | Mae Loss: 0.2042863 | SMAPE: 30.5566311 | MASE: 1.0007764
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0892746 | Vali Loss: 0.0599195 | Test Loss: 0.0892504 | Mae Loss: 0.1878022 | SMAPE: 54.5412712 | MASE: 1.5643598
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.2855312 | Vali Loss: 0.1539664 | Test Loss: 0.1241785 | Mae Loss: 0.3269792 | SMAPE: 56.7457275 | MASE: 2.2177570
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.2209223 | Vali Loss: 0.2159594 | Test Loss: 0.1740057 | Mae Loss: 0.4177945 | SMAPE: 49.1802292 | MASE: 2.4608762
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.2142965 | Vali Loss: 0.1576763 | Test Loss: 0.1254797 | Mae Loss: 0.3424413 | SMAPE: 43.7269669 | MASE: 1.9368980
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.2078556 | Vali Loss: 0.1212773 | Test Loss: 0.1217849 | Mae Loss: 0.2875377 | SMAPE: 62.7340775 | MASE: 2.4335093
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.1935271 | Vali Loss: 0.1369716 | Test Loss: 0.1283113 | Mae Loss: 0.3141535 | SMAPE: 57.7484589 | MASE: 2.3071351
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.1987804 | Vali Loss: 0.1459309 | Test Loss: 0.1228867 | Mae Loss: 0.3259264 | SMAPE: 51.6561737 | MASE: 2.2911510
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.1993023 | Vali Loss: 0.1371187 | Test Loss: 0.1221145 | Mae Loss: 0.3081026 | SMAPE: 64.3844833 | MASE: 2.2746689
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.2003002 | Vali Loss: 0.1285053 | Test Loss: 0.1217272 | Mae Loss: 0.2977839 | SMAPE: 35.6623154 | MASE: 1.7013834
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.1957962 | Vali Loss: 0.1529212 | Test Loss: 0.1221366 | Mae Loss: 0.3224744 | SMAPE: 58.2047272 | MASE: 2.3011777
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.1938297 | Vali Loss: 0.1515158 | Test Loss: 0.1222846 | Mae Loss: 0.3240760 | SMAPE: 62.7586670 | MASE: 2.3519592
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.3336242 | Vali Loss: 0.2046921 | Test Loss: 0.1512844 | Mae Loss: 0.3898186 | SMAPE: 60.8749466 | MASE: 2.6726086
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.2963939 | Vali Loss: 0.2644111 | Test Loss: 0.1550163 | Mae Loss: 0.4776553 | SMAPE: 57.7679024 | MASE: 3.0819359
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.2623846 | Vali Loss: 0.2130393 | Test Loss: 0.1572906 | Mae Loss: 0.4187390 | SMAPE: 58.5519905 | MASE: 2.8622770
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.2130308 | Vali Loss: 0.1582565 | Test Loss: 0.1537467 | Mae Loss: 0.3240669 | SMAPE: 42.4414635 | MASE: 1.8701217
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1943005 | Vali Loss: 0.1373802 | Test Loss: 0.1540144 | Mae Loss: 0.3035057 | SMAPE: 59.3873253 | MASE: 2.4831169
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1772082 | Vali Loss: 0.1420440 | Test Loss: 0.1456110 | Mae Loss: 0.3081181 | SMAPE: 45.6607475 | MASE: 2.1122882
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.1738549 | Vali Loss: 0.1406158 | Test Loss: 0.1464495 | Mae Loss: 0.2980913 | SMAPE: 56.6539764 | MASE: 2.4338553
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1621839 | Vali Loss: 0.1390110 | Test Loss: 0.1470725 | Mae Loss: 0.3033940 | SMAPE: 37.7783432 | MASE: 1.7562219
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1643819 | Vali Loss: 0.1458988 | Test Loss: 0.1481330 | Mae Loss: 0.3112784 | SMAPE: 55.7339478 | MASE: 2.4255283
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.1787620 | Vali Loss: 0.1313431 | Test Loss: 0.1485590 | Mae Loss: 0.2878479 | SMAPE: 38.8980179 | MASE: 1.8452665
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.5265217 | Vali Loss: 0.1512878 | Test Loss: 0.1255913 | Mae Loss: 0.3187734 | SMAPE: 46.3196945 | MASE: 2.2522459
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.3697480 | Vali Loss: 0.1829821 | Test Loss: 0.1529943 | Mae Loss: 0.3891202 | SMAPE: 62.0929184 | MASE: 3.2287164
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.3420787 | Vali Loss: 0.1674031 | Test Loss: 0.1313066 | Mae Loss: 0.3480201 | SMAPE: 46.2873230 | MASE: 2.4526436
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.3415699 | Vali Loss: 0.2495084 | Test Loss: 0.1487773 | Mae Loss: 0.4461899 | SMAPE: 48.3608818 | MASE: 2.6411419
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.3350784 | Vali Loss: 0.2506089 | Test Loss: 0.1510348 | Mae Loss: 0.4514666 | SMAPE: 59.4275894 | MASE: 3.1639941
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.3168134 | Vali Loss: 0.2264746 | Test Loss: 0.1504878 | Mae Loss: 0.4319465 | SMAPE: 52.7162971 | MASE: 2.7588398
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.3257668 | Vali Loss: 0.2533819 | Test Loss: 0.1493064 | Mae Loss: 0.4557516 | SMAPE: 59.7389679 | MASE: 3.1824620
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.3229345 | Vali Loss: 0.2328551 | Test Loss: 0.1492008 | Mae Loss: 0.4335092 | SMAPE: 55.5409622 | MASE: 2.9771626
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.3270655 | Vali Loss: 0.2686698 | Test Loss: 0.1497397 | Mae Loss: 0.4687595 | SMAPE: 55.8370705 | MASE: 3.0016208
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.3207791 | Vali Loss: 0.2480886 | Test Loss: 0.1493548 | Mae Loss: 0.4493637 | SMAPE: 53.7244453 | MASE: 2.9992728
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.4367060 | Vali Loss: 0.1215314 | Test Loss: 0.1378913 | Mae Loss: 0.2719842 | SMAPE: 45.7037926 | MASE: 2.1358683
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.3461464 | Vali Loss: 0.1728261 | Test Loss: 0.1528725 | Mae Loss: 0.3665786 | SMAPE: 55.8722992 | MASE: 2.7491088
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.3179185 | Vali Loss: 0.2219647 | Test Loss: 0.1621733 | Mae Loss: 0.3977146 | SMAPE: 51.9717522 | MASE: 2.7132773
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.2911130 | Vali Loss: 0.1908864 | Test Loss: 0.1778128 | Mae Loss: 0.3984476 | SMAPE: 55.6166229 | MASE: 3.0356176
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.2949713 | Vali Loss: 0.1981367 | Test Loss: 0.1626766 | Mae Loss: 0.3951147 | SMAPE: 54.6922150 | MASE: 2.8162830
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.3093598 | Vali Loss: 0.1933615 | Test Loss: 0.1652864 | Mae Loss: 0.3932922 | SMAPE: 51.1184998 | MASE: 2.7719271
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.2983377 | Vali Loss: 0.2021891 | Test Loss: 0.1692424 | Mae Loss: 0.4050162 | SMAPE: 52.4528503 | MASE: 2.8273275
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.3080118 | Vali Loss: 0.2303764 | Test Loss: 0.1686525 | Mae Loss: 0.4274832 | SMAPE: 57.8523521 | MASE: 3.0489430
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.3015685 | Vali Loss: 0.2176450 | Test Loss: 0.1683111 | Mae Loss: 0.4192955 | SMAPE: 53.1453018 | MASE: 2.8032570
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.2853370 | Vali Loss: 0.2010624 | Test Loss: 0.1680327 | Mae Loss: 0.4016317 | SMAPE: 52.0625992 | MASE: 2.7627468
