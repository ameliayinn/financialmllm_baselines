seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.5380212 | Vali Loss: 0.2058136 | Test Loss: 0.1621085 | Mae Loss: 0.3940414 | SMAPE: 9.7017632 | MASE: 1.6256635
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.5475415 | Vali Loss: 0.1678085 | Test Loss: 0.1631938 | Mae Loss: 0.3599671 | SMAPE: 14.4789743 | MASE: 2.4174669
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.5357160 | Vali Loss: 0.1964280 | Test Loss: 0.1624307 | Mae Loss: 0.3927474 | SMAPE: 13.8167601 | MASE: 2.1498399
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.4795759 | Vali Loss: 0.1851856 | Test Loss: 0.1529161 | Mae Loss: 0.3726439 | SMAPE: 13.5139580 | MASE: 2.3907168
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.4117435 | Vali Loss: 0.1319976 | Test Loss: 0.1339498 | Mae Loss: 0.3133702 | SMAPE: 11.2266760 | MASE: 1.6573635
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.3646673 | Vali Loss: 0.1067325 | Test Loss: 0.1295041 | Mae Loss: 0.2836589 | SMAPE: 9.8627176 | MASE: 1.6953095
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.3081717 | Vali Loss: 0.0939926 | Test Loss: 0.1273019 | Mae Loss: 0.2635172 | SMAPE: 9.2498503 | MASE: 1.5528337
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.2978760 | Vali Loss: 0.0841770 | Test Loss: 0.1263799 | Mae Loss: 0.2469424 | SMAPE: 9.1888533 | MASE: 1.5947727
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.2860593 | Vali Loss: 0.0820067 | Test Loss: 0.1256397 | Mae Loss: 0.2435107 | SMAPE: 8.7701464 | MASE: 1.4579111
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.2672268 | Vali Loss: 0.0798569 | Test Loss: 0.1254853 | Mae Loss: 0.2392219 | SMAPE: 8.2292471 | MASE: 1.3873959
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.6634822 | Vali Loss: 0.1570419 | Test Loss: 0.8316718 | Mae Loss: 0.3196152 | SMAPE: 11.8121500 | MASE: 2.5283132
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.5999139 | Vali Loss: 0.3228040 | Test Loss: 0.5131244 | Mae Loss: 0.5168344 | SMAPE: 17.9538670 | MASE: 3.5080183
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.5865244 | Vali Loss: 0.3695173 | Test Loss: 0.4625967 | Mae Loss: 0.5525262 | SMAPE: 17.6699333 | MASE: 3.0206196
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.5026342 | Vali Loss: 0.2601074 | Test Loss: 0.4193931 | Mae Loss: 0.4659908 | SMAPE: 14.7963409 | MASE: 2.7340167
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.3840406 | Vali Loss: 0.1519965 | Test Loss: 0.3329546 | Mae Loss: 0.3250951 | SMAPE: 13.1992054 | MASE: 2.7124190
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.2941051 | Vali Loss: 0.0933455 | Test Loss: 0.2899230 | Mae Loss: 0.2664779 | SMAPE: 13.3714142 | MASE: 2.1884863
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.2270593 | Vali Loss: 0.0801949 | Test Loss: 0.2727729 | Mae Loss: 0.2454905 | SMAPE: 9.8194351 | MASE: 1.6097172
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.2088586 | Vali Loss: 0.0759278 | Test Loss: 0.2701249 | Mae Loss: 0.2371847 | SMAPE: 11.0447044 | MASE: 2.1610682
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.2200083 | Vali Loss: 0.0741633 | Test Loss: 0.2703404 | Mae Loss: 0.2306997 | SMAPE: 8.6142559 | MASE: 2.1000545
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.2073132 | Vali Loss: 0.0785714 | Test Loss: 0.2686974 | Mae Loss: 0.2429044 | SMAPE: 8.7944002 | MASE: 1.8666512
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.6565398 | Vali Loss: 0.7455034 | Test Loss: 0.6225016 | Mae Loss: 0.8080290 | SMAPE: 32.2599754 | MASE: 5.0298858
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.4775029 | Vali Loss: 0.8358896 | Test Loss: 0.6412004 | Mae Loss: 0.8058125 | SMAPE: 31.4425583 | MASE: 4.8652124
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.5469300 | Vali Loss: 0.6502340 | Test Loss: 0.7517409 | Mae Loss: 0.7453367 | SMAPE: 27.8964901 | MASE: 4.4873071
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.4949975 | Vali Loss: 0.6803233 | Test Loss: 0.6522338 | Mae Loss: 0.7665128 | SMAPE: 32.2735023 | MASE: 5.7336001
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.5041529 | Vali Loss: 0.6294717 | Test Loss: 0.6404667 | Mae Loss: 0.7444426 | SMAPE: 30.8931084 | MASE: 4.8805909
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.4844864 | Vali Loss: 0.4624071 | Test Loss: 0.6967531 | Mae Loss: 0.6291593 | SMAPE: 26.6137428 | MASE: 4.5494061
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.4712373 | Vali Loss: 0.4991526 | Test Loss: 0.6976890 | Mae Loss: 0.6486773 | SMAPE: 20.6631317 | MASE: 3.4570987
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.4846719 | Vali Loss: 0.4200689 | Test Loss: 0.6918801 | Mae Loss: 0.6025742 | SMAPE: 26.8273239 | MASE: 4.7585697
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.4567841 | Vali Loss: 0.4442947 | Test Loss: 0.6885000 | Mae Loss: 0.6190181 | SMAPE: 19.9119377 | MASE: 2.8886364
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.4496454 | Vali Loss: 0.5359747 | Test Loss: 0.6861132 | Mae Loss: 0.6878418 | SMAPE: 24.7222328 | MASE: 4.3901534
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.5306643 | Vali Loss: 1.9280190 | Test Loss: 0.5030787 | Mae Loss: 1.3566227 | SMAPE: 58.5412369 | MASE: 8.7349672
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.5084254 | Vali Loss: 2.4836264 | Test Loss: 0.4846503 | Mae Loss: 1.4975131 | SMAPE: 63.7759399 | MASE: 9.0536575
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.4694606 | Vali Loss: 1.7646068 | Test Loss: 0.5567679 | Mae Loss: 1.2951884 | SMAPE: 51.5183868 | MASE: 7.8086686
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.4416370 | Vali Loss: 1.7496009 | Test Loss: 0.5078350 | Mae Loss: 1.2897409 | SMAPE: 59.1649704 | MASE: 8.8798609
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.4405369 | Vali Loss: 1.6935018 | Test Loss: 0.5176870 | Mae Loss: 1.2686799 | SMAPE: 50.4633179 | MASE: 7.3745289
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.4051161 | Vali Loss: 1.7409495 | Test Loss: 0.5187046 | Mae Loss: 1.2887911 | SMAPE: 55.9672775 | MASE: 9.0917902
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.3817037 | Vali Loss: 1.5499103 | Test Loss: 0.5142631 | Mae Loss: 1.2072697 | SMAPE: 47.5283241 | MASE: 6.7197762
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.4107793 | Vali Loss: 1.6704658 | Test Loss: 0.5077399 | Mae Loss: 1.2601106 | SMAPE: 51.2799263 | MASE: 7.5911312
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.4068960 | Vali Loss: 1.5638698 | Test Loss: 0.5039333 | Mae Loss: 1.2117655 | SMAPE: 53.0358658 | MASE: 7.8330550
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.3961090 | Vali Loss: 1.5570476 | Test Loss: 0.5009192 | Mae Loss: 1.2160755 | SMAPE: 50.4851265 | MASE: 7.9442468
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.5490275 | Vali Loss: 3.1540315 | Test Loss: 0.3828947 | Mae Loss: 1.7196134 | SMAPE: 76.7572556 | MASE: 10.4932880
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.3860195 | Vali Loss: 3.6467986 | Test Loss: 0.2628652 | Mae Loss: 1.8944179 | SMAPE: 88.1599045 | MASE: 12.3276787
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.3772413 | Vali Loss: 3.7982612 | Test Loss: 0.2350568 | Mae Loss: 1.9325722 | SMAPE: 91.8645401 | MASE: 11.9469624
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.3861066 | Vali Loss: 3.7817159 | Test Loss: 0.2398709 | Mae Loss: 1.9287440 | SMAPE: 86.5719910 | MASE: 10.7544079
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.3836719 | Vali Loss: 3.6013751 | Test Loss: 0.2533359 | Mae Loss: 1.8821839 | SMAPE: 85.2526321 | MASE: 10.9769630
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.3467648 | Vali Loss: 3.6386883 | Test Loss: 0.2554068 | Mae Loss: 1.8943859 | SMAPE: 87.5682449 | MASE: 11.3641338
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.3754130 | Vali Loss: 3.5740831 | Test Loss: 0.2574302 | Mae Loss: 1.8770542 | SMAPE: 86.6302643 | MASE: 11.9540710
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.3620984 | Vali Loss: 3.5129533 | Test Loss: 0.2582350 | Mae Loss: 1.8593978 | SMAPE: 85.1001968 | MASE: 11.2190371
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.3580692 | Vali Loss: 3.6164777 | Test Loss: 0.2582659 | Mae Loss: 1.8891572 | SMAPE: 86.9143600 | MASE: 12.0236511
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.3815013 | Vali Loss: 3.5700207 | Test Loss: 0.2576571 | Mae Loss: 1.8766350 | SMAPE: 86.1724167 | MASE: 12.0253601
