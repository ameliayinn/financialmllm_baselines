seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0441736 | Vali Loss: 0.0374314 | Test Loss: 0.0408653 | Mae Loss: 0.1415581 | SMAPE: 5.1668849 | MASE: 2.6214354
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0337809 | Vali Loss: 0.0374523 | Test Loss: 0.0441170 | Mae Loss: 0.1437755 | SMAPE: 8.5093231 | MASE: 3.2980154
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0441736 | Vali Loss: 0.0374314 | Test Loss: 0.0408653 | Mae Loss: 0.1415581 | SMAPE: 5.1668849 | MASE: 2.6214354
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0337809 | Vali Loss: 0.0374523 | Test Loss: 0.0441170 | Mae Loss: 0.1437755 | SMAPE: 8.5093231 | MASE: 3.2980154
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0343497 | Vali Loss: 0.0164341 | Test Loss: 0.0220245 | Mae Loss: 0.1036476 | SMAPE: 3.4174726 | MASE: 1.6849208
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0377886 | Vali Loss: 0.0200409 | Test Loss: 0.0268757 | Mae Loss: 0.1067984 | SMAPE: 4.8674564 | MASE: 2.3538969
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0298434 | Vali Loss: 0.0199055 | Test Loss: 0.0244254 | Mae Loss: 0.1056596 | SMAPE: 4.5328093 | MASE: 1.7397343
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0280358 | Vali Loss: 0.0167478 | Test Loss: 0.0207217 | Mae Loss: 0.0973827 | SMAPE: 3.6613584 | MASE: 1.5979921
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0251991 | Vali Loss: 0.0150130 | Test Loss: 0.0188274 | Mae Loss: 0.0917302 | SMAPE: 3.7879148 | MASE: 1.7492526
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0233220 | Vali Loss: 0.0132706 | Test Loss: 0.0177024 | Mae Loss: 0.0845775 | SMAPE: 3.5471969 | MASE: 1.3976190
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0255397 | Vali Loss: 0.0135393 | Test Loss: 0.0173950 | Mae Loss: 0.0856446 | SMAPE: 4.7536106 | MASE: 2.3269806
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0253872 | Vali Loss: 0.0128803 | Test Loss: 0.0173505 | Mae Loss: 0.0818976 | SMAPE: 2.7490127 | MASE: 1.3888730
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0995063 | Vali Loss: 0.0606740 | Test Loss: 0.0479260 | Mae Loss: 0.1939927 | SMAPE: 7.6574044 | MASE: 3.4476533
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0702650 | Vali Loss: 0.0479141 | Test Loss: 0.0432158 | Mae Loss: 0.1557159 | SMAPE: 8.4237022 | MASE: 3.5035658
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0693121 | Vali Loss: 0.0518851 | Test Loss: 0.0479024 | Mae Loss: 0.1721737 | SMAPE: 6.6368432 | MASE: 3.0560231
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0716888 | Vali Loss: 0.0360457 | Test Loss: 0.0422824 | Mae Loss: 0.1231345 | SMAPE: 6.5395775 | MASE: 3.3846810
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0512825 | Vali Loss: 0.0466611 | Test Loss: 0.0365876 | Mae Loss: 0.1479947 | SMAPE: 6.0408144 | MASE: 2.6611123
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0630040 | Vali Loss: 0.0285255 | Test Loss: 0.0361827 | Mae Loss: 0.1125835 | SMAPE: 7.1999631 | MASE: 3.4211912
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0530737 | Vali Loss: 0.0524418 | Test Loss: 0.0366276 | Mae Loss: 0.1729174 | SMAPE: 4.3793097 | MASE: 2.2353294
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0536682 | Vali Loss: 0.0302685 | Test Loss: 0.0361682 | Mae Loss: 0.1195175 | SMAPE: 7.2618313 | MASE: 3.2028413
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0537943 | Vali Loss: 0.0381339 | Test Loss: 0.0355855 | Mae Loss: 0.1270521 | SMAPE: 8.9752579 | MASE: 3.2727995
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0547758 | Vali Loss: 0.0319951 | Test Loss: 0.0353307 | Mae Loss: 0.1163959 | SMAPE: 6.8452821 | MASE: 2.7098184
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.2217781 | Vali Loss: 0.0575016 | Test Loss: 0.0671662 | Mae Loss: 0.1887579 | SMAPE: 10.1274252 | MASE: 4.1767483
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1172009 | Vali Loss: 0.0486798 | Test Loss: 0.0666165 | Mae Loss: 0.1663877 | SMAPE: 9.0831699 | MASE: 4.8307571
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1229451 | Vali Loss: 0.1058542 | Test Loss: 0.0763896 | Mae Loss: 0.2779122 | SMAPE: 11.8643856 | MASE: 4.8905492
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1140116 | Vali Loss: 0.0647217 | Test Loss: 0.0694332 | Mae Loss: 0.1989453 | SMAPE: 9.7412071 | MASE: 4.0261507
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1090097 | Vali Loss: 0.0511175 | Test Loss: 0.0757376 | Mae Loss: 0.1842062 | SMAPE: 10.6874666 | MASE: 4.2861919
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1152084 | Vali Loss: 0.0576046 | Test Loss: 0.0780424 | Mae Loss: 0.2057658 | SMAPE: 12.5385170 | MASE: 5.2343402
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.1087235 | Vali Loss: 0.0938468 | Test Loss: 0.0772923 | Mae Loss: 0.2585013 | SMAPE: 8.4327793 | MASE: 3.9514539
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1117243 | Vali Loss: 0.0705162 | Test Loss: 0.0764644 | Mae Loss: 0.2232508 | SMAPE: 11.7406635 | MASE: 5.0160279
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1122161 | Vali Loss: 0.0589080 | Test Loss: 0.0760652 | Mae Loss: 0.2015144 | SMAPE: 6.0105443 | MASE: 2.9858336
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0976330 | Vali Loss: 0.0979226 | Test Loss: 0.0757554 | Mae Loss: 0.2713973 | SMAPE: 11.6393089 | MASE: 5.5197845
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2380645 | Vali Loss: 0.0701500 | Test Loss: 0.1198380 | Mae Loss: 0.2383538 | SMAPE: 10.6852913 | MASE: 4.9356074
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1457969 | Vali Loss: 0.0890250 | Test Loss: 0.1179335 | Mae Loss: 0.2807240 | SMAPE: 12.1222124 | MASE: 5.4332657
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1509175 | Vali Loss: 0.0532685 | Test Loss: 0.1075103 | Mae Loss: 0.2122215 | SMAPE: 10.0329857 | MASE: 5.0419660
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1291979 | Vali Loss: 0.0577793 | Test Loss: 0.1085935 | Mae Loss: 0.2237553 | SMAPE: 11.7235680 | MASE: 5.1984916
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1385248 | Vali Loss: 0.0498963 | Test Loss: 0.1047970 | Mae Loss: 0.2051530 | SMAPE: 7.8848896 | MASE: 3.8901670
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1215962 | Vali Loss: 0.0503245 | Test Loss: 0.1049359 | Mae Loss: 0.2072919 | SMAPE: 10.8429012 | MASE: 4.8121343
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1170961 | Vali Loss: 0.0505341 | Test Loss: 0.1049879 | Mae Loss: 0.2072815 | SMAPE: 8.5057678 | MASE: 4.1588082
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1261860 | Vali Loss: 0.0583762 | Test Loss: 0.1046761 | Mae Loss: 0.2215668 | SMAPE: 10.3123684 | MASE: 4.6962585
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1336883 | Vali Loss: 0.0534345 | Test Loss: 0.1041750 | Mae Loss: 0.2137729 | SMAPE: 9.8935289 | MASE: 4.2006254
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1291434 | Vali Loss: 0.0534468 | Test Loss: 0.1040230 | Mae Loss: 0.2149236 | SMAPE: 9.8680916 | MASE: 4.6230488
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3164056 | Vali Loss: 0.0223104 | Test Loss: 0.1426408 | Mae Loss: 0.1229336 | SMAPE: 8.7921476 | MASE: 3.8895566
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1840192 | Vali Loss: 0.0416261 | Test Loss: 0.1488406 | Mae Loss: 0.1619031 | SMAPE: 8.9551544 | MASE: 3.8309872
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1896691 | Vali Loss: 0.0170082 | Test Loss: 0.1387999 | Mae Loss: 0.1104756 | SMAPE: 9.1257668 | MASE: 3.9686131
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1727150 | Vali Loss: 0.0103616 | Test Loss: 0.1393663 | Mae Loss: 0.0815328 | SMAPE: 7.6923618 | MASE: 3.5889175
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1675780 | Vali Loss: 0.0185605 | Test Loss: 0.1411447 | Mae Loss: 0.1131777 | SMAPE: 6.0671096 | MASE: 2.8123612
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1565234 | Vali Loss: 0.0149146 | Test Loss: 0.1401776 | Mae Loss: 0.0980081 | SMAPE: 8.6943512 | MASE: 3.8774500
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1475032 | Vali Loss: 0.0136349 | Test Loss: 0.1394602 | Mae Loss: 0.0927887 | SMAPE: 6.8456831 | MASE: 3.1410103
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1800437 | Vali Loss: 0.0142812 | Test Loss: 0.1390042 | Mae Loss: 0.0956473 | SMAPE: 6.5592823 | MASE: 3.0598764
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1668989 | Vali Loss: 0.0135973 | Test Loss: 0.1388480 | Mae Loss: 0.0933603 | SMAPE: 6.9918098 | MASE: 3.1883450
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1684650 | Vali Loss: 0.0105611 | Test Loss: 0.1385224 | Mae Loss: 0.0822731 | SMAPE: 6.0078168 | MASE: 2.7745051
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0441736 | Vali Loss: 0.0374314 | Test Loss: 0.0408653 | Mae Loss: 0.1415581 | SMAPE: 5.1668849 | MASE: 2.6214354
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0337809 | Vali Loss: 0.0374523 | Test Loss: 0.0441170 | Mae Loss: 0.1437755 | SMAPE: 8.5093231 | MASE: 3.2980154
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0343497 | Vali Loss: 0.0164341 | Test Loss: 0.0220245 | Mae Loss: 0.1036476 | SMAPE: 3.4174726 | MASE: 1.6849208
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0377886 | Vali Loss: 0.0200409 | Test Loss: 0.0268757 | Mae Loss: 0.1067984 | SMAPE: 4.8674564 | MASE: 2.3538969
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0298434 | Vali Loss: 0.0199055 | Test Loss: 0.0244254 | Mae Loss: 0.1056596 | SMAPE: 4.5328093 | MASE: 1.7397343
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0280358 | Vali Loss: 0.0167478 | Test Loss: 0.0207217 | Mae Loss: 0.0973827 | SMAPE: 3.6613584 | MASE: 1.5979921
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0251991 | Vali Loss: 0.0150130 | Test Loss: 0.0188274 | Mae Loss: 0.0917302 | SMAPE: 3.7879148 | MASE: 1.7492526
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0233220 | Vali Loss: 0.0132706 | Test Loss: 0.0177024 | Mae Loss: 0.0845775 | SMAPE: 3.5471969 | MASE: 1.3976190
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0255397 | Vali Loss: 0.0135393 | Test Loss: 0.0173950 | Mae Loss: 0.0856446 | SMAPE: 4.7536106 | MASE: 2.3269806
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0253872 | Vali Loss: 0.0128803 | Test Loss: 0.0173505 | Mae Loss: 0.0818976 | SMAPE: 2.7490127 | MASE: 1.3888730
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0995063 | Vali Loss: 0.0606740 | Test Loss: 0.0479260 | Mae Loss: 0.1939927 | SMAPE: 7.6574044 | MASE: 3.4476533
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0702650 | Vali Loss: 0.0479141 | Test Loss: 0.0432158 | Mae Loss: 0.1557159 | SMAPE: 8.4237022 | MASE: 3.5035658
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0693121 | Vali Loss: 0.0518851 | Test Loss: 0.0479024 | Mae Loss: 0.1721737 | SMAPE: 6.6368432 | MASE: 3.0560231
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0716888 | Vali Loss: 0.0360457 | Test Loss: 0.0422824 | Mae Loss: 0.1231345 | SMAPE: 6.5395775 | MASE: 3.3846810
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0512825 | Vali Loss: 0.0466611 | Test Loss: 0.0365876 | Mae Loss: 0.1479947 | SMAPE: 6.0408144 | MASE: 2.6611123
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0630040 | Vali Loss: 0.0285255 | Test Loss: 0.0361827 | Mae Loss: 0.1125835 | SMAPE: 7.1999631 | MASE: 3.4211912
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0530737 | Vali Loss: 0.0524418 | Test Loss: 0.0366276 | Mae Loss: 0.1729174 | SMAPE: 4.3793097 | MASE: 2.2353294
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0536682 | Vali Loss: 0.0302685 | Test Loss: 0.0361682 | Mae Loss: 0.1195175 | SMAPE: 7.2618313 | MASE: 3.2028413
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0537943 | Vali Loss: 0.0381339 | Test Loss: 0.0355855 | Mae Loss: 0.1270521 | SMAPE: 8.9752579 | MASE: 3.2727995
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0547758 | Vali Loss: 0.0319951 | Test Loss: 0.0353307 | Mae Loss: 0.1163959 | SMAPE: 6.8452821 | MASE: 2.7098184
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0441736 | Vali Loss: 0.0374314 | Test Loss: 0.0408653 | Mae Loss: 0.1415581 | SMAPE: 5.1668849 | MASE: 2.6214354
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0337809 | Vali Loss: 0.0374523 | Test Loss: 0.0441170 | Mae Loss: 0.1437755 | SMAPE: 8.5093231 | MASE: 3.2980154
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0402008 | Vali Loss: 0.0326942 | Test Loss: 0.0448676 | Mae Loss: 0.1217695 | SMAPE: 6.5012918 | MASE: 2.7608402
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0361891 | Vali Loss: 0.0194614 | Test Loss: 0.0274329 | Mae Loss: 0.1116741 | SMAPE: 5.6411099 | MASE: 2.5033619
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0434882 | Vali Loss: 0.0348940 | Test Loss: 0.0363234 | Mae Loss: 0.1414491 | SMAPE: 4.3280544 | MASE: 1.8690761
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0389562 | Vali Loss: 0.0225926 | Test Loss: 0.0396302 | Mae Loss: 0.1095176 | SMAPE: 5.0395885 | MASE: 2.4388833
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0338909 | Vali Loss: 0.0345740 | Test Loss: 0.0361697 | Mae Loss: 0.1390199 | SMAPE: 4.8127813 | MASE: 2.7921629
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0337791 | Vali Loss: 0.0266995 | Test Loss: 0.0343359 | Mae Loss: 0.1197377 | SMAPE: 5.2726326 | MASE: 2.7207072
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0349501 | Vali Loss: 0.0279304 | Test Loss: 0.0338897 | Mae Loss: 0.1250204 | SMAPE: 7.3395820 | MASE: 2.4564490
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0317936 | Vali Loss: 0.0225432 | Test Loss: 0.0333383 | Mae Loss: 0.1125283 | SMAPE: 5.4546952 | MASE: 2.2214324
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0349867 | Vali Loss: 0.0179126 | Test Loss: 0.0332480 | Mae Loss: 0.1017991 | SMAPE: 5.5047441 | MASE: 2.2698526
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0301506 | Vali Loss: 0.0236309 | Test Loss: 0.0331935 | Mae Loss: 0.1129999 | SMAPE: 5.3182926 | MASE: 2.2388756
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0343878 | Vali Loss: 0.0238911 | Test Loss: 0.0332160 | Mae Loss: 0.1159194 | SMAPE: 4.3969707 | MASE: 2.3399932
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0314060 | Vali Loss: 0.0277506 | Test Loss: 0.0331588 | Mae Loss: 0.1254330 | SMAPE: 6.9760799 | MASE: 2.5309784
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0343529 | Vali Loss: 0.0294335 | Test Loss: 0.0331503 | Mae Loss: 0.1284684 | SMAPE: 6.3511705 | MASE: 2.3110383
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0388085 | Vali Loss: 0.0232002 | Test Loss: 0.0331453 | Mae Loss: 0.1109899 | SMAPE: 6.9057813 | MASE: 2.4656613
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.0356412 | Vali Loss: 0.0308058 | Test Loss: 0.0328929 | Mae Loss: 0.1376955 | SMAPE: 3.4536679 | MASE: 1.9676138
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.0256444 | Vali Loss: 0.0273248 | Test Loss: 0.0329790 | Mae Loss: 0.1230285 | SMAPE: 5.3285336 | MASE: 1.7482097
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 17 | Train Loss: 0.0319091 | Vali Loss: 0.0164908 | Test Loss: 0.0332801 | Mae Loss: 0.0921040 | SMAPE: 5.5039620 | MASE: 2.4520459
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 18 | Train Loss: 0.0329639 | Vali Loss: 0.0205105 | Test Loss: 0.0329551 | Mae Loss: 0.0984717 | SMAPE: 4.5681057 | MASE: 1.6777949
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 19 | Train Loss: 0.0315611 | Vali Loss: 0.0248745 | Test Loss: 0.0331966 | Mae Loss: 0.1154457 | SMAPE: 4.4570303 | MASE: 2.0595539
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 20 | Train Loss: 0.0319526 | Vali Loss: 0.0203929 | Test Loss: 0.0331457 | Mae Loss: 0.1028598 | SMAPE: 5.2523432 | MASE: 2.3657629
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1196460 | Vali Loss: 0.0453711 | Test Loss: 0.0663536 | Mae Loss: 0.1697541 | SMAPE: 7.3554435 | MASE: 3.9481781
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0693334 | Vali Loss: 0.0531240 | Test Loss: 0.0618890 | Mae Loss: 0.1727262 | SMAPE: 10.2242250 | MASE: 4.3204036
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0672442 | Vali Loss: 0.0554109 | Test Loss: 0.0709011 | Mae Loss: 0.1766915 | SMAPE: 7.8757772 | MASE: 3.6538291
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0655323 | Vali Loss: 0.0534582 | Test Loss: 0.0686986 | Mae Loss: 0.1714475 | SMAPE: 7.7318525 | MASE: 3.1229877
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0662939 | Vali Loss: 0.0530419 | Test Loss: 0.0627949 | Mae Loss: 0.1702674 | SMAPE: 9.1044617 | MASE: 3.3733563
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0651328 | Vali Loss: 0.0519064 | Test Loss: 0.0617218 | Mae Loss: 0.1646953 | SMAPE: 6.1466022 | MASE: 3.3980989
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0701386 | Vali Loss: 0.0504037 | Test Loss: 0.0614042 | Mae Loss: 0.1592793 | SMAPE: 6.1665273 | MASE: 2.9891274
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0603868 | Vali Loss: 0.0417412 | Test Loss: 0.0614389 | Mae Loss: 0.1459397 | SMAPE: 6.8899589 | MASE: 3.5238976
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0623952 | Vali Loss: 0.0457127 | Test Loss: 0.0614288 | Mae Loss: 0.1501704 | SMAPE: 7.4103975 | MASE: 3.7435477
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0637627 | Vali Loss: 0.0514266 | Test Loss: 0.0612849 | Mae Loss: 0.1661894 | SMAPE: 6.6862197 | MASE: 2.5751340
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0675951 | Vali Loss: 0.0512693 | Test Loss: 0.0613954 | Mae Loss: 0.1643982 | SMAPE: 7.9484186 | MASE: 3.4614418
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.0617781 | Vali Loss: 0.0412512 | Test Loss: 0.0613017 | Mae Loss: 0.1405071 | SMAPE: 5.2851720 | MASE: 2.9137373
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.0660784 | Vali Loss: 0.0370134 | Test Loss: 0.0615327 | Mae Loss: 0.1319425 | SMAPE: 7.9910898 | MASE: 3.6488688
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 14 | Train Loss: 0.0665072 | Vali Loss: 0.0509918 | Test Loss: 0.0613821 | Mae Loss: 0.1631212 | SMAPE: 9.0633059 | MASE: 4.0421715
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 15 | Train Loss: 0.0626122 | Vali Loss: 0.0491400 | Test Loss: 0.0614261 | Mae Loss: 0.1577258 | SMAPE: 6.5856538 | MASE: 2.7128267
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 16 | Train Loss: 0.0619222 | Vali Loss: 0.0360936 | Test Loss: 0.0615113 | Mae Loss: 0.1332220 | SMAPE: 8.6657524 | MASE: 2.9405596
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 17 | Train Loss: 0.0577802 | Vali Loss: 0.0370479 | Test Loss: 0.0614944 | Mae Loss: 0.1325085 | SMAPE: 6.5740957 | MASE: 2.6120265
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 18 | Train Loss: 0.0645768 | Vali Loss: 0.0475002 | Test Loss: 0.0616388 | Mae Loss: 0.1480755 | SMAPE: 8.8920164 | MASE: 3.5836098
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 19 | Train Loss: 0.0623437 | Vali Loss: 0.0512037 | Test Loss: 0.0614125 | Mae Loss: 0.1637641 | SMAPE: 6.2522078 | MASE: 2.6887851
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 20 | Train Loss: 0.0611912 | Vali Loss: 0.0505745 | Test Loss: 0.0616010 | Mae Loss: 0.1603025 | SMAPE: 6.3020468 | MASE: 2.6781604
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1594488 | Vali Loss: 0.0627374 | Test Loss: 0.0931095 | Mae Loss: 0.1956189 | SMAPE: 10.4641151 | MASE: 4.6582084
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1207481 | Vali Loss: 0.0695044 | Test Loss: 0.0938048 | Mae Loss: 0.2072968 | SMAPE: 6.3997507 | MASE: 3.8726976
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1047323 | Vali Loss: 0.0868695 | Test Loss: 0.1100428 | Mae Loss: 0.2500360 | SMAPE: 9.2209625 | MASE: 4.9176717
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1072327 | Vali Loss: 0.0774720 | Test Loss: 0.1032654 | Mae Loss: 0.2295575 | SMAPE: 11.3230238 | MASE: 4.3670797
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1069382 | Vali Loss: 0.0691216 | Test Loss: 0.1011271 | Mae Loss: 0.2103371 | SMAPE: 8.8148832 | MASE: 3.8034315
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1096643 | Vali Loss: 0.0755590 | Test Loss: 0.1011265 | Mae Loss: 0.2259196 | SMAPE: 12.5092134 | MASE: 5.2845860
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0989798 | Vali Loss: 0.0762959 | Test Loss: 0.1012892 | Mae Loss: 0.2242781 | SMAPE: 11.4481840 | MASE: 5.0935221
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1030652 | Vali Loss: 0.0636048 | Test Loss: 0.1016136 | Mae Loss: 0.2032369 | SMAPE: 5.6866426 | MASE: 3.2270658
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0979381 | Vali Loss: 0.0782317 | Test Loss: 0.1015538 | Mae Loss: 0.2317566 | SMAPE: 11.1249390 | MASE: 4.6523805
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.1062652 | Vali Loss: 0.0762260 | Test Loss: 0.1013783 | Mae Loss: 0.2248415 | SMAPE: 13.4052601 | MASE: 4.8741803
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.1042312 | Vali Loss: 0.0671185 | Test Loss: 0.1013471 | Mae Loss: 0.2117217 | SMAPE: 6.4031377 | MASE: 3.7078288
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3091073 | Vali Loss: 0.1323411 | Test Loss: 0.1908188 | Mae Loss: 0.3376774 | SMAPE: 15.9924965 | MASE: 7.2840967
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1513315 | Vali Loss: 0.0635057 | Test Loss: 0.1416320 | Mae Loss: 0.2157666 | SMAPE: 10.1358747 | MASE: 4.4643703
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1393015 | Vali Loss: 0.0340168 | Test Loss: 0.1423275 | Mae Loss: 0.1558051 | SMAPE: 8.7085657 | MASE: 4.3431783
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1391550 | Vali Loss: 0.0691846 | Test Loss: 0.1413323 | Mae Loss: 0.2242932 | SMAPE: 8.9292068 | MASE: 3.7613981
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1228028 | Vali Loss: 0.0585744 | Test Loss: 0.1421656 | Mae Loss: 0.2100386 | SMAPE: 7.4751062 | MASE: 4.3077087
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1394641 | Vali Loss: 0.0532889 | Test Loss: 0.1431278 | Mae Loss: 0.2116353 | SMAPE: 10.5202808 | MASE: 4.8527050
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1528958 | Vali Loss: 0.0748357 | Test Loss: 0.1433948 | Mae Loss: 0.2457481 | SMAPE: 9.8755398 | MASE: 4.6408587
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1329926 | Vali Loss: 0.0794327 | Test Loss: 0.1433258 | Mae Loss: 0.2540639 | SMAPE: 8.9861984 | MASE: 4.0987005
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1310706 | Vali Loss: 0.0728198 | Test Loss: 0.1436674 | Mae Loss: 0.2420689 | SMAPE: 9.6743565 | MASE: 4.5823054
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1172652 | Vali Loss: 0.0452460 | Test Loss: 0.1436828 | Mae Loss: 0.1957408 | SMAPE: 8.1411924 | MASE: 4.0188727
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.1348825 | Vali Loss: 0.0488476 | Test Loss: 0.1435470 | Mae Loss: 0.1995227 | SMAPE: 8.8881092 | MASE: 4.3627052
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.1328307 | Vali Loss: 0.0519389 | Test Loss: 0.1434411 | Mae Loss: 0.2117468 | SMAPE: 10.6635981 | MASE: 5.3552661
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 13 | Train Loss: 0.1270306 | Vali Loss: 0.0515267 | Test Loss: 0.1435707 | Mae Loss: 0.2066988 | SMAPE: 10.4449215 | MASE: 4.8372040
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3952285 | Vali Loss: 0.1709822 | Test Loss: 0.2519410 | Mae Loss: 0.3362287 | SMAPE: 16.2866535 | MASE: 6.7975397
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.2146435 | Vali Loss: 0.0588578 | Test Loss: 0.1967478 | Mae Loss: 0.1977692 | SMAPE: 12.6745110 | MASE: 5.9448843
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1957172 | Vali Loss: 0.0243809 | Test Loss: 0.1805193 | Mae Loss: 0.1327802 | SMAPE: 9.6287880 | MASE: 4.2249722
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1633293 | Vali Loss: 0.0183064 | Test Loss: 0.1784844 | Mae Loss: 0.1115685 | SMAPE: 7.7605343 | MASE: 3.5854690
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1826000 | Vali Loss: 0.0126349 | Test Loss: 0.1763585 | Mae Loss: 0.0876434 | SMAPE: 9.3410854 | MASE: 3.9467583
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1831959 | Vali Loss: 0.0118218 | Test Loss: 0.1750925 | Mae Loss: 0.0876103 | SMAPE: 8.1028309 | MASE: 3.6826322
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1848408 | Vali Loss: 0.0128997 | Test Loss: 0.1756432 | Mae Loss: 0.0877048 | SMAPE: 5.2107201 | MASE: 2.6569090
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1775341 | Vali Loss: 0.0135105 | Test Loss: 0.1757033 | Mae Loss: 0.0888006 | SMAPE: 7.7331176 | MASE: 3.6262350
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1781298 | Vali Loss: 0.0128288 | Test Loss: 0.1756245 | Mae Loss: 0.0899585 | SMAPE: 5.9277782 | MASE: 2.9171748
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1737341 | Vali Loss: 0.0106769 | Test Loss: 0.1758048 | Mae Loss: 0.0776633 | SMAPE: 7.6895080 | MASE: 3.4269805
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.1578604 | Vali Loss: 0.0094603 | Test Loss: 0.1757564 | Mae Loss: 0.0786198 | SMAPE: 8.5474768 | MASE: 3.9245958
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.1572846 | Vali Loss: 0.0143856 | Test Loss: 0.1756602 | Mae Loss: 0.0959773 | SMAPE: 6.0946798 | MASE: 3.1298749
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 13 | Train Loss: 0.1641299 | Vali Loss: 0.0112107 | Test Loss: 0.1759002 | Mae Loss: 0.0835191 | SMAPE: 7.3290496 | MASE: 3.4468124
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 14 | Train Loss: 0.1602520 | Vali Loss: 0.0123130 | Test Loss: 0.1755818 | Mae Loss: 0.0858667 | SMAPE: 5.2786155 | MASE: 2.5863276
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 15 | Train Loss: 0.1682665 | Vali Loss: 0.0140512 | Test Loss: 0.1755651 | Mae Loss: 0.0936283 | SMAPE: 5.1964903 | MASE: 2.8634353
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 16 | Train Loss: 0.1604484 | Vali Loss: 0.0156265 | Test Loss: 0.1754846 | Mae Loss: 0.1000618 | SMAPE: 7.2426825 | MASE: 3.6733983
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 17 | Train Loss: 0.1908812 | Vali Loss: 0.0136476 | Test Loss: 0.1754865 | Mae Loss: 0.0951096 | SMAPE: 7.7246666 | MASE: 4.0215869
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 18 | Train Loss: 0.1720567 | Vali Loss: 0.0119657 | Test Loss: 0.1754516 | Mae Loss: 0.0846294 | SMAPE: 8.4495592 | MASE: 3.8829167
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 19 | Train Loss: 0.1599863 | Vali Loss: 0.0106454 | Test Loss: 0.1756493 | Mae Loss: 0.0796311 | SMAPE: 8.5727081 | MASE: 3.9899743
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 20 | Train Loss: 0.1835350 | Vali Loss: 0.0166270 | Test Loss: 0.1757933 | Mae Loss: 0.1067433 | SMAPE: 9.1966953 | MASE: 3.6844714
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0441736 | Vali Loss: 0.0374314 | Test Loss: 0.0408653 | Mae Loss: 0.1415581 | SMAPE: 1.2348675 | MASE: 2.6214261
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0337809 | Vali Loss: 0.0374523 | Test Loss: 0.0441170 | Mae Loss: 0.1437755 | SMAPE: 1.9456801 | MASE: 3.2980099
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0343497 | Vali Loss: 0.0164341 | Test Loss: 0.0220245 | Mae Loss: 0.1036476 | SMAPE: 0.8474828 | MASE: 1.6849225
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0377886 | Vali Loss: 0.0200409 | Test Loss: 0.0268757 | Mae Loss: 0.1067984 | SMAPE: 1.1621748 | MASE: 2.3538883
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0298434 | Vali Loss: 0.0199055 | Test Loss: 0.0244254 | Mae Loss: 0.1056596 | SMAPE: 1.0724939 | MASE: 1.7397316
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0280358 | Vali Loss: 0.0167478 | Test Loss: 0.0207217 | Mae Loss: 0.0973827 | SMAPE: 0.8765002 | MASE: 1.5979935
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0251991 | Vali Loss: 0.0150130 | Test Loss: 0.0188274 | Mae Loss: 0.0917302 | SMAPE: 0.9136882 | MASE: 1.7492460
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0233220 | Vali Loss: 0.0132706 | Test Loss: 0.0177024 | Mae Loss: 0.0845775 | SMAPE: 0.8386124 | MASE: 1.3976167
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0255397 | Vali Loss: 0.0135393 | Test Loss: 0.0173950 | Mae Loss: 0.0856446 | SMAPE: 1.1175733 | MASE: 2.3269703
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0253872 | Vali Loss: 0.0128803 | Test Loss: 0.0173505 | Mae Loss: 0.0818976 | SMAPE: 0.6631885 | MASE: 1.3888712
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0402008 | Vali Loss: 0.0326942 | Test Loss: 0.0448676 | Mae Loss: 0.1217695 | SMAPE: 1.5294753 | MASE: 2.7608316
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0361891 | Vali Loss: 0.0194614 | Test Loss: 0.0274329 | Mae Loss: 0.1116741 | SMAPE: 1.3652573 | MASE: 2.5033555
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0434882 | Vali Loss: 0.0348940 | Test Loss: 0.0363234 | Mae Loss: 0.1414491 | SMAPE: 1.0328705 | MASE: 1.8690723
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0389562 | Vali Loss: 0.0225926 | Test Loss: 0.0396302 | Mae Loss: 0.1095176 | SMAPE: 1.2025281 | MASE: 2.4388783
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0338909 | Vali Loss: 0.0345740 | Test Loss: 0.0361697 | Mae Loss: 0.1390199 | SMAPE: 1.1644436 | MASE: 2.7921607
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0337791 | Vali Loss: 0.0266995 | Test Loss: 0.0343359 | Mae Loss: 0.1197377 | SMAPE: 1.2633237 | MASE: 2.7206991
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0349501 | Vali Loss: 0.0279304 | Test Loss: 0.0338897 | Mae Loss: 0.1250204 | SMAPE: 1.6681939 | MASE: 2.4564443
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0317936 | Vali Loss: 0.0225432 | Test Loss: 0.0333383 | Mae Loss: 0.1125283 | SMAPE: 1.2769848 | MASE: 2.2214243
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0349867 | Vali Loss: 0.0179126 | Test Loss: 0.0332480 | Mae Loss: 0.1017991 | SMAPE: 1.2834877 | MASE: 2.2698514
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0301506 | Vali Loss: 0.0236309 | Test Loss: 0.0331935 | Mae Loss: 0.1129999 | SMAPE: 1.2726007 | MASE: 2.2388732
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0343878 | Vali Loss: 0.0238911 | Test Loss: 0.0332160 | Mae Loss: 0.1159194 | SMAPE: 1.0588332 | MASE: 2.3399932
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0441736 | Vali Loss: 0.0374314 | Test Loss: 0.0408653 | Mae Loss: 0.1415581 | SMAPE: 1.2348675 | MASE: 2.6214261
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0337809 | Vali Loss: 0.0374523 | Test Loss: 0.0441170 | Mae Loss: 0.1437755 | SMAPE: 1.9456801 | MASE: 3.2980099
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0343497 | Vali Loss: 0.0164341 | Test Loss: 0.0220245 | Mae Loss: 0.1036476 | SMAPE: 0.8474828 | MASE: 1.6849225
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0377886 | Vali Loss: 0.0200409 | Test Loss: 0.0268757 | Mae Loss: 0.1067984 | SMAPE: 1.1621748 | MASE: 2.3538883
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0298434 | Vali Loss: 0.0199055 | Test Loss: 0.0244254 | Mae Loss: 0.1056596 | SMAPE: 1.0724939 | MASE: 1.7397316
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0280358 | Vali Loss: 0.0167478 | Test Loss: 0.0207217 | Mae Loss: 0.0973827 | SMAPE: 0.8765002 | MASE: 1.5979935
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0251991 | Vali Loss: 0.0150130 | Test Loss: 0.0188274 | Mae Loss: 0.0917302 | SMAPE: 0.9136882 | MASE: 1.7492460
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0233220 | Vali Loss: 0.0132706 | Test Loss: 0.0177024 | Mae Loss: 0.0845775 | SMAPE: 0.8386124 | MASE: 1.3976167
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0255397 | Vali Loss: 0.0135393 | Test Loss: 0.0173950 | Mae Loss: 0.0856446 | SMAPE: 1.1175733 | MASE: 2.3269703
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0253872 | Vali Loss: 0.0128803 | Test Loss: 0.0173505 | Mae Loss: 0.0818976 | SMAPE: 0.6631885 | MASE: 1.3888712
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0223020 | Vali Loss: 0.0131609 | Test Loss: 0.0172547 | Mae Loss: 0.0835659 | SMAPE: 0.7333953 | MASE: 1.6069804
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0219840 | Vali Loss: 0.0128278 | Test Loss: 0.0172793 | Mae Loss: 0.0816861 | SMAPE: 0.6065836 | MASE: 1.2688725
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0232380 | Vali Loss: 0.0132921 | Test Loss: 0.0173825 | Mae Loss: 0.0827185 | SMAPE: 0.7825633 | MASE: 1.3895426
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0261675 | Vali Loss: 0.0134707 | Test Loss: 0.0172931 | Mae Loss: 0.0854892 | SMAPE: 0.6045232 | MASE: 1.3374738
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.0212175 | Vali Loss: 0.0131964 | Test Loss: 0.0173899 | Mae Loss: 0.0826051 | SMAPE: 0.7422543 | MASE: 1.4837002
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.0220659 | Vali Loss: 0.0132015 | Test Loss: 0.0173723 | Mae Loss: 0.0834403 | SMAPE: 1.1138916 | MASE: 1.9488033
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 17 | Train Loss: 0.0232899 | Vali Loss: 0.0133406 | Test Loss: 0.0173978 | Mae Loss: 0.0819986 | SMAPE: 0.8948438 | MASE: 1.3401350
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 18 | Train Loss: 0.0225226 | Vali Loss: 0.0134577 | Test Loss: 0.0174167 | Mae Loss: 0.0850946 | SMAPE: 1.0690503 | MASE: 1.8721112
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 19 | Train Loss: 0.0237696 | Vali Loss: 0.0132811 | Test Loss: 0.0173186 | Mae Loss: 0.0830631 | SMAPE: 1.1813344 | MASE: 1.9268677
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 20 | Train Loss: 0.0229079 | Vali Loss: 0.0115446 | Test Loss: 0.0173099 | Mae Loss: 0.0780689 | SMAPE: 1.0907673 | MASE: 1.6561877
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0995063 | Vali Loss: 0.0606740 | Test Loss: 0.0479260 | Mae Loss: 0.1939927 | SMAPE: 1.7884566 | MASE: 3.4476459
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0402008 | Vali Loss: 0.0326942 | Test Loss: 0.0448676 | Mae Loss: 0.1217695 | SMAPE: 1.5294753 | MASE: 2.7608316
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0361891 | Vali Loss: 0.0194614 | Test Loss: 0.0274329 | Mae Loss: 0.1116741 | SMAPE: 1.3652573 | MASE: 2.5033555
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0434882 | Vali Loss: 0.0348940 | Test Loss: 0.0363234 | Mae Loss: 0.1414491 | SMAPE: 1.0328705 | MASE: 1.8690723
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0389562 | Vali Loss: 0.0225926 | Test Loss: 0.0396302 | Mae Loss: 0.1095176 | SMAPE: 1.2025281 | MASE: 2.4388783
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0338909 | Vali Loss: 0.0345740 | Test Loss: 0.0361697 | Mae Loss: 0.1390199 | SMAPE: 1.1644436 | MASE: 2.7921607
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0337791 | Vali Loss: 0.0266995 | Test Loss: 0.0343359 | Mae Loss: 0.1197377 | SMAPE: 1.2633237 | MASE: 2.7206991
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0349501 | Vali Loss: 0.0279304 | Test Loss: 0.0338897 | Mae Loss: 0.1250204 | SMAPE: 1.6681939 | MASE: 2.4564443
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0317936 | Vali Loss: 0.0225432 | Test Loss: 0.0333383 | Mae Loss: 0.1125283 | SMAPE: 1.2769848 | MASE: 2.2214243
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0349867 | Vali Loss: 0.0179126 | Test Loss: 0.0332480 | Mae Loss: 0.1017991 | SMAPE: 1.2834877 | MASE: 2.2698514
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0301506 | Vali Loss: 0.0236309 | Test Loss: 0.0331935 | Mae Loss: 0.1129999 | SMAPE: 1.2726007 | MASE: 2.2388732
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0343878 | Vali Loss: 0.0238911 | Test Loss: 0.0332160 | Mae Loss: 0.1159194 | SMAPE: 1.0588332 | MASE: 2.3399932
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0314060 | Vali Loss: 0.0277506 | Test Loss: 0.0331588 | Mae Loss: 0.1254330 | SMAPE: 1.5832387 | MASE: 2.5309741
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0343529 | Vali Loss: 0.0294335 | Test Loss: 0.0331503 | Mae Loss: 0.1284684 | SMAPE: 1.4699984 | MASE: 2.3110344
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0388085 | Vali Loss: 0.0232002 | Test Loss: 0.0331453 | Mae Loss: 0.1109899 | SMAPE: 1.6012658 | MASE: 2.4656601
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.0356412 | Vali Loss: 0.0308058 | Test Loss: 0.0328929 | Mae Loss: 0.1376955 | SMAPE: 0.8536057 | MASE: 1.9676143
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.0256444 | Vali Loss: 0.0273248 | Test Loss: 0.0329790 | Mae Loss: 0.1230285 | SMAPE: 1.2238858 | MASE: 1.7482090
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 17 | Train Loss: 0.0319091 | Vali Loss: 0.0164908 | Test Loss: 0.0332801 | Mae Loss: 0.0921040 | SMAPE: 1.3022691 | MASE: 2.4520380
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 18 | Train Loss: 0.0329639 | Vali Loss: 0.0205105 | Test Loss: 0.0329551 | Mae Loss: 0.0984717 | SMAPE: 1.0753919 | MASE: 1.6777929
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 19 | Train Loss: 0.0315611 | Vali Loss: 0.0248745 | Test Loss: 0.0331966 | Mae Loss: 0.1154457 | SMAPE: 1.0596539 | MASE: 2.0595524
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 20 | Train Loss: 0.0319526 | Vali Loss: 0.0203929 | Test Loss: 0.0331457 | Mae Loss: 0.1028598 | SMAPE: 1.2355721 | MASE: 2.3657539
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.1196460 | Vali Loss: 0.0453711 | Test Loss: 0.0663536 | Mae Loss: 0.1697541 | SMAPE: 1.7609928 | MASE: 3.9481647
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0693334 | Vali Loss: 0.0531240 | Test Loss: 0.0618890 | Mae Loss: 0.1727262 | SMAPE: 2.3852088 | MASE: 4.3203926
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0672442 | Vali Loss: 0.0554109 | Test Loss: 0.0709011 | Mae Loss: 0.1766915 | SMAPE: 1.8246396 | MASE: 3.6538270
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0655323 | Vali Loss: 0.0534582 | Test Loss: 0.0686986 | Mae Loss: 0.1714475 | SMAPE: 1.7886404 | MASE: 3.1229825
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0662939 | Vali Loss: 0.0530419 | Test Loss: 0.0627949 | Mae Loss: 0.1702674 | SMAPE: 2.0851762 | MASE: 3.3733554
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0651328 | Vali Loss: 0.0519064 | Test Loss: 0.0617218 | Mae Loss: 0.1646953 | SMAPE: 1.4437153 | MASE: 3.3980849
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0701386 | Vali Loss: 0.0504037 | Test Loss: 0.0614042 | Mae Loss: 0.1592793 | SMAPE: 1.4387423 | MASE: 2.9891229
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0441736 | Vali Loss: 0.0374314 | Test Loss: 0.0408653 | Mae Loss: 0.1415581 | SMAPE: 1.2348675 | MASE: 2.6214261
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0337809 | Vali Loss: 0.0374523 | Test Loss: 0.0441170 | Mae Loss: 0.1437755 | SMAPE: 1.9456801 | MASE: 3.2980099
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0343497 | Vali Loss: 0.0164341 | Test Loss: 0.0220245 | Mae Loss: 0.1036476 | SMAPE: 0.8474828 | MASE: 1.6849225
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0377886 | Vali Loss: 0.0200409 | Test Loss: 0.0268757 | Mae Loss: 0.1067984 | SMAPE: 1.1621748 | MASE: 2.3538883
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0298434 | Vali Loss: 0.0199055 | Test Loss: 0.0244254 | Mae Loss: 0.1056596 | SMAPE: 1.0724939 | MASE: 1.7397316
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0280358 | Vali Loss: 0.0167478 | Test Loss: 0.0207217 | Mae Loss: 0.0973827 | SMAPE: 0.8765002 | MASE: 1.5979935
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0251991 | Vali Loss: 0.0150130 | Test Loss: 0.0188274 | Mae Loss: 0.0917302 | SMAPE: 0.9136882 | MASE: 1.7492460
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0233220 | Vali Loss: 0.0132706 | Test Loss: 0.0177024 | Mae Loss: 0.0845775 | SMAPE: 0.8386124 | MASE: 1.3976167
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0255397 | Vali Loss: 0.0135393 | Test Loss: 0.0173950 | Mae Loss: 0.0856446 | SMAPE: 1.1175733 | MASE: 2.3269703
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0253872 | Vali Loss: 0.0128803 | Test Loss: 0.0173505 | Mae Loss: 0.0818976 | SMAPE: 0.6631885 | MASE: 1.3888712
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0223020 | Vali Loss: 0.0131609 | Test Loss: 0.0172547 | Mae Loss: 0.0835659 | SMAPE: 0.7333953 | MASE: 1.6069804
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0219840 | Vali Loss: 0.0128278 | Test Loss: 0.0172793 | Mae Loss: 0.0816861 | SMAPE: 0.6065836 | MASE: 1.2688725
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0232380 | Vali Loss: 0.0132921 | Test Loss: 0.0173825 | Mae Loss: 0.0827185 | SMAPE: 0.7825633 | MASE: 1.3895426
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0261675 | Vali Loss: 0.0134707 | Test Loss: 0.0172931 | Mae Loss: 0.0854892 | SMAPE: 0.6045232 | MASE: 1.3374738
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.0212175 | Vali Loss: 0.0131964 | Test Loss: 0.0173899 | Mae Loss: 0.0826051 | SMAPE: 0.7422543 | MASE: 1.4837002
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.0220659 | Vali Loss: 0.0132015 | Test Loss: 0.0173723 | Mae Loss: 0.0834403 | SMAPE: 1.1138916 | MASE: 1.9488033
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 17 | Train Loss: 0.0232899 | Vali Loss: 0.0133406 | Test Loss: 0.0173978 | Mae Loss: 0.0819986 | SMAPE: 0.8948438 | MASE: 1.3401350
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 18 | Train Loss: 0.0225226 | Vali Loss: 0.0134577 | Test Loss: 0.0174167 | Mae Loss: 0.0850946 | SMAPE: 1.0690503 | MASE: 1.8721112
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 19 | Train Loss: 0.0237696 | Vali Loss: 0.0132811 | Test Loss: 0.0173186 | Mae Loss: 0.0830631 | SMAPE: 1.1813344 | MASE: 1.9268677
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 20 | Train Loss: 0.0229079 | Vali Loss: 0.0115446 | Test Loss: 0.0173099 | Mae Loss: 0.0780689 | SMAPE: 1.0907673 | MASE: 1.6561877
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0995063 | Vali Loss: 0.0606740 | Test Loss: 0.0479260 | Mae Loss: 0.1939927 | SMAPE: 1.7884566 | MASE: 3.4476459
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.0702650 | Vali Loss: 0.0479141 | Test Loss: 0.0432158 | Mae Loss: 0.1557159 | SMAPE: 1.9401911 | MASE: 3.5035644
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0693121 | Vali Loss: 0.0518851 | Test Loss: 0.0479024 | Mae Loss: 0.1721737 | SMAPE: 1.5523546 | MASE: 3.0560181
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0716888 | Vali Loss: 0.0360457 | Test Loss: 0.0422824 | Mae Loss: 0.1231345 | SMAPE: 1.5466202 | MASE: 3.3846767
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0512825 | Vali Loss: 0.0466611 | Test Loss: 0.0365876 | Mae Loss: 0.1479947 | SMAPE: 1.4167730 | MASE: 2.6611066
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0630040 | Vali Loss: 0.0285255 | Test Loss: 0.0361827 | Mae Loss: 0.1125835 | SMAPE: 1.6684266 | MASE: 3.4211829
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0530737 | Vali Loss: 0.0524418 | Test Loss: 0.0366276 | Mae Loss: 0.1729174 | SMAPE: 1.0440755 | MASE: 2.2353265
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0536682 | Vali Loss: 0.0302685 | Test Loss: 0.0361682 | Mae Loss: 0.1195175 | SMAPE: 1.6743885 | MASE: 3.2028341
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0537943 | Vali Loss: 0.0381339 | Test Loss: 0.0355855 | Mae Loss: 0.1270521 | SMAPE: 2.0522909 | MASE: 3.2727981
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0547758 | Vali Loss: 0.0319951 | Test Loss: 0.0353307 | Mae Loss: 0.1163959 | SMAPE: 1.5922242 | MASE: 2.7098181
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0534735 | Vali Loss: 0.0573138 | Test Loss: 0.0353109 | Mae Loss: 0.1804103 | SMAPE: 1.5740354 | MASE: 2.7477384
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.0541381 | Vali Loss: 0.0252656 | Test Loss: 0.0350829 | Mae Loss: 0.1081420 | SMAPE: 1.4164704 | MASE: 2.5903821
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.0508736 | Vali Loss: 0.0300782 | Test Loss: 0.0350908 | Mae Loss: 0.1169425 | SMAPE: 1.6542157 | MASE: 3.0010900
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 14 | Train Loss: 0.0538816 | Vali Loss: 0.0222365 | Test Loss: 0.0350149 | Mae Loss: 0.0977842 | SMAPE: 1.3046343 | MASE: 2.6426990
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 15 | Train Loss: 0.0539270 | Vali Loss: 0.0388006 | Test Loss: 0.0350154 | Mae Loss: 0.1330213 | SMAPE: 1.9297624 | MASE: 3.0657368
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 16 | Train Loss: 0.0546018 | Vali Loss: 0.0466582 | Test Loss: 0.0350049 | Mae Loss: 0.1579931 | SMAPE: 1.3773985 | MASE: 2.5969944
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 17 | Train Loss: 0.0559250 | Vali Loss: 0.0404459 | Test Loss: 0.0351133 | Mae Loss: 0.1406477 | SMAPE: 1.7950045 | MASE: 3.2129283
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 18 | Train Loss: 0.0569594 | Vali Loss: 0.0441588 | Test Loss: 0.0349492 | Mae Loss: 0.1399563 | SMAPE: 1.3012969 | MASE: 2.3173065
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 19 | Train Loss: 0.0552492 | Vali Loss: 0.0155006 | Test Loss: 0.0350542 | Mae Loss: 0.0781404 | SMAPE: 1.2864842 | MASE: 2.7061632
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 20 | Train Loss: 0.0546207 | Vali Loss: 0.0279005 | Test Loss: 0.0351394 | Mae Loss: 0.1154367 | SMAPE: 1.4676553 | MASE: 3.1764615
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.2217781 | Vali Loss: 0.0575016 | Test Loss: 0.0671662 | Mae Loss: 0.1887579 | SMAPE: 2.3644438 | MASE: 4.1767464
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1172009 | Vali Loss: 0.0486798 | Test Loss: 0.0666165 | Mae Loss: 0.1663877 | SMAPE: 2.1327784 | MASE: 4.8307462
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1229451 | Vali Loss: 0.1058542 | Test Loss: 0.0763896 | Mae Loss: 0.2779122 | SMAPE: 2.7329571 | MASE: 4.8905425
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.1140116 | Vali Loss: 0.0647217 | Test Loss: 0.0694332 | Mae Loss: 0.1989453 | SMAPE: 2.2177198 | MASE: 4.0261474
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.1090097 | Vali Loss: 0.0511175 | Test Loss: 0.0757376 | Mae Loss: 0.1842062 | SMAPE: 2.4427474 | MASE: 4.2861900
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.1152084 | Vali Loss: 0.0576046 | Test Loss: 0.0780424 | Mae Loss: 0.2057658 | SMAPE: 2.9012101 | MASE: 5.2343349
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.1087235 | Vali Loss: 0.0938468 | Test Loss: 0.0772923 | Mae Loss: 0.2585013 | SMAPE: 1.9666500 | MASE: 3.9514463
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.1117243 | Vali Loss: 0.0705162 | Test Loss: 0.0764644 | Mae Loss: 0.2232508 | SMAPE: 2.6967835 | MASE: 5.0160203
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.1122161 | Vali Loss: 0.0589080 | Test Loss: 0.0760652 | Mae Loss: 0.2015144 | SMAPE: 1.4169458 | MASE: 2.9858282
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0976330 | Vali Loss: 0.0979226 | Test Loss: 0.0757554 | Mae Loss: 0.2713973 | SMAPE: 2.7003095 | MASE: 5.5197716
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.1032325 | Vali Loss: 0.0569883 | Test Loss: 0.0756904 | Mae Loss: 0.1937991 | SMAPE: 2.1879528 | MASE: 4.7902975
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 12 | Train Loss: 0.1040843 | Vali Loss: 0.0598073 | Test Loss: 0.0756546 | Mae Loss: 0.1996939 | SMAPE: 2.4084089 | MASE: 4.5624480
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.2380645 | Vali Loss: 0.0701500 | Test Loss: 0.1198380 | Mae Loss: 0.2383538 | SMAPE: 2.5157681 | MASE: 4.9355984
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.1457969 | Vali Loss: 0.0890250 | Test Loss: 0.1179335 | Mae Loss: 0.2807240 | SMAPE: 2.8311245 | MASE: 5.4332600
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.1509175 | Vali Loss: 0.0532685 | Test Loss: 0.1075103 | Mae Loss: 0.2122215 | SMAPE: 2.3641579 | MASE: 5.0419540
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1291979 | Vali Loss: 0.0577793 | Test Loss: 0.1085935 | Mae Loss: 0.2237553 | SMAPE: 2.7186439 | MASE: 5.1984797
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1385248 | Vali Loss: 0.0498963 | Test Loss: 0.1047970 | Mae Loss: 0.2051530 | SMAPE: 1.8545123 | MASE: 3.8901603
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1215962 | Vali Loss: 0.0503245 | Test Loss: 0.1049359 | Mae Loss: 0.2072919 | SMAPE: 2.5282712 | MASE: 4.8121271
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1170961 | Vali Loss: 0.0505341 | Test Loss: 0.1049879 | Mae Loss: 0.2072815 | SMAPE: 2.0111160 | MASE: 4.1588011
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1261860 | Vali Loss: 0.0583762 | Test Loss: 0.1046761 | Mae Loss: 0.2215668 | SMAPE: 2.3978465 | MASE: 4.6962509
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1336883 | Vali Loss: 0.0534345 | Test Loss: 0.1041750 | Mae Loss: 0.2137729 | SMAPE: 2.3145275 | MASE: 4.2006202
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1291434 | Vali Loss: 0.0534468 | Test Loss: 0.1040230 | Mae Loss: 0.2149236 | SMAPE: 2.3157539 | MASE: 4.6230397
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.1344590 | Vali Loss: 0.0488099 | Test Loss: 0.1039831 | Mae Loss: 0.2004299 | SMAPE: 2.2725561 | MASE: 4.6337910
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.1109766 | Vali Loss: 0.0528563 | Test Loss: 0.1038359 | Mae Loss: 0.2120011 | SMAPE: 2.4438987 | MASE: 4.6001925
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 13 | Train Loss: 0.1103469 | Vali Loss: 0.0560718 | Test Loss: 0.1036396 | Mae Loss: 0.2258123 | SMAPE: 2.2496252 | MASE: 4.3859992
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 14 | Train Loss: 0.1195094 | Vali Loss: 0.0575450 | Test Loss: 0.1037181 | Mae Loss: 0.2210190 | SMAPE: 1.9082766 | MASE: 3.5621085
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 15 | Train Loss: 0.1248321 | Vali Loss: 0.0458154 | Test Loss: 0.1036895 | Mae Loss: 0.1964190 | SMAPE: 2.2285917 | MASE: 4.2729554
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 16 | Train Loss: 0.1155938 | Vali Loss: 0.0543157 | Test Loss: 0.1037235 | Mae Loss: 0.2170658 | SMAPE: 2.0217175 | MASE: 3.7332861
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 17 | Train Loss: 0.1203482 | Vali Loss: 0.0566140 | Test Loss: 0.1036864 | Mae Loss: 0.2234384 | SMAPE: 2.0891731 | MASE: 4.1120186
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 18 | Train Loss: 0.1177355 | Vali Loss: 0.0515145 | Test Loss: 0.1038047 | Mae Loss: 0.2112612 | SMAPE: 2.1515117 | MASE: 4.0480571
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 19 | Train Loss: 0.1315512 | Vali Loss: 0.0593805 | Test Loss: 0.1037879 | Mae Loss: 0.2262200 | SMAPE: 2.4025066 | MASE: 4.8535757
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 20 | Train Loss: 0.1229525 | Vali Loss: 0.0563292 | Test Loss: 0.1037459 | Mae Loss: 0.2213782 | SMAPE: 2.1475992 | MASE: 4.2885656
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3164056 | Vali Loss: 0.0223104 | Test Loss: 0.1426408 | Mae Loss: 0.1229336 | SMAPE: 2.0063775 | MASE: 3.8895495
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1840192 | Vali Loss: 0.0416261 | Test Loss: 0.1488406 | Mae Loss: 0.1619031 | SMAPE: 2.0562227 | MASE: 3.8309803
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1896691 | Vali Loss: 0.0170082 | Test Loss: 0.1387999 | Mae Loss: 0.1104756 | SMAPE: 2.0923922 | MASE: 3.9686069
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1727150 | Vali Loss: 0.0103616 | Test Loss: 0.1393663 | Mae Loss: 0.0815328 | SMAPE: 1.7370174 | MASE: 3.5889099
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1675780 | Vali Loss: 0.0185605 | Test Loss: 0.1411447 | Mae Loss: 0.1131777 | SMAPE: 1.3986667 | MASE: 2.8123548
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1565234 | Vali Loss: 0.0149146 | Test Loss: 0.1401776 | Mae Loss: 0.0980081 | SMAPE: 1.9349614 | MASE: 3.8774433
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1475032 | Vali Loss: 0.0136349 | Test Loss: 0.1394602 | Mae Loss: 0.0927887 | SMAPE: 1.5603771 | MASE: 3.1410041
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1800437 | Vali Loss: 0.0142812 | Test Loss: 0.1390042 | Mae Loss: 0.0956473 | SMAPE: 1.5210932 | MASE: 3.0598717
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1668989 | Vali Loss: 0.0135973 | Test Loss: 0.1388480 | Mae Loss: 0.0933603 | SMAPE: 1.6039404 | MASE: 3.1883376
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1684650 | Vali Loss: 0.0105611 | Test Loss: 0.1385224 | Mae Loss: 0.0822731 | SMAPE: 1.3813308 | MASE: 2.7744999
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.1675805 | Vali Loss: 0.0117249 | Test Loss: 0.1385059 | Mae Loss: 0.0862580 | SMAPE: 1.4525126 | MASE: 3.0913775
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.1540149 | Vali Loss: 0.0126809 | Test Loss: 0.1385337 | Mae Loss: 0.0880834 | SMAPE: 1.6721960 | MASE: 3.3618703
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 13 | Train Loss: 0.1434585 | Vali Loss: 0.0122890 | Test Loss: 0.1384713 | Mae Loss: 0.0862191 | SMAPE: 1.7359551 | MASE: 3.2650869
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 14 | Train Loss: 0.1606172 | Vali Loss: 0.0133959 | Test Loss: 0.1383760 | Mae Loss: 0.0925873 | SMAPE: 1.2266093 | MASE: 2.5651155
