seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0517727 | Vali Loss: 0.0179892 | Test Loss: 0.0223126 | Mae Loss: 0.1096177 | SMAPE: 1.1344210 | MASE: 2.7607551
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0360546 | Vali Loss: 0.0253591 | Test Loss: 0.0297774 | Mae Loss: 0.1177132 | SMAPE: 1.2138262 | MASE: 2.2352300
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0332978 | Vali Loss: 0.0172856 | Test Loss: 0.0224389 | Mae Loss: 0.1041385 | SMAPE: 1.2518252 | MASE: 2.1820323
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0309680 | Vali Loss: 0.0181427 | Test Loss: 0.0231448 | Mae Loss: 0.1016275 | SMAPE: 1.4087688 | MASE: 2.2682726
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0271622 | Vali Loss: 0.0163124 | Test Loss: 0.0225722 | Mae Loss: 0.0926837 | SMAPE: 1.1187453 | MASE: 1.9182500
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0246532 | Vali Loss: 0.0138626 | Test Loss: 0.0201094 | Mae Loss: 0.0855980 | SMAPE: 0.6236160 | MASE: 1.3728247
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0269285 | Vali Loss: 0.0132400 | Test Loss: 0.0194484 | Mae Loss: 0.0828786 | SMAPE: 1.0911441 | MASE: 1.6788251
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0266165 | Vali Loss: 0.0132361 | Test Loss: 0.0196401 | Mae Loss: 0.0831853 | SMAPE: 1.1076499 | MASE: 2.4784558
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0280259 | Vali Loss: 0.0129532 | Test Loss: 0.0198929 | Mae Loss: 0.0806560 | SMAPE: 0.8550409 | MASE: 1.9582464
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0264061 | Vali Loss: 0.0137101 | Test Loss: 0.0198513 | Mae Loss: 0.0854264 | SMAPE: 0.8712631 | MASE: 1.2537971
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0244626 | Vali Loss: 0.0135534 | Test Loss: 0.0199826 | Mae Loss: 0.0842566 | SMAPE: 0.7156873 | MASE: 1.5643317
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0233296 | Vali Loss: 0.0133166 | Test Loss: 0.0199255 | Mae Loss: 0.0838563 | SMAPE: 0.8547809 | MASE: 1.5513030
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0276187 | Vali Loss: 0.0136125 | Test Loss: 0.0199935 | Mae Loss: 0.0845316 | SMAPE: 1.2000831 | MASE: 2.3211210
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0296395 | Vali Loss: 0.0130779 | Test Loss: 0.0199852 | Mae Loss: 0.0823630 | SMAPE: 0.8473569 | MASE: 1.3326836
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.0240763 | Vali Loss: 0.0133183 | Test Loss: 0.0199262 | Mae Loss: 0.0835942 | SMAPE: 0.6992850 | MASE: 1.3834428
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.0236689 | Vali Loss: 0.0135195 | Test Loss: 0.0199321 | Mae Loss: 0.0848329 | SMAPE: 0.7806221 | MASE: 1.4206613
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 17 | Train Loss: 0.0250697 | Vali Loss: 0.0123166 | Test Loss: 0.0199314 | Mae Loss: 0.0789236 | SMAPE: 0.7349461 | MASE: 1.2971069
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 18 | Train Loss: 0.0259369 | Vali Loss: 0.0131561 | Test Loss: 0.0199278 | Mae Loss: 0.0818024 | SMAPE: 0.9410919 | MASE: 1.9173160
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 19 | Train Loss: 0.0267235 | Vali Loss: 0.0128772 | Test Loss: 0.0199661 | Mae Loss: 0.0801794 | SMAPE: 1.2696433 | MASE: 2.1050808
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 20 | Train Loss: 0.0161597 | Vali Loss: 0.0131707 | Test Loss: 0.0199324 | Mae Loss: 0.0826027 | SMAPE: 0.9415168 | MASE: 1.5616361
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0946273 | Vali Loss: 0.1289900 | Test Loss: 0.0710727 | Mae Loss: 0.3259799 | SMAPE: 3.1124928 | MASE: 5.5105104
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1020845 | Vali Loss: 0.0435562 | Test Loss: 0.0494683 | Mae Loss: 0.1582931 | SMAPE: 2.3108492 | MASE: 4.2583194
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0717107 | Vali Loss: 0.0178925 | Test Loss: 0.0438733 | Mae Loss: 0.0915978 | SMAPE: 1.7107397 | MASE: 2.8369837
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0671916 | Vali Loss: 0.0403091 | Test Loss: 0.0422109 | Mae Loss: 0.1324335 | SMAPE: 1.4743327 | MASE: 2.7545340
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0518762 | Vali Loss: 0.0603377 | Test Loss: 0.0456225 | Mae Loss: 0.1885509 | SMAPE: 1.8622957 | MASE: 3.2013373
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0697251 | Vali Loss: 0.0418120 | Test Loss: 0.0452357 | Mae Loss: 0.1504456 | SMAPE: 2.0510321 | MASE: 3.7055714
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0664511 | Vali Loss: 0.0269579 | Test Loss: 0.0443683 | Mae Loss: 0.1113594 | SMAPE: 1.9479758 | MASE: 3.3267210
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0544991 | Vali Loss: 0.0591895 | Test Loss: 0.0437469 | Mae Loss: 0.1774832 | SMAPE: 2.0231712 | MASE: 3.5407186
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0644981 | Vali Loss: 0.0320411 | Test Loss: 0.0438579 | Mae Loss: 0.1172742 | SMAPE: 1.7017695 | MASE: 2.8429048
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0635693 | Vali Loss: 0.0373021 | Test Loss: 0.0437310 | Mae Loss: 0.1319355 | SMAPE: 1.7367224 | MASE: 2.6678824
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0668104 | Vali Loss: 0.0594016 | Test Loss: 0.0436701 | Mae Loss: 0.1863166 | SMAPE: 1.2103314 | MASE: 2.5279379
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.0679302 | Vali Loss: 0.0386573 | Test Loss: 0.0436871 | Mae Loss: 0.1305072 | SMAPE: 1.4596596 | MASE: 2.6774156
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.0600455 | Vali Loss: 0.0432693 | Test Loss: 0.0437897 | Mae Loss: 0.1431691 | SMAPE: 1.6811901 | MASE: 2.9437673
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1388511 | Vali Loss: 0.0702523 | Test Loss: 0.0755671 | Mae Loss: 0.2247122 | SMAPE: 2.5102916 | MASE: 4.4980493
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1074384 | Vali Loss: 0.1004018 | Test Loss: 0.0851083 | Mae Loss: 0.2838451 | SMAPE: 3.2975976 | MASE: 5.6901951
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1200011 | Vali Loss: 0.0802616 | Test Loss: 0.0743166 | Mae Loss: 0.2341558 | SMAPE: 2.4359729 | MASE: 4.7022715
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.0968269 | Vali Loss: 0.0652489 | Test Loss: 0.0740681 | Mae Loss: 0.2078301 | SMAPE: 2.2107608 | MASE: 4.3516369
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0897332 | Vali Loss: 0.0785821 | Test Loss: 0.0643993 | Mae Loss: 0.2283487 | SMAPE: 1.8868768 | MASE: 3.9339571
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0893186 | Vali Loss: 0.0529650 | Test Loss: 0.0589890 | Mae Loss: 0.1689122 | SMAPE: 1.8096699 | MASE: 3.6575625
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0900038 | Vali Loss: 0.0314053 | Test Loss: 0.0574543 | Mae Loss: 0.1355382 | SMAPE: 1.5805945 | MASE: 3.3624246
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.0846808 | Vali Loss: 0.0452902 | Test Loss: 0.0570570 | Mae Loss: 0.1561467 | SMAPE: 1.9878381 | MASE: 3.7195842
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0894673 | Vali Loss: 0.0390407 | Test Loss: 0.0566948 | Mae Loss: 0.1382773 | SMAPE: 1.6233196 | MASE: 3.1245120
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0752614 | Vali Loss: 0.0576341 | Test Loss: 0.0564851 | Mae Loss: 0.1777564 | SMAPE: 2.5044148 | MASE: 4.5475154
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.0783504 | Vali Loss: 0.0582466 | Test Loss: 0.0565297 | Mae Loss: 0.1825569 | SMAPE: 2.2871542 | MASE: 4.1607080
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 12 | Train Loss: 0.0741932 | Vali Loss: 0.0442410 | Test Loss: 0.0565747 | Mae Loss: 0.1542286 | SMAPE: 2.0459170 | MASE: 4.0090513
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 13 | Train Loss: 0.0841145 | Vali Loss: 0.0579028 | Test Loss: 0.0566334 | Mae Loss: 0.1822945 | SMAPE: 2.0992370 | MASE: 3.8629146
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 14 | Train Loss: 0.0798670 | Vali Loss: 0.0488457 | Test Loss: 0.0565793 | Mae Loss: 0.1676350 | SMAPE: 1.5757598 | MASE: 3.4104607
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 15 | Train Loss: 0.0757005 | Vali Loss: 0.0355905 | Test Loss: 0.0565398 | Mae Loss: 0.1425958 | SMAPE: 1.5791371 | MASE: 3.1635873
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 16 | Train Loss: 0.0859087 | Vali Loss: 0.0521577 | Test Loss: 0.0564618 | Mae Loss: 0.1735852 | SMAPE: 2.3778741 | MASE: 4.0669103
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 17 | Train Loss: 0.0925113 | Vali Loss: 0.0337627 | Test Loss: 0.0565011 | Mae Loss: 0.1389471 | SMAPE: 2.0421979 | MASE: 3.9927669
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3387966 | Vali Loss: 0.4223252 | Test Loss: 0.2529277 | Mae Loss: 0.6420919 | SMAPE: 6.4712210 | MASE: 12.3871717
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.3637807 | Vali Loss: 0.1630287 | Test Loss: 0.1489618 | Mae Loss: 0.3513994 | SMAPE: 3.7940879 | MASE: 7.1915927
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2790546 | Vali Loss: 0.0476683 | Test Loss: 0.1308837 | Mae Loss: 0.1763140 | SMAPE: 2.3215137 | MASE: 5.0890260
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1790739 | Vali Loss: 0.1015340 | Test Loss: 0.1256161 | Mae Loss: 0.2920882 | SMAPE: 3.1148093 | MASE: 6.1086931
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1502082 | Vali Loss: 0.1068958 | Test Loss: 0.1212522 | Mae Loss: 0.3080759 | SMAPE: 2.9291339 | MASE: 6.0527625
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1348157 | Vali Loss: 0.0892307 | Test Loss: 0.1171391 | Mae Loss: 0.2813405 | SMAPE: 3.1009123 | MASE: 6.1394796
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1396875 | Vali Loss: 0.0788820 | Test Loss: 0.1147892 | Mae Loss: 0.2679244 | SMAPE: 2.8997252 | MASE: 5.3265839
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1450730 | Vali Loss: 0.0820192 | Test Loss: 0.1131894 | Mae Loss: 0.2709797 | SMAPE: 2.8811705 | MASE: 5.7659221
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1278765 | Vali Loss: 0.0705435 | Test Loss: 0.1125595 | Mae Loss: 0.2502408 | SMAPE: 2.6092434 | MASE: 5.0860701
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1319182 | Vali Loss: 0.0790956 | Test Loss: 0.1124088 | Mae Loss: 0.2664285 | SMAPE: 2.6674829 | MASE: 5.3323674
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.1408847 | Vali Loss: 0.0800086 | Test Loss: 0.1122623 | Mae Loss: 0.2718643 | SMAPE: 2.4424956 | MASE: 5.2536240
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.1368292 | Vali Loss: 0.0736213 | Test Loss: 0.1121575 | Mae Loss: 0.2581481 | SMAPE: 2.6569018 | MASE: 5.1687636
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 13 | Train Loss: 0.1226277 | Vali Loss: 0.0730697 | Test Loss: 0.1121575 | Mae Loss: 0.2538130 | SMAPE: 2.4554775 | MASE: 5.0874047
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3180490 | Vali Loss: 0.0245679 | Test Loss: 0.1469305 | Mae Loss: 0.1342671 | SMAPE: 2.0161650 | MASE: 4.3661718
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1763342 | Vali Loss: 0.0148269 | Test Loss: 0.1399951 | Mae Loss: 0.1037953 | SMAPE: 1.7935373 | MASE: 3.4667964
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1774102 | Vali Loss: 0.0245991 | Test Loss: 0.1431992 | Mae Loss: 0.1328502 | SMAPE: 2.1654034 | MASE: 4.3041821
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1902261 | Vali Loss: 0.0152323 | Test Loss: 0.1400454 | Mae Loss: 0.1013262 | SMAPE: 2.0766230 | MASE: 3.8895493
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1679970 | Vali Loss: 0.0161233 | Test Loss: 0.1402606 | Mae Loss: 0.1011592 | SMAPE: 1.4747665 | MASE: 2.8742001
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1691398 | Vali Loss: 0.0159317 | Test Loss: 0.1408431 | Mae Loss: 0.1044983 | SMAPE: 1.9151092 | MASE: 4.1219649
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1708421 | Vali Loss: 0.0168220 | Test Loss: 0.1407069 | Mae Loss: 0.1068568 | SMAPE: 1.6505175 | MASE: 3.0825889
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1782229 | Vali Loss: 0.0141208 | Test Loss: 0.1404724 | Mae Loss: 0.0968683 | SMAPE: 1.4843960 | MASE: 3.1521828
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1846313 | Vali Loss: 0.0146606 | Test Loss: 0.1403789 | Mae Loss: 0.0984258 | SMAPE: 1.6542507 | MASE: 3.1294825
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1817749 | Vali Loss: 0.0168359 | Test Loss: 0.1401996 | Mae Loss: 0.1069645 | SMAPE: 1.4093239 | MASE: 2.9862623
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.1685264 | Vali Loss: 0.0120365 | Test Loss: 0.1401537 | Mae Loss: 0.0874445 | SMAPE: 1.4026072 | MASE: 2.6521981
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.1606841 | Vali Loss: 0.0139996 | Test Loss: 0.1402072 | Mae Loss: 0.0966290 | SMAPE: 1.7109387 | MASE: 3.4511895
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 13 | Train Loss: 0.1566098 | Vali Loss: 0.0140447 | Test Loss: 0.1402100 | Mae Loss: 0.0949355 | SMAPE: 1.7801421 | MASE: 3.5521982
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 14 | Train Loss: 0.1695703 | Vali Loss: 0.0169558 | Test Loss: 0.1401204 | Mae Loss: 0.1091055 | SMAPE: 1.1596737 | MASE: 2.2083437
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 15 | Train Loss: 0.1587092 | Vali Loss: 0.0118622 | Test Loss: 0.1401303 | Mae Loss: 0.0876075 | SMAPE: 1.6908245 | MASE: 3.1807742
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 16 | Train Loss: 0.1474107 | Vali Loss: 0.0131925 | Test Loss: 0.1402638 | Mae Loss: 0.0936668 | SMAPE: 1.3749599 | MASE: 2.9411314
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 17 | Train Loss: 0.1536339 | Vali Loss: 0.0132717 | Test Loss: 0.1401781 | Mae Loss: 0.0956531 | SMAPE: 1.6485293 | MASE: 3.3919635
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 18 | Train Loss: 0.1587433 | Vali Loss: 0.0137130 | Test Loss: 0.1401697 | Mae Loss: 0.0926353 | SMAPE: 1.2504637 | MASE: 2.3762739
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 19 | Train Loss: 0.1533716 | Vali Loss: 0.0153737 | Test Loss: 0.1399779 | Mae Loss: 0.1009756 | SMAPE: 1.3888326 | MASE: 2.8118834
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 20 | Train Loss: 0.1676041 | Vali Loss: 0.0139559 | Test Loss: 0.1400216 | Mae Loss: 0.0962633 | SMAPE: 1.7609010 | MASE: 3.2973592
