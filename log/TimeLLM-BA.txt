seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0517727 | Vali Loss: 0.0179892 | Test Loss: 0.0223126 | Mae Loss: 0.1096177 | SMAPE: 1.1344210 | MASE: 2.7607551
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0360546 | Vali Loss: 0.0253591 | Test Loss: 0.0297774 | Mae Loss: 0.1177132 | SMAPE: 1.2138262 | MASE: 2.2352300
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0332978 | Vali Loss: 0.0173026 | Test Loss: 0.0224440 | Mae Loss: 0.1042776 | SMAPE: 1.2514057 | MASE: 2.1813347
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0309231 | Vali Loss: 0.0181102 | Test Loss: 0.0231814 | Mae Loss: 0.1015714 | SMAPE: 1.4093424 | MASE: 2.2691514
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0271361 | Vali Loss: 0.0162449 | Test Loss: 0.0225308 | Mae Loss: 0.0924391 | SMAPE: 1.1163388 | MASE: 1.9142225
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0246343 | Vali Loss: 0.0138434 | Test Loss: 0.0201668 | Mae Loss: 0.0852922 | SMAPE: 0.6220594 | MASE: 1.3690975
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0268812 | Vali Loss: 0.0132222 | Test Loss: 0.0195133 | Mae Loss: 0.0829146 | SMAPE: 1.0895282 | MASE: 1.6762439
