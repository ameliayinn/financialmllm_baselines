seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0517727 | Vali Loss: 0.0179892 | Test Loss: 0.0223126 | Mae Loss: 0.1096177 | SMAPE: 1.1344210 | MASE: 2.7607551
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0360546 | Vali Loss: 0.0253591 | Test Loss: 0.0297774 | Mae Loss: 0.1177132 | SMAPE: 1.2138262 | MASE: 2.2352300
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0332978 | Vali Loss: 0.0173026 | Test Loss: 0.0224440 | Mae Loss: 0.1042776 | SMAPE: 1.2514057 | MASE: 2.1813347
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0309231 | Vali Loss: 0.0181102 | Test Loss: 0.0231814 | Mae Loss: 0.1015714 | SMAPE: 1.4093424 | MASE: 2.2691514
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0271361 | Vali Loss: 0.0162449 | Test Loss: 0.0225308 | Mae Loss: 0.0924391 | SMAPE: 1.1163388 | MASE: 1.9142225
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0246343 | Vali Loss: 0.0138434 | Test Loss: 0.0201668 | Mae Loss: 0.0852922 | SMAPE: 0.6220594 | MASE: 1.3690975
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0268812 | Vali Loss: 0.0132222 | Test Loss: 0.0195133 | Mae Loss: 0.0829146 | SMAPE: 1.0895282 | MASE: 1.6762439
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0265729 | Vali Loss: 0.0132982 | Test Loss: 0.0197563 | Mae Loss: 0.0836415 | SMAPE: 1.1017463 | MASE: 2.4651821
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0280229 | Vali Loss: 0.0129616 | Test Loss: 0.0199146 | Mae Loss: 0.0806568 | SMAPE: 0.8492118 | MASE: 1.9446226
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0263970 | Vali Loss: 0.0138234 | Test Loss: 0.0199640 | Mae Loss: 0.0857475 | SMAPE: 0.8725877 | MASE: 1.2556392
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0244353 | Vali Loss: 0.0136472 | Test Loss: 0.0199908 | Mae Loss: 0.0845229 | SMAPE: 0.7175503 | MASE: 1.5681683
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0233024 | Vali Loss: 0.0133757 | Test Loss: 0.0199781 | Mae Loss: 0.0840555 | SMAPE: 0.8577214 | MASE: 1.5567023
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0275831 | Vali Loss: 0.0137196 | Test Loss: 0.0199649 | Mae Loss: 0.0849485 | SMAPE: 1.2072604 | MASE: 2.3346231
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0296377 | Vali Loss: 0.0131743 | Test Loss: 0.0200305 | Mae Loss: 0.0824097 | SMAPE: 0.8416134 | MASE: 1.3233516
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.0240264 | Vali Loss: 0.0133618 | Test Loss: 0.0200134 | Mae Loss: 0.0837284 | SMAPE: 0.7025831 | MASE: 1.3898963
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.0236991 | Vali Loss: 0.0135886 | Test Loss: 0.0200136 | Mae Loss: 0.0851439 | SMAPE: 0.7830740 | MASE: 1.4250503
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 17 | Train Loss: 0.0251006 | Vali Loss: 0.0122972 | Test Loss: 0.0200216 | Mae Loss: 0.0790247 | SMAPE: 0.7422978 | MASE: 1.3101413
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 18 | Train Loss: 0.0259240 | Vali Loss: 0.0132104 | Test Loss: 0.0200624 | Mae Loss: 0.0818458 | SMAPE: 0.9356397 | MASE: 1.9060150
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 19 | Train Loss: 0.0266970 | Vali Loss: 0.0129444 | Test Loss: 0.0200150 | Mae Loss: 0.0803044 | SMAPE: 1.2691344 | MASE: 2.1042836
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 20 | Train Loss: 0.0161814 | Vali Loss: 0.0132775 | Test Loss: 0.0200482 | Mae Loss: 0.0826943 | SMAPE: 0.9388144 | MASE: 1.5570585
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0946273 | Vali Loss: 0.1289900 | Test Loss: 0.0710727 | Mae Loss: 0.3259799 | SMAPE: 3.1124928 | MASE: 5.5105104
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1020845 | Vali Loss: 0.0435562 | Test Loss: 0.0494683 | Mae Loss: 0.1582931 | SMAPE: 2.3108492 | MASE: 4.2583194
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0717107 | Vali Loss: 0.0178925 | Test Loss: 0.0438733 | Mae Loss: 0.0915978 | SMAPE: 1.7107397 | MASE: 2.8369837
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0671916 | Vali Loss: 0.0403091 | Test Loss: 0.0422109 | Mae Loss: 0.1324335 | SMAPE: 1.4748129 | MASE: 2.7554612
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0518762 | Vali Loss: 0.0603377 | Test Loss: 0.0456225 | Mae Loss: 0.1885509 | SMAPE: 1.8622957 | MASE: 3.2013373
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0697251 | Vali Loss: 0.0418120 | Test Loss: 0.0452357 | Mae Loss: 0.1504456 | SMAPE: 2.0510321 | MASE: 3.7055714
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0664511 | Vali Loss: 0.0269579 | Test Loss: 0.0443683 | Mae Loss: 0.1113594 | SMAPE: 1.9479758 | MASE: 3.3267210
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0544991 | Vali Loss: 0.0591895 | Test Loss: 0.0437469 | Mae Loss: 0.1774832 | SMAPE: 2.0231712 | MASE: 3.5407186
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0644981 | Vali Loss: 0.0320411 | Test Loss: 0.0438579 | Mae Loss: 0.1172742 | SMAPE: 1.7017695 | MASE: 2.8429048
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0635693 | Vali Loss: 0.0373021 | Test Loss: 0.0437310 | Mae Loss: 0.1319355 | SMAPE: 1.7367224 | MASE: 2.6678824
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0668104 | Vali Loss: 0.0594016 | Test Loss: 0.0436701 | Mae Loss: 0.1863166 | SMAPE: 1.2103314 | MASE: 2.5279379
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.0679302 | Vali Loss: 0.0386573 | Test Loss: 0.0436871 | Mae Loss: 0.1305072 | SMAPE: 1.4596596 | MASE: 2.6774156
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.0600455 | Vali Loss: 0.0432693 | Test Loss: 0.0437897 | Mae Loss: 0.1431691 | SMAPE: 1.6811901 | MASE: 2.9437673
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1388511 | Vali Loss: 0.0702523 | Test Loss: 0.0755671 | Mae Loss: 0.2247122 | SMAPE: 2.5102916 | MASE: 4.4980493
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1074384 | Vali Loss: 0.1004018 | Test Loss: 0.0851083 | Mae Loss: 0.2838451 | SMAPE: 3.2975976 | MASE: 5.6901951
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1200011 | Vali Loss: 0.0802616 | Test Loss: 0.0743166 | Mae Loss: 0.2341558 | SMAPE: 2.4359729 | MASE: 4.7022715
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.0968269 | Vali Loss: 0.0652489 | Test Loss: 0.0740681 | Mae Loss: 0.2078301 | SMAPE: 2.2107608 | MASE: 4.3516369
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0897332 | Vali Loss: 0.0785821 | Test Loss: 0.0643993 | Mae Loss: 0.2283487 | SMAPE: 1.8868768 | MASE: 3.9339571
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0893186 | Vali Loss: 0.0529650 | Test Loss: 0.0589890 | Mae Loss: 0.1689122 | SMAPE: 1.8096699 | MASE: 3.6575625
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0900038 | Vali Loss: 0.0314053 | Test Loss: 0.0574543 | Mae Loss: 0.1355382 | SMAPE: 1.5805945 | MASE: 3.3624246
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.0846808 | Vali Loss: 0.0452902 | Test Loss: 0.0570570 | Mae Loss: 0.1561467 | SMAPE: 1.9878381 | MASE: 3.7195842
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0894673 | Vali Loss: 0.0390407 | Test Loss: 0.0566948 | Mae Loss: 0.1382773 | SMAPE: 1.6233196 | MASE: 3.1245120
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0752614 | Vali Loss: 0.0576341 | Test Loss: 0.0564851 | Mae Loss: 0.1777564 | SMAPE: 2.5044148 | MASE: 4.5475154
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.0783504 | Vali Loss: 0.0582466 | Test Loss: 0.0565297 | Mae Loss: 0.1825569 | SMAPE: 2.2871542 | MASE: 4.1607080
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 12 | Train Loss: 0.0741932 | Vali Loss: 0.0442410 | Test Loss: 0.0565747 | Mae Loss: 0.1542286 | SMAPE: 2.0459170 | MASE: 4.0090513
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 13 | Train Loss: 0.0841145 | Vali Loss: 0.0579028 | Test Loss: 0.0566334 | Mae Loss: 0.1822945 | SMAPE: 2.0992370 | MASE: 3.8629146
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 14 | Train Loss: 0.0798670 | Vali Loss: 0.0488457 | Test Loss: 0.0565793 | Mae Loss: 0.1676350 | SMAPE: 1.5757598 | MASE: 3.4104607
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 15 | Train Loss: 0.0757005 | Vali Loss: 0.0355905 | Test Loss: 0.0565398 | Mae Loss: 0.1425958 | SMAPE: 1.5791371 | MASE: 3.1635873
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 16 | Train Loss: 0.0859087 | Vali Loss: 0.0521577 | Test Loss: 0.0564618 | Mae Loss: 0.1735852 | SMAPE: 2.3778741 | MASE: 4.0669103
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 17 | Train Loss: 0.0925113 | Vali Loss: 0.0337627 | Test Loss: 0.0565011 | Mae Loss: 0.1389471 | SMAPE: 2.0421979 | MASE: 3.9927669
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3387966 | Vali Loss: 0.4223252 | Test Loss: 0.2529277 | Mae Loss: 0.6420919 | SMAPE: 6.4712210 | MASE: 12.3871717
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.3637807 | Vali Loss: 0.1630287 | Test Loss: 0.1489618 | Mae Loss: 0.3513994 | SMAPE: 3.7940879 | MASE: 7.1915927
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2790546 | Vali Loss: 0.0476683 | Test Loss: 0.1308837 | Mae Loss: 0.1763140 | SMAPE: 2.3215137 | MASE: 5.0890260
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1790739 | Vali Loss: 0.1015340 | Test Loss: 0.1256161 | Mae Loss: 0.2920882 | SMAPE: 3.1148093 | MASE: 6.1086931
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1502082 | Vali Loss: 0.1068958 | Test Loss: 0.1212522 | Mae Loss: 0.3080759 | SMAPE: 2.9291339 | MASE: 6.0527625
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1348157 | Vali Loss: 0.0892307 | Test Loss: 0.1171391 | Mae Loss: 0.2813405 | SMAPE: 3.1009123 | MASE: 6.1394796
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1396875 | Vali Loss: 0.0788820 | Test Loss: 0.1147892 | Mae Loss: 0.2679244 | SMAPE: 2.8997252 | MASE: 5.3265839
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1450730 | Vali Loss: 0.0820192 | Test Loss: 0.1131894 | Mae Loss: 0.2709797 | SMAPE: 2.8811705 | MASE: 5.7659221
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1278765 | Vali Loss: 0.0705435 | Test Loss: 0.1125595 | Mae Loss: 0.2502408 | SMAPE: 2.6092434 | MASE: 5.0860701
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1319182 | Vali Loss: 0.0790956 | Test Loss: 0.1124088 | Mae Loss: 0.2664285 | SMAPE: 2.6674829 | MASE: 5.3323674
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.1408847 | Vali Loss: 0.0800086 | Test Loss: 0.1122623 | Mae Loss: 0.2718643 | SMAPE: 2.4424956 | MASE: 5.2536240
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.1368396 | Vali Loss: 0.0735247 | Test Loss: 0.1121363 | Mae Loss: 0.2580093 | SMAPE: 2.6551225 | MASE: 5.1652827
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 13 | Train Loss: 0.1227386 | Vali Loss: 0.0731168 | Test Loss: 0.1120404 | Mae Loss: 0.2539552 | SMAPE: 2.4563179 | MASE: 5.0891480
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3188723 | Vali Loss: 0.0160488 | Test Loss: 0.1450031 | Mae Loss: 0.1046633 | SMAPE: 1.8211210 | MASE: 3.9315889
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1763975 | Vali Loss: 0.0173195 | Test Loss: 0.1416568 | Mae Loss: 0.1078707 | SMAPE: 1.8668704 | MASE: 3.6145365
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1821661 | Vali Loss: 0.0178097 | Test Loss: 0.1399634 | Mae Loss: 0.1074066 | SMAPE: 2.0631046 | MASE: 4.0983963
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1919812 | Vali Loss: 0.0161626 | Test Loss: 0.1415028 | Mae Loss: 0.1047588 | SMAPE: 2.1525600 | MASE: 4.0359421
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1692248 | Vali Loss: 0.0188369 | Test Loss: 0.1428688 | Mae Loss: 0.1166546 | SMAPE: 1.5483346 | MASE: 3.0192432
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1713111 | Vali Loss: 0.0179315 | Test Loss: 0.1430060 | Mae Loss: 0.1120995 | SMAPE: 1.9162853 | MASE: 4.1245947
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1718025 | Vali Loss: 0.0171621 | Test Loss: 0.1421879 | Mae Loss: 0.1091229 | SMAPE: 1.6064200 | MASE: 2.9981852
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1787956 | Vali Loss: 0.0135646 | Test Loss: 0.1416748 | Mae Loss: 0.0962234 | SMAPE: 1.4192367 | MASE: 3.0108740
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1846865 | Vali Loss: 0.0143288 | Test Loss: 0.1415182 | Mae Loss: 0.0981491 | SMAPE: 1.6203145 | MASE: 3.0634234
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1818798 | Vali Loss: 0.0161245 | Test Loss: 0.1413085 | Mae Loss: 0.1051597 | SMAPE: 1.3440464 | MASE: 2.8456407
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.1686054 | Vali Loss: 0.0114414 | Test Loss: 0.1413400 | Mae Loss: 0.0858009 | SMAPE: 1.3689768 | MASE: 2.5873141
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.1610439 | Vali Loss: 0.0136173 | Test Loss: 0.1411485 | Mae Loss: 0.0950577 | SMAPE: 1.6793814 | MASE: 3.3858671
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 13 | Train Loss: 0.1570397 | Vali Loss: 0.0136335 | Test Loss: 0.1411757 | Mae Loss: 0.0933751 | SMAPE: 1.7447958 | MASE: 3.4799640
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 14 | Train Loss: 0.1699968 | Vali Loss: 0.0164002 | Test Loss: 0.1411897 | Mae Loss: 0.1080732 | SMAPE: 1.0831577 | MASE: 2.0597937
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 15 | Train Loss: 0.1586844 | Vali Loss: 0.0110021 | Test Loss: 0.1411018 | Mae Loss: 0.0847376 | SMAPE: 1.6372644 | MASE: 3.0773790
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 16 | Train Loss: 0.1482594 | Vali Loss: 0.0125259 | Test Loss: 0.1411143 | Mae Loss: 0.0914718 | SMAPE: 1.3145823 | MASE: 2.8103697
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 17 | Train Loss: 0.1540308 | Vali Loss: 0.0125094 | Test Loss: 0.1410655 | Mae Loss: 0.0931278 | SMAPE: 1.6277064 | MASE: 3.3479388
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 18 | Train Loss: 0.1590211 | Vali Loss: 0.0129753 | Test Loss: 0.1411670 | Mae Loss: 0.0908451 | SMAPE: 1.2033874 | MASE: 2.2855697
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 19 | Train Loss: 0.1537346 | Vali Loss: 0.0151335 | Test Loss: 0.1411331 | Mae Loss: 0.1003683 | SMAPE: 1.3429869 | MASE: 2.7171276
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 20 | Train Loss: 0.1681176 | Vali Loss: 0.0135352 | Test Loss: 0.1409735 | Mae Loss: 0.0940889 | SMAPE: 1.7118163 | MASE: 3.2029421
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 1 | Train Loss: 0.0517727 | Vali Loss: 0.0179892 | Test Loss: 0.0223126 | Mae Loss: 0.1096177 | SMAPE: 1.1344210 | MASE: 2.7607551
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 2 | Train Loss: 0.0360546 | Vali Loss: 0.0253591 | Test Loss: 0.0297774 | Mae Loss: 0.1177132 | SMAPE: 1.2138262 | MASE: 2.2352300
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 3 | Train Loss: 0.0332978 | Vali Loss: 0.0172856 | Test Loss: 0.0224389 | Mae Loss: 0.1041385 | SMAPE: 1.2518252 | MASE: 2.1820323
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 4 | Train Loss: 0.0309680 | Vali Loss: 0.0181427 | Test Loss: 0.0231448 | Mae Loss: 0.1016275 | SMAPE: 1.4087688 | MASE: 2.2682726
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 5 | Train Loss: 0.0271622 | Vali Loss: 0.0163124 | Test Loss: 0.0225722 | Mae Loss: 0.0926837 | SMAPE: 1.1187453 | MASE: 1.9182500
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 6 | Train Loss: 0.0246532 | Vali Loss: 0.0138626 | Test Loss: 0.0201094 | Mae Loss: 0.0855980 | SMAPE: 0.6236160 | MASE: 1.3728247
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 7 | Train Loss: 0.0269285 | Vali Loss: 0.0132400 | Test Loss: 0.0194484 | Mae Loss: 0.0828786 | SMAPE: 1.0911441 | MASE: 1.6788251
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 8 | Train Loss: 0.0266165 | Vali Loss: 0.0132361 | Test Loss: 0.0196401 | Mae Loss: 0.0831853 | SMAPE: 1.1076499 | MASE: 2.4784558
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 9 | Train Loss: 0.0280259 | Vali Loss: 0.0129532 | Test Loss: 0.0198929 | Mae Loss: 0.0806560 | SMAPE: 0.8550409 | MASE: 1.9582464
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 10 | Train Loss: 0.0264061 | Vali Loss: 0.0137101 | Test Loss: 0.0198513 | Mae Loss: 0.0854264 | SMAPE: 0.8712631 | MASE: 1.2537971
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 11 | Train Loss: 0.0244626 | Vali Loss: 0.0135534 | Test Loss: 0.0199826 | Mae Loss: 0.0842566 | SMAPE: 0.7156873 | MASE: 1.5643317
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 12 | Train Loss: 0.0233296 | Vali Loss: 0.0133166 | Test Loss: 0.0199255 | Mae Loss: 0.0838563 | SMAPE: 0.8547809 | MASE: 1.5513030
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 13 | Train Loss: 0.0276187 | Vali Loss: 0.0136125 | Test Loss: 0.0199935 | Mae Loss: 0.0845316 | SMAPE: 1.2000831 | MASE: 2.3211210
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 14 | Train Loss: 0.0296395 | Vali Loss: 0.0130779 | Test Loss: 0.0199852 | Mae Loss: 0.0823630 | SMAPE: 0.8473569 | MASE: 1.3326836
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 15 | Train Loss: 0.0240763 | Vali Loss: 0.0133183 | Test Loss: 0.0199262 | Mae Loss: 0.0835942 | SMAPE: 0.6992850 | MASE: 1.3834428
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 16 | Train Loss: 0.0236689 | Vali Loss: 0.0135195 | Test Loss: 0.0199321 | Mae Loss: 0.0848329 | SMAPE: 0.7806221 | MASE: 1.4206613
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 17 | Train Loss: 0.0250697 | Vali Loss: 0.0123166 | Test Loss: 0.0199314 | Mae Loss: 0.0789236 | SMAPE: 0.7349461 | MASE: 1.2971069
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 18 | Train Loss: 0.0259369 | Vali Loss: 0.0131561 | Test Loss: 0.0199278 | Mae Loss: 0.0818024 | SMAPE: 0.9410919 | MASE: 1.9173160
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 19 | Train Loss: 0.0267235 | Vali Loss: 0.0128772 | Test Loss: 0.0199661 | Mae Loss: 0.0801794 | SMAPE: 1.2696433 | MASE: 2.1050808
seq_len: 10 | label_len: 5 | pred_len: 2 | Epoch: 20 | Train Loss: 0.0161597 | Vali Loss: 0.0131707 | Test Loss: 0.0199324 | Mae Loss: 0.0826027 | SMAPE: 0.9415168 | MASE: 1.5616361
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0946273 | Vali Loss: 0.1289900 | Test Loss: 0.0710727 | Mae Loss: 0.3259799 | SMAPE: 3.1124928 | MASE: 5.5105104
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1020845 | Vali Loss: 0.0435562 | Test Loss: 0.0494683 | Mae Loss: 0.1582931 | SMAPE: 2.3108492 | MASE: 4.2583194
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 1 | Train Loss: 0.0946273 | Vali Loss: 0.1289900 | Test Loss: 0.0710727 | Mae Loss: 0.3259799 | SMAPE: 3.1124928 | MASE: 5.5105104
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 2 | Train Loss: 0.1020845 | Vali Loss: 0.0435562 | Test Loss: 0.0494683 | Mae Loss: 0.1582931 | SMAPE: 2.3108492 | MASE: 4.2583194
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 3 | Train Loss: 0.0717107 | Vali Loss: 0.0178925 | Test Loss: 0.0438733 | Mae Loss: 0.0915978 | SMAPE: 1.7107397 | MASE: 2.8369837
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 4 | Train Loss: 0.0671916 | Vali Loss: 0.0403091 | Test Loss: 0.0422109 | Mae Loss: 0.1324335 | SMAPE: 1.4743327 | MASE: 2.7545340
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 5 | Train Loss: 0.0518762 | Vali Loss: 0.0603377 | Test Loss: 0.0456225 | Mae Loss: 0.1885509 | SMAPE: 1.8622957 | MASE: 3.2013373
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 6 | Train Loss: 0.0697251 | Vali Loss: 0.0418120 | Test Loss: 0.0452357 | Mae Loss: 0.1504456 | SMAPE: 2.0510321 | MASE: 3.7055714
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 7 | Train Loss: 0.0664511 | Vali Loss: 0.0269579 | Test Loss: 0.0443683 | Mae Loss: 0.1113594 | SMAPE: 1.9479758 | MASE: 3.3267210
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 8 | Train Loss: 0.0544991 | Vali Loss: 0.0591895 | Test Loss: 0.0437469 | Mae Loss: 0.1774832 | SMAPE: 2.0231712 | MASE: 3.5407186
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 9 | Train Loss: 0.0644981 | Vali Loss: 0.0320411 | Test Loss: 0.0438579 | Mae Loss: 0.1172742 | SMAPE: 1.7017695 | MASE: 2.8429048
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 10 | Train Loss: 0.0635693 | Vali Loss: 0.0373021 | Test Loss: 0.0437310 | Mae Loss: 0.1319355 | SMAPE: 1.7367224 | MASE: 2.6678824
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 11 | Train Loss: 0.0668104 | Vali Loss: 0.0594016 | Test Loss: 0.0436701 | Mae Loss: 0.1863166 | SMAPE: 1.2103314 | MASE: 2.5279379
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 12 | Train Loss: 0.0679302 | Vali Loss: 0.0386573 | Test Loss: 0.0436871 | Mae Loss: 0.1305072 | SMAPE: 1.4596596 | MASE: 2.6774156
seq_len: 20 | label_len: 10 | pred_len: 4 | Epoch: 13 | Train Loss: 0.0600455 | Vali Loss: 0.0432693 | Test Loss: 0.0437897 | Mae Loss: 0.1431691 | SMAPE: 1.6811901 | MASE: 2.9437673
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 1 | Train Loss: 0.1388511 | Vali Loss: 0.0702523 | Test Loss: 0.0755671 | Mae Loss: 0.2247122 | SMAPE: 2.5102916 | MASE: 4.4980493
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 2 | Train Loss: 0.1074384 | Vali Loss: 0.1004018 | Test Loss: 0.0851083 | Mae Loss: 0.2838451 | SMAPE: 3.2975976 | MASE: 5.6901951
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 3 | Train Loss: 0.1200011 | Vali Loss: 0.0802616 | Test Loss: 0.0743166 | Mae Loss: 0.2341558 | SMAPE: 2.4359729 | MASE: 4.7022715
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 4 | Train Loss: 0.0968269 | Vali Loss: 0.0652489 | Test Loss: 0.0740681 | Mae Loss: 0.2078301 | SMAPE: 2.2107608 | MASE: 4.3516369
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 5 | Train Loss: 0.0897332 | Vali Loss: 0.0785821 | Test Loss: 0.0643993 | Mae Loss: 0.2283487 | SMAPE: 1.8868768 | MASE: 3.9339571
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 6 | Train Loss: 0.0893186 | Vali Loss: 0.0529650 | Test Loss: 0.0589890 | Mae Loss: 0.1689122 | SMAPE: 1.8096699 | MASE: 3.6575625
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 7 | Train Loss: 0.0900038 | Vali Loss: 0.0314053 | Test Loss: 0.0574543 | Mae Loss: 0.1355382 | SMAPE: 1.5805945 | MASE: 3.3624246
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 8 | Train Loss: 0.0846808 | Vali Loss: 0.0452902 | Test Loss: 0.0570570 | Mae Loss: 0.1561467 | SMAPE: 1.9878381 | MASE: 3.7195842
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 9 | Train Loss: 0.0894673 | Vali Loss: 0.0390407 | Test Loss: 0.0566948 | Mae Loss: 0.1382773 | SMAPE: 1.6233196 | MASE: 3.1245120
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 10 | Train Loss: 0.0752614 | Vali Loss: 0.0576341 | Test Loss: 0.0564851 | Mae Loss: 0.1777564 | SMAPE: 2.5044148 | MASE: 4.5475154
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 11 | Train Loss: 0.0783504 | Vali Loss: 0.0582466 | Test Loss: 0.0565297 | Mae Loss: 0.1825569 | SMAPE: 2.2871542 | MASE: 4.1607080
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 12 | Train Loss: 0.0741932 | Vali Loss: 0.0442410 | Test Loss: 0.0565747 | Mae Loss: 0.1542286 | SMAPE: 2.0459170 | MASE: 4.0090513
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 13 | Train Loss: 0.0841145 | Vali Loss: 0.0579028 | Test Loss: 0.0566334 | Mae Loss: 0.1822945 | SMAPE: 2.0992370 | MASE: 3.8629146
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 14 | Train Loss: 0.0798670 | Vali Loss: 0.0488457 | Test Loss: 0.0565793 | Mae Loss: 0.1676350 | SMAPE: 1.5757598 | MASE: 3.4104607
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 15 | Train Loss: 0.0757005 | Vali Loss: 0.0355905 | Test Loss: 0.0565398 | Mae Loss: 0.1425958 | SMAPE: 1.5791371 | MASE: 3.1635873
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 16 | Train Loss: 0.0859087 | Vali Loss: 0.0521577 | Test Loss: 0.0564618 | Mae Loss: 0.1735852 | SMAPE: 2.3778741 | MASE: 4.0669103
seq_len: 30 | label_len: 15 | pred_len: 6 | Epoch: 17 | Train Loss: 0.0925113 | Vali Loss: 0.0337627 | Test Loss: 0.0565011 | Mae Loss: 0.1389471 | SMAPE: 2.0421979 | MASE: 3.9927669
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 1 | Train Loss: 0.3387966 | Vali Loss: 0.4223252 | Test Loss: 0.2529277 | Mae Loss: 0.6420919 | SMAPE: 6.4712210 | MASE: 12.3871717
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 2 | Train Loss: 0.3637807 | Vali Loss: 0.1630287 | Test Loss: 0.1489618 | Mae Loss: 0.3513994 | SMAPE: 3.7940879 | MASE: 7.1915927
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 3 | Train Loss: 0.2790546 | Vali Loss: 0.0476683 | Test Loss: 0.1308837 | Mae Loss: 0.1763140 | SMAPE: 2.3215137 | MASE: 5.0890260
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 4 | Train Loss: 0.1790739 | Vali Loss: 0.1015340 | Test Loss: 0.1256161 | Mae Loss: 0.2920882 | SMAPE: 3.1148093 | MASE: 6.1086931
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 5 | Train Loss: 0.1502082 | Vali Loss: 0.1068958 | Test Loss: 0.1212522 | Mae Loss: 0.3080759 | SMAPE: 2.9291339 | MASE: 6.0527625
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 6 | Train Loss: 0.1348157 | Vali Loss: 0.0892307 | Test Loss: 0.1171391 | Mae Loss: 0.2813405 | SMAPE: 3.1009123 | MASE: 6.1394796
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 7 | Train Loss: 0.1396875 | Vali Loss: 0.0788820 | Test Loss: 0.1147892 | Mae Loss: 0.2679244 | SMAPE: 2.8997252 | MASE: 5.3265839
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 8 | Train Loss: 0.1450730 | Vali Loss: 0.0820192 | Test Loss: 0.1131894 | Mae Loss: 0.2709797 | SMAPE: 2.8811705 | MASE: 5.7659221
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 9 | Train Loss: 0.1278765 | Vali Loss: 0.0705435 | Test Loss: 0.1125595 | Mae Loss: 0.2502408 | SMAPE: 2.6092434 | MASE: 5.0860701
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 10 | Train Loss: 0.1319182 | Vali Loss: 0.0790956 | Test Loss: 0.1124088 | Mae Loss: 0.2664285 | SMAPE: 2.6674829 | MASE: 5.3323674
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 11 | Train Loss: 0.1408847 | Vali Loss: 0.0800086 | Test Loss: 0.1122623 | Mae Loss: 0.2718643 | SMAPE: 2.4424956 | MASE: 5.2536240
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 12 | Train Loss: 0.1368292 | Vali Loss: 0.0736213 | Test Loss: 0.1121575 | Mae Loss: 0.2581481 | SMAPE: 2.6569018 | MASE: 5.1687636
seq_len: 40 | label_len: 20 | pred_len: 8 | Epoch: 13 | Train Loss: 0.1226277 | Vali Loss: 0.0730697 | Test Loss: 0.1121575 | Mae Loss: 0.2538130 | SMAPE: 2.4554775 | MASE: 5.0874047
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 1 | Train Loss: 0.3180490 | Vali Loss: 0.0245679 | Test Loss: 0.1469305 | Mae Loss: 0.1342671 | SMAPE: 2.0161650 | MASE: 4.3661718
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 2 | Train Loss: 0.1763342 | Vali Loss: 0.0148269 | Test Loss: 0.1399951 | Mae Loss: 0.1037953 | SMAPE: 1.7935373 | MASE: 3.4667964
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 3 | Train Loss: 0.1774102 | Vali Loss: 0.0245991 | Test Loss: 0.1431992 | Mae Loss: 0.1328502 | SMAPE: 2.1654034 | MASE: 4.3041821
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 4 | Train Loss: 0.1902261 | Vali Loss: 0.0152323 | Test Loss: 0.1400454 | Mae Loss: 0.1013262 | SMAPE: 2.0766230 | MASE: 3.8895493
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 5 | Train Loss: 0.1679970 | Vali Loss: 0.0161233 | Test Loss: 0.1402606 | Mae Loss: 0.1011592 | SMAPE: 1.4747665 | MASE: 2.8742001
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 6 | Train Loss: 0.1691398 | Vali Loss: 0.0159317 | Test Loss: 0.1408431 | Mae Loss: 0.1044983 | SMAPE: 1.9151092 | MASE: 4.1219649
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 7 | Train Loss: 0.1708421 | Vali Loss: 0.0168220 | Test Loss: 0.1407069 | Mae Loss: 0.1068568 | SMAPE: 1.6505175 | MASE: 3.0825889
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 8 | Train Loss: 0.1782229 | Vali Loss: 0.0141208 | Test Loss: 0.1404724 | Mae Loss: 0.0968683 | SMAPE: 1.4843960 | MASE: 3.1521828
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 9 | Train Loss: 0.1846313 | Vali Loss: 0.0146606 | Test Loss: 0.1403789 | Mae Loss: 0.0984258 | SMAPE: 1.6542507 | MASE: 3.1294825
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 10 | Train Loss: 0.1817749 | Vali Loss: 0.0168359 | Test Loss: 0.1401996 | Mae Loss: 0.1069645 | SMAPE: 1.4093239 | MASE: 2.9862623
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 11 | Train Loss: 0.1685264 | Vali Loss: 0.0120365 | Test Loss: 0.1401537 | Mae Loss: 0.0874445 | SMAPE: 1.4026072 | MASE: 2.6521981
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 12 | Train Loss: 0.1606841 | Vali Loss: 0.0139996 | Test Loss: 0.1402072 | Mae Loss: 0.0966290 | SMAPE: 1.7109387 | MASE: 3.4511895
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 13 | Train Loss: 0.1566098 | Vali Loss: 0.0140447 | Test Loss: 0.1402100 | Mae Loss: 0.0949355 | SMAPE: 1.7801421 | MASE: 3.5521982
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 14 | Train Loss: 0.1695703 | Vali Loss: 0.0169558 | Test Loss: 0.1401204 | Mae Loss: 0.1091055 | SMAPE: 1.1596737 | MASE: 2.2083437
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 15 | Train Loss: 0.1587092 | Vali Loss: 0.0118622 | Test Loss: 0.1401303 | Mae Loss: 0.0876075 | SMAPE: 1.6908245 | MASE: 3.1807742
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 16 | Train Loss: 0.1474107 | Vali Loss: 0.0131925 | Test Loss: 0.1402638 | Mae Loss: 0.0936668 | SMAPE: 1.3749599 | MASE: 2.9411314
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 17 | Train Loss: 0.1536339 | Vali Loss: 0.0132717 | Test Loss: 0.1401781 | Mae Loss: 0.0956531 | SMAPE: 1.6485293 | MASE: 3.3919635
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 18 | Train Loss: 0.1587433 | Vali Loss: 0.0137130 | Test Loss: 0.1401697 | Mae Loss: 0.0926353 | SMAPE: 1.2504637 | MASE: 2.3762739
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 19 | Train Loss: 0.1533716 | Vali Loss: 0.0153737 | Test Loss: 0.1399779 | Mae Loss: 0.1009756 | SMAPE: 1.3888326 | MASE: 2.8118834
seq_len: 50 | label_len: 25 | pred_len: 10 | Epoch: 20 | Train Loss: 0.1676041 | Vali Loss: 0.0139559 | Test Loss: 0.1400216 | Mae Loss: 0.0962633 | SMAPE: 1.7609010 | MASE: 3.2973592
